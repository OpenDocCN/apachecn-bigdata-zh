# 第一章。大数据和数据科学-简介

*大数据绝对是大事！*它通过在巨大的数据仓库中获得隐藏的洞察力，并通过开辟新的商业卓越途径，承诺了大量的机会。通过先进的分析技术利用**大数据**已经成为组织创造和保持竞争优势的一个显而易见的方法。

本章解释了大数据的含义、大数据分析面临的各种挑战，以及 **Apache Spark** 如何作为事实上的标准来应对计算挑战，并充当数据科学平台。

本章涵盖的主题如下:

*   大数据概述-有什么好大惊小怪的？
*   大数据分析面临的挑战-为什么这么难？
*   大数据分析的发展——数据分析趋势
*   数据分析火花-应对大数据挑战的解决方案
*   Spark 堆栈-所有这些构成了一个完整的大数据解决方案

# 大数据概述

关于什么是大数据，已经说了很多，也写了很多，但是没有明确的标准来定义它。在某种程度上，它实际上是一个相对术语。无论是大数据还是小数据，只有正确分析，才能充分利用这些数据。为了让数据更有意义，需要一套正确的分析技术，选择正确的工具和技术在数据分析中至关重要。然而，当数据本身成为问题的一部分，并且需要在执行数据分析之前解决计算挑战时，它就变成了一个大数据问题。

万维网(也称为 Web 2.0)发生了一场革命，它改变了人们使用互联网的方式。静态网页变成了互动网站，开始收集越来越多的数据。云计算、社交媒体和移动计算的技术进步带来了数据的爆炸式增长。每个数字设备都开始发射数据，许多其他来源开始推动数据洪流。来自每个角落的数据流以极快的速度生成了各种各样的海量数据！以这种方式形成大数据是一种自然现象，因为万维网就是这样发展的，具体细节中没有明确的努力。这是关于过去的！如果考虑到现在正在发生的变化，以及未来将要发生的变化，数据生成的数量和速度超出了人们的预期。我之所以做出这样的声明，是因为得益于**物联网** ( **物联网**)，如今每个设备都变得越来越智能。

信息技术的趋势是，技术进步也促进了数据爆炸。随着更便宜的在线存储池集群的出现，以及以最低价格提供商品硬件，数据存储经历了范式转变。将来自不同来源的数据以其原始形式存储在一个数据湖中，正迅速超越精心设计的数据集市和数据仓库。使用模式也从僵化的模式驱动的、基于关系数据库管理系统的方法转向无模式的、持续可用的 **NoSQL** 数据存储驱动的解决方案。因此，无论是结构化、半结构化还是非结构化数据的创建速度开始前所未有地加快。

组织非常确信，不仅可以通过利用大数据来回答特定的业务问题；它还带来了机会来涵盖业务中未发现的可能性，并解决与此相关的不确定性。因此，除了自然的数据流入，组织开始设计策略来生成越来越多的数据，以保持其竞争优势并为未来做好准备。在这里，一个例子将有助于更好地理解这一点。想象一下，传感器安装在制造工厂的机器上，不断发出数据，从而显示机器零件的状态，公司能够预测机器何时会出现故障。它让公司防止故障或损坏，避免计划外停机，节省了大量资金。

# 大数据分析面临的挑战

在大数据分析方面，大体上有两种令人生畏的挑战。第一个挑战是对大规模计算平台的需求，一旦它到位，第二个挑战是从大规模的巨大数据中进行分析和理解。

## 计算挑战

随着数据量的增加，对大数据的存储需求也越来越大。数据管理成了一项繁琐的任务。尽管处理器的处理速度和随机存取存储器的频率达到了标准，但由于寻道时间而导致的访问磁盘存储器的延迟成为主要瓶颈。

从各种业务应用程序和数据孤岛中提取结构化和非结构化数据，整合它们，并对它们进行处理以找到有用的业务见解，这是一项挑战。只有少数几个应用程序可以解决任何一个领域，或者只有少数几个领域的多样化业务需求。然而，集成这些应用程序以统一的方式解决大多数业务需求只会增加复杂性。

为了应对这些挑战，人们转向了具有分布式文件系统的分布式计算框架，例如 Hadoop 和 **Hadoop 分布式文件系统** ( **HDFS** )。这可以消除由于磁盘输入/输出造成的延迟，因为数据可以在机器集群中并行读取。

分布式计算技术在此之前已经存在了几十年，但只有在行业意识到大数据的重要性后，它才变得更加突出。因此，像 Hadoop 和 HDFS 或亚马逊 S3 这样的技术平台成为了行业标准。在 Hadoop 的基础上，开发了许多其他解决方案，如 Pig、Hive、Sqoop 等，以解决不同类型的行业需求，如存储、**提取、转换和加载** ( **ETL** )以及数据集成，使 Hadoop 成为一个统一的平台。

## 分析挑战

分析数据以发现一些隐藏的见解一直具有挑战性，因为处理庞大的数据集涉及额外的复杂性。传统的商业智能和 OLAP 解决方案无法解决大数据带来的大部分挑战。举个例子，如果一个数据集有多个维度，比如 100，那么很难将这些变量相互比较得出结论，因为它大约有 100 个 C2 组合。这种情况需要*相关*等统计技术来发现隐藏的模式。

尽管有许多问题的统计解决方案，但数据科学家或分析专业人员很难对数据进行切片和切割，以找到智能见解，除非他们将整个数据集加载到内存中的**数据框**中。主要的障碍是，大多数用于统计分析和机器学习的通用算法都是单线程的，并且是在数据集通常不那么庞大并且可以放在单台计算机的内存中的时候编写的。由于内存计算的限制，那些用 R 或 Python 编写的算法在部署到分布式计算环境中时，其本机形式不再非常有用。

为了应对这一挑战，统计学家和计算机科学家必须合作重写大多数在分布式计算环境中运行良好的算法。因此，在 Hadoop 上为并行处理开发了一个名为 **Mahout** 的机器学习算法库。它拥有业内最常用的大多数通用算法。其他分布式计算框架也采取了类似的举措。

# 大数据分析的演进

上一节概述了如何针对大数据需求应对计算和数据分析挑战。之所以成为可能，是因为一些相关趋势的融合，如低成本商品硬件、大数据的可访问性和改进的数据分析技术。Hadoop 成为许多大型分布式数据处理基础设施的基石。

然而，人们很快开始意识到 Hadoop 的局限性。Hadoop 解决方案最适合仅特定类型的大数据需求，如 ETL 它只因为这样的需求而流行。

在某些情况下，数据工程师或分析师必须对数据集执行临时查询，以进行交互式数据分析。每次他们在 Hadoop 上运行查询时，数据都会从磁盘中读取(HDFS 读取)并加载到内存中，这是一件代价高昂的事情。实际上，作业运行的速度是通过网络和磁盘集群进行输入/输出传输的速度，而不是中央处理器和内存的速度。

以下是该场景的图示:

![Evolution of big data analytics](graphics/image_01_001.jpg)

Hadoop 的 MapReduce 模型不能很好地适应的另一个例子是本质上是迭代的机器学习算法。Hadoop MapReduce 表现不佳，迭代计算存在巨大延迟。由于 MapReduce 有一个受限的编程模型，禁止 Map 和 Reduce 工作人员之间的通信，因此中间结果需要存储在一个稳定的存储中。因此，这些数据被推送到 HDFS，然后写入，而不是保存在内存中，然后加载回内存，用于后续迭代，类似于其他迭代。磁盘输入/输出的数量取决于算法中涉及的迭代次数，这在保存和加载数据时被序列化和反序列化开销所抵消。总的来说，它的计算成本很高，并且无法达到预期的受欢迎程度。

以下是这种情况的图示:

![Evolution of big data analytics](graphics/image_01_002.jpg)

为了解决这个问题，开发了定制的解决方案，例如谷歌的 Pregel，这是一种迭代图形处理算法，针对进程间通信和中间结果的内存存储进行了优化，以使其运行更快。同样，开发或重新设计了许多其他解决方案，这些解决方案最适合所用算法的一些特定需求。

不是重新设计所有的算法，而是需要一个通用引擎，它可以被大多数算法用于分布式计算平台上的内存计算。还期望这样的设计将导致迭代计算和特别数据分析的更快执行。这就是火花项目如何在加州大学伯克利分校的 AMPLab 铺平了道路。

# 数据分析的火花

Spark 项目在 AMP 实验室获得成功后不久，它于 2010 年成为开源项目，并于 2013 年移交给 Apache 软件基金会。它目前由 Databricks 领导。

与其他分布式计算平台相比，Spark 具有许多明显的优势，例如:

*   迭代机器学习和交互式数据分析的更快执行平台
*   用于批处理、SQL 查询、实时流处理、图形处理和复杂数据分析的单一堆栈
*   通过隐藏分布式编程的复杂性，提供高级 API 来开发各种分布式应用程序
*   无缝支持各种数据源，如 RDBMS、HBase、Cassandra、Parquet、MongoDB、HDFS、亚马逊 S3 等

![Spark for data analytics](graphics/image_01_003.jpg)

下面是迭代算法的内存数据共享的图示:

![Spark for data analytics](graphics/image_01_004.jpg)

Spark 隐藏了编写核心 MapReduce 作业的复杂性，并通过简单的函数调用提供了大部分功能。由于其简单性，它能够迎合越来越多的受众群体，如数据科学家、数据工程师、统计学家和 R/Python/Scala/Java 开发人员。

Spark 架构主要由数据存储层、管理框架和应用编程接口组成。它被设计为在 HDFS 文件系统之上工作，从而利用现有的生态系统。部署可以作为一个独立的服务器，也可以在分布式计算框架上，如 Apache Mesos 或纱。Scala 提供了一个应用编程接口，Scala 是编写 Spark 的语言，还有 Java、R 和 Python。

# 火花堆

Spark 是一个通用集群计算系统，它使其他更高级别的组件能够利用其核心引擎。它可以与 Apache Hadoop 互操作，也就是说，它可以读写 HDFS 的数据，还可以与 Hadoop 应用编程接口支持的其他存储系统集成。

虽然它允许在其上构建其他更高级别的应用程序，但它已经有了一些构建在其上的组件，这些组件与其核心引擎紧密集成，以利用核心的未来增强功能。这些应用程序与 Spark 捆绑在一起，以覆盖行业中更广泛的需求集。大多数真实世界的应用程序需要跨项目集成，以解决通常有一组需求的特定业务问题。Apache Spark 缓解了这一问题，因为它允许更高级别的组件无缝集成，例如开发项目中的库。

此外，借助 Spark 对 Scala、Java、R 和 Python 的内置支持，更广泛的开发人员和数据工程师能够利用整个 Spark 堆栈:

![The Spark stack](graphics/image_01_005.jpg)

## 火花芯

在某种程度上，Spark 内核类似于操作系统的内核。它是通用执行引擎，既快速又容错。整个 Spark 生态系统都建立在这个核心引擎之上。它主要用于跨工作节点进行作业调度、任务分配和作业监控。它还负责内存管理、与各种异构存储系统交互以及各种其他操作。

Spark 核心的主要构建模块是**弹性分布式数据集** ( **RDD** )，这是一个不可变的、容错的元素集合。Spark 可以从各种数据源创建 rdd，如 HDFS、本地文件系统、亚马逊 S3、其他 rdd、NoSQL 数据存储(如 Cassandra)等。从失败后自动重建的意义上来说，它们是有弹性的。rdd 是通过惰性并行转换构建的。它们可以被缓存和分区，也可以不被具体化。

整个 Spark 核心引擎可以看作是分布式数据集上的一组简单操作。Spark 中所有作业的调度和执行都是基于与每个 RDD 相关的方法完成的。此外，与每个 RDD 相关联的方法定义了它们自己的分布式内存计算方式。

## 火花 SQL

Spark 的这一模块旨在对结构化数据进行查询、分析和执行操作。这是整个 Spark 堆栈中非常重要的组成部分，因为大多数组织数据都是结构化的，尽管非结构化数据正在快速增长。作为一个分布式查询引擎，它使 Hadoop Hive 查询能够在不做任何修改的情况下运行快 100 倍。除了 Hive 之外，它还支持 Apache Parquet(一种高效的柱状存储)、JSON 和其他结构化数据格式。Spark SQL 支持运行 SQL 查询以及用 Python、Scala 和 Java 编写的复杂程序。

Spark SQL 提供了一个称为 **DataFrames** 的分布式编程抽象，以前称为 SchemaRDD，与之相关的函数较少。数据框架是命名列的分布式集合，类似于 SQL 表或 Python 的 Pandas 数据框架。它们可以用各种带有模式的数据源来构建，例如 Hive、Parquet、JSON、其他 RDBMS 源，以及 Spark RDDs。

Spark SQL 可以用于跨不同格式的 ETL 处理，然后运行即席分析。Spark SQL 附带了一个名为 Catalyst 的优化器框架，可以转换 SQL 查询以提高效率。

## 火花流

企业数据的处理窗口比以往任何时候都要短。为了满足行业的实时处理需求，设计了 Spark 的这个组件，它具有容错性和可扩展性。Spark 通过支持实时数据流上的数据分析、机器学习和图形处理，支持实时数据流上的数据分析。

它提供了一个名为**离散流** ( **数据流**)的应用编程接口来操纵实时数据流。实时数据流被分成小批量，比如说， *x* 秒。Spark 将每个批次视为一个 RDD，并将其作为基本的 RDD 操作进行处理。数据流可以从来自 HDFS、卡夫卡、弗鲁姆或任何其他可以在 TCP 套接字上流式传输数据的来源的实时数据流中创建。通过对数据流应用一些高级操作，可以产生其他数据流。

Spark 流的最终结果可以写回 Spark 支持的各种数据存储，也可以推送到任何仪表板进行可视化。

## MLlib

MLlib 是 Spark 堆栈中内置的机器学习库。这是在 Spark 0.8 中引入的。它的目标是让机器学习变得可扩展和容易。开发人员可以在他们选择的编程语言中无缝地使用火花 SQL、火花流和 GraphX，无论是 Java、Python 还是 Scala。MLlib 提供了必要的功能来执行各种统计分析，如相关性、抽样、假设检验等。该组件还广泛覆盖了分类、回归、协同过滤、聚类和分解中的应用和算法。

机器学习工作流程包括收集和预处理数据、构建和部署模型、评估结果以及细化模型。在现实世界中，预处理步骤占用了大量的精力。这些通常是涉及昂贵的中间读/写操作的多阶段工作流。通常，这些处理步骤可以在一段时间内执行多次。引入了一个新的概念 **ML 管道**来简化这些预处理步骤。流水线是一系列转换，其中一个阶段的输出是另一个阶段的输入，形成一个链。ML 管道利用 Spark 和 MLlib，使开发人员能够定义可重用的转换序列。

## 图形

GraphX 是一个基于 Spark 的薄层统一图形分析框架。它被设计成一个通用的分布式数据流框架来代替专门的图形处理框架。它是容错的，也利用内存中的计算。

**GraphX** 是一个嵌入式图形处理 API，用于操作图形(例如社交网络)和进行图形并行计算(例如谷歌的 Pregel)。它结合了 Spark 堆栈上图形并行和数据并行系统的优点，以统一探索性数据分析、迭代图形计算和 ETL 处理。它扩展了 RDD 抽象，引入了**弹性分布图** ( **RDG** )，这是一个有向图，其属性与其每个顶点和边相关联。

GraphX 包括相当大的图形算法集合，例如 PageRank、K-Core、三角计数、LDA 等等。

## 火花放电

SparkR 项目的启动是为了将 R 的统计分析和机器学习能力与 Spark 的可扩展性相结合。它解决了 R 的局限性，即它能够处理的数据与单机内存中的数据一样多。r 程序现在可以通过 SparkR 在分布式环境中扩展。

SparkR 实际上是一个 R Package，它提供了一个 R shell 来利用 Spark 的分布式计算引擎。借助 R 丰富的内置数据分析包，数据科学家可以大规模交互分析大型数据集。

# 总结

在本章中，我们简要介绍了大数据的含义。然后，我们讨论了大数据分析中涉及的计算和分析挑战。后来，我们研究了大数据环境下的分析空间在一段时间内是如何演变的，以及趋势如何。我们还讲述了 Spark 如何应对大数据分析的大部分挑战，并成为数据科学和并行计算的通用统一分析平台。在这一章的结尾，我们只是给你一个关于 Spark 堆栈及其组件的提示。

在下一章中，我们将学习 Spark 编程模型。我们将深入探究 Spark 的基本构造块，也就是 RDD。此外，我们将学习如何在 Scala 和 Python 上使用 RDD 应用编程接口编程。

# 参考文献

Apache Spark 概述:

*   [http://spark.apache.org/docs/latest/](http://spark.apache.org/docs/latest/)
*   [https://databricks.com/spark/about](https://databricks.com/spark/about)

Apache Spark 架构:

*   [http://lintool . github . io/SparkTutorial/slides/day 1 _ context . pdf](http://lintool.github.io/SparkTutorial/slides/day1_context.pdf)