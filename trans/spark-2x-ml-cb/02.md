# 火花机器学习的线性代数刚刚好

在本章中，我们将介绍以下食谱:

*   矢量和矩阵的包导入和初始设置
*   使用 Spark 2.0 创建 DenseVector 和设置
*   使用 Spark 2.0 创建 SparseVector 并进行设置
*   使用 Spark 2.0 创建密度矩阵和设置
*   使用 Spark 2.0 的稀疏局部矩阵
*   使用 Spark 2.0 执行矢量算法
*   使用 Spark 2.0 执行矩阵运算
*   Spark 2.0 ML 库中的分布式矩阵
*   探索火花 2.0 中的行矩阵
*   探索 Spark 2.0 中的分布式索引存储矩阵
*   探索 Spark 2.0 中的分布式坐标矩阵
*   探索 Spark 2.0 中的分布式块矩阵

# 介绍

线性代数是**机器学习** ( **ML** )和**数学** **编程** ( **MP** )的基石。在处理 Spark 的机器库时，必须了解 Scala 提供的向量/矩阵结构(默认导入)不同于 Spark 提供的 Spark ML、MLlib Vector、Matrix 设施。后者由 RDDs 提供支持，如果您打算使用 Spark(即并行性)进行大规模矩阵/向量计算(例如，具有更高数值精度的 SVD 实现备选方案，在某些情况下需要用于衍生品定价和风险分析)，则后者是理想的数据结构。Scala 向量/矩阵库提供了一组丰富的线性代数操作，如点积、加法等，它们在 ML 管道中仍然有自己的位置。总之，使用 Scala Breeze 和 Spark 或 Spark ML 的主要区别在于，Spark 工具由 RDDs 支持，它允许同时进行分布式、并发计算和弹性，而不需要任何额外的并发模块或额外的努力(例如，Akka + Breeze)。

几乎所有的机器学习算法都使用某种形式的分类或回归机制(不一定是线性的)来训练模型，然后通过将训练输出与实际输出进行比较来最小化误差。例如，Spark 中推荐系统的任何实现都将严重依赖于矩阵分解、因子分解、近似或**单值分解** ( **SVD** )。处理大数据集降维的另一个感兴趣的机器学习领域是**主成分分析** ( **主成分分析**)，它严重依赖于线性代数、因子分解和矩阵操作。

当我们在 Spark 1.x.x 中第一次检查 Spark ML 和 MLlib 算法的源代码时，我们很快注意到 Vectors 和 Matrices 使用 RDDs 作为许多优秀算法的基础。

当我们重新回顾 Spark 2.0 和机器学习库的源代码时，我们注意到了一些有趣的变化，这些变化需要在未来考虑。下面是一个从 Spark 1.6.2 到 Spark 2.0.0 的这种变化的例子，它影响了我们使用 Spark 的一些线性代数代码:

*   在之前的版本(Spark 1.6.x)中，可以使用`toBreeze()`函数直接转换`DenseVector`或`SparseVector`(参考[https://Spark . Apache . org/docs/1 . 5 . 2/API/Java/org/Apache/Spark/mllib/linalg/vectors . html](https://spark.apache.org/docs/1.5.2/api/java/org/apache/spark/mllib/linalg/Vectors.html))，如下代码库所示:

```
val w3 = w1.toBreeze // spark 1.6.x codeval w4 = w2.toBreeze //spark 1.6.x code
```

*   在 Spark 2.0 中，`toBreeze()`功能不仅改为了`asBreeze()`，还降级为私有功能
*   要解决这个问题，请使用以下代码片段之一将前面的向量转换为常用的`BreezeVector`实例:

```
val w3 = new BreezeVector(x.toArray)//x.asBreeze, spark 2.0val w4 = new BreezeVector(y.toArray)//y.asBreeze, spark 2.0
```

Scala 是一种简洁的语言，在这种语言中，面向对象和函数式编程范例可以共存而不冲突。虽然在机器学习范例中，函数式编程是首选，但是在后期阶段使用面向对象的方法进行初始数据收集和呈现并没有错。

在大规模分布式矩阵方面，我们的经验表明，当接近大矩阵集 10 <sup class="calibre28">9</sup> 到 10 <sup class="calibre28">13</sup> 到 10 <sup class="calibre28">27</sup> 等等时，您必须更深入地了解分布式操作中固有的网络操作和洗牌。根据我们的经验，局部和分布式矩阵/向量运算(例如，点积、乘法等)的组合在大规模操作时效果最佳。

下图描述了可用火花矢量和矩阵的分类:

![](../images/00044.jpeg)

# 矢量和矩阵的包导入和初始设置

在我们可以在 Spark 中编程或使用向量和矩阵工件之前，我们需要首先导入正确的包，然后设置`SparkSession`，这样我们就可以访问集群句柄。

在这个简短的食谱中，我们重点介绍了能够涵盖 Spark 中大多数线性代数操作的大量软件包。随后的单个配方将包括特定程序所需的精确子集。

# 怎么做...

1.  在 IntelliJ 或您选择的 IDE 中启动一个新项目。确保包含必要的 JAR 文件。
2.  设置程序将驻留的包位置:

```
package spark.ml.cookbook.chapter2
```

3.  导入矢量和矩阵操作所需的包:

```
import org.apache.spark.mllib.linalg.distributed.RowMatriximport org.apache.spark.mllib.linalg.distributed.{IndexedRow, IndexedRowMatrix}import org.apache.spark.mllib.linalg.distributed.{CoordinateMatrix, MatrixEntry}import org.apache.spark.sql.{SparkSession}import org.apache.spark.rdd._import org.apache.spark.mllib.linalg._import breeze.linalg.{DenseVector => BreezeVector}import Array._import org.apache.spark.mllib.linalg.DenseMatriximport org.apache.spark.mllib.linalg.SparseVector
```

4.  导入用于设置`log4j`日志级别的包。此步骤是可选的，但我们强烈建议您这样做(在开发周期中适当更改级别):

```
import org.apache.log4j.Loggerimport org.apache.log4j.Level
```

5.  将日志级别设置为警告和错误，以减少输出。有关软件包要求，请参见上一步:

```
Logger.getLogger("org").setLevel(Level.ERROR)Logger.getLogger("akka").setLevel(Level.ERROR)
```

6.  设置火花上下文和应用程序参数，以便火花可以运行:

```
val spark = SparkSession.builder.master("local[*]").appName("myVectorMatrix").config("spark.sql.warehouse.dir", ".").getOrCreate()
```

# 还有更多...

在 Spark 2.0 之前，SparkContext 和 SQLContext 必须分别初始化。如果您计划在早期版本的 Spark 中运行代码，请参考以下代码片段。

设置应用程序参数，以便 Spark 可以运行(使用 Spark 1.5.2 或 Spark 1.6.1):

```
val conf = new SparkConf().setMaster("local[*]").setAppName("myVectorMatrix").setSparkHome("C:\\spark-1.5.2-bin-hadoop2.6")val sc = new SparkContext(conf)val sqlContext = new SQLContext(sc)
```

# 请参见

SparkSession 是 Spark 2.x.x 及更高版本中集群的新入口点。SparkSession 统一了对集群和所有数据的访问入口。它统一了对 SparkContext、SQLContext 或 HiveContext 的访问，同时使使用数据框架和数据集 API 变得更加容易。我们将在[第 4 章](04.html#5UNGG0-4d291c9fed174a6992fd24938c2f9c77)、*实现健壮机器学习系统的通用方法*中用一个专用的方法重新访问 SparkSession。

参考下图:

![](../images/00045.jpeg)

方法调用的文档见[https://spark . Apache . org/docs/2 . 0 . 0/API/Scala/# org . Apache . spark . SQL . sparksession](https://spark.apache.org/docs/2.0.0/api/scala/#org.apache.spark.sql.SparkSession)。

# 使用 Spark 2.0 创建 DenseVector 和设置

在本食谱中，我们使用 Spark 2.0 机器库探索`DenseVectors`。

Spark 提供了两种不同类型的向量工具(密集和稀疏)，用于存储和操作将在机器学习或优化算法中使用的特征向量。

# 怎么做...

1.  在本节中，我们将研究`DenseVector`个例子，您最有可能使用这些例子来实现/扩充现有的机器学习程序。这些示例还有助于更好地理解 Spark ML 或 MLlib 源代码和底层实现(例如，单值分解)。
2.  这里我们看一下从数组创建一个 ML 向量特征(带有独立变量)，这是一个常见的用例。在这种情况下，我们有三个几乎完全填充的 Scala 阵列，对应于客户和产品特性集。我们将这些数组转换为 Scala 中相应的`DenseVectors`:

```
val CustomerFeatures1: Array[Double] = Array(1,3,5,7,9,1,3,2,4,5,6,1,2,5,3,7,4,3,4,1)val CustomerFeatures2: Array[Double] = Array(2,5,5,8,6,1,3,2,4,5,2,1,2,5,3,2,1,1,1,1)val ProductFeatures1: Array[Double]  = Array(0,1,1,0,1,1,1,0,0,1,1,1,1,0,1,2,0,1,1,0)
```

设置变量以从数组创建向量。从数组转换到`DenseVector`:

```
val x = Vectors.dense(CustomerFeatures1)val y = Vectors.dense(CustomerFeatures2)val z = Vectors.dense(ProductFeatures1)
```

3.  下一步是创建`DenseVector`并通过初始化赋值。

这是引用最多的情况，并且经常在处理批处理输入的类构造函数中使用:

```
val denseVec2 = Vectors.dense(5,3,5,8,5,3,4,2,1,6)
```

4.  下面是另一个示例，显示初始化期间从字符串到双精度值的动态转换。这里我们从一个字符串开始，内联调用`toDouble`:

```
val xyz = Vectors.dense("2".toDouble, "3".toDouble, "4".toDouble)println(xyz)
```

输出如下:

```
[2.0,3.0,4.0]
```

# 它是如何工作的...

1.  此方法构造函数的签名是:

```
DenseVector (double[] values)
```

2.  方法继承自以下内容，这使得它的具体方法可用于所有例程:

```
interface class java.lang.Objectinterface org.apache.spark.mllib.linalg. Vector
```

3.  有几个感兴趣的方法调用:
    1.  制作矢量的深度副本:

```
DenseVector copy()
```

```
SparseVector toSparse()
```

```
Int numNonzeros()
```

```
Double[] toArray()
```

# 还有更多...

必须注意不要将`Breeze`库提供的矢量工具与 Spark ML 矢量混合。要使用 ML 库算法，需要使用其原生数据结构，但在使用 ML 库算法(例如 ALS 或 SVD)时，始终可以从 ML 向量转换为`Breeze`，进行所有的数学运算，然后转换为 Spark 想要的数据结构。

我们需要向量和矩阵导入语句，这样我们就可以使用 ML 库本身，否则将默认使用 Scala 向量和矩阵。当程序无法在集群上扩展时，这是许多混乱的根源。

下图描绘了一个有助于阐明主题的图示视图:

![](../images/00046.jpeg)

# 请参见

*   构造函数的文档可在[https://spark . Apache . org/docs/latest/API/Java/org/Apache/spark/mllib/linalg/densevector . html # constructor _ summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/DenseVector.html#constructor_summary)获得

*   方法调用的文档可在[https://spark . Apache . org/docs/latest/API/Java/org/Apache/spark/mllib/linalg/densevector . html # method _ summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/DenseVector.html#method_summary)获得

# 创建 SparseVector 并使用 Spark 进行设置

在这个食谱中，我们考察了几种类型的`SparseVector`创造。随着向量长度的增加(百万)和密度的保持(少数非零成员)，稀疏表示变得越来越有优势。

# 怎么做...

1.  在 IntelliJ 或您选择的 IDE 中启动一个新项目。确保包含必要的 JAR 文件。
2.  导入矢量和矩阵操作所需的包:

```
import org.apache.spark.sql.{SparkSession}import org.apache.spark.mllib.linalg._import breeze.linalg.{DenseVector => BreezeVector}import Array._import org.apache.spark.mllib.linalg.SparseVector
```

3.  设置火花上下文和应用程序参数，以便火花可以运行。有关更多细节和变化，请参见本章中的第一个配方:

```
val spark = SparkSession.builder.master("local[*]").appName("myVectorMatrix").config("spark.sql.warehouse.dir", ".").getOrCreate()
```

4.  在这里，我们看着创建一个对应于它的等价的密度向量的最大稀疏向量。该调用由三个参数组成:向量的大小、非零数据的索引，最后是数据本身。

在下面的例子中，我们可以比较密集和稀疏事件创建。如您所见，非零的四个元素(5、3、8、9)对应于位置(0、2、18、19)，而数字 20 表示总大小:

```
val denseVec1 = Vectors.dense(5,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,8,9)val sparseVec1 = Vectors.sparse(20, Array(0,2,18,19), Array(5, 3, 8,9))
```

5.  为了更好地理解数据结构，我们比较输出和一些对我们有帮助的重要属性，特别是使用向量的动态编程。

首先，我们看一下 DenseVector 的打印输出，看看它的表示形式:

```
println(denseVec1.size)println(denseVec1.numActives)println(denseVec1.numNonzeros)println("denceVec1 presentation = ",denseVec1)
```

输出如下:

```
denseVec1.size = 20denseVec1.numActives = 20denseVec1.numNonzeros = 4(denseVec1 presentation = ,[5.0,0.0,3.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,8.0,9.0])
```

6.  接下来，我们看一下 SparseVector 的打印输出，看看它的内部表示:

```
println(sparseVec1.size)println(sparseVec1.numActives)println(sparseVec1.numNonzeros)println("sparseVec1 presentation = ",sparseVec1)
```

如果我们将内部表示和元素数量与活动和非零元素进行比较和对比，您会看到 SparseVector 只存储非零元素和索引，以减少存储需求。

输出如下:

```
denseVec1.size = 20println(sparseVec1.numActives)= 4sparseVec1.numNonzeros = 4 (sparseVec1 presentation = ,(20,[0,2,18,19],[5.0,3.0,8.0,9.0]))
```

7.  我们可以根据需要在稀疏和密集转换器之间来回转换。你可能想这么做的原因是外部数学和线性代数不符合 Spark 的内部表示。为了说明这一点，我们将变量类型显式化了，但是您可以在实际操作中消除这个额外的声明:

```
val ConvertedDenseVect : DenseVector= sparseVec1.toDenseval ConvertedSparseVect : SparseVector= denseVec1.toSparseprintln("ConvertedDenseVect =", ConvertedDenseVect)println("ConvertedSparseVect =", ConvertedSparseVect)
```

输出如下:

```
(ConvertedDenseVect =,[5.0,0.0,3.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,8.0,9.0])(ConvertedSparseVect =,(20,[0,2,18,19],[5.0,3.0,8.0,9.0]))
```

# 它是如何工作的...

1.  此方法构造函数的签名是:

```
SparseVector(int size, int[] indices, double[] values)
```

方法继承自以下内容，这使得它的具体方法可用于所有例程:

```
interface class java.lang.Object  
```

有几个与感兴趣的向量相关的方法调用:

```
SparseVector Copy() 
```

```
DenseVector toDense()
```

```
Int numNonzeros()
```

```
Double[] toArray() 
```

# 还有更多...

1.  必须记住，密集向量和稀疏向量是局部向量，它们不能与分布式工具(例如，像行矩阵类这样的分布式矩阵)混淆。
2.  本地机器上矢量的基本数学运算将由两个库提供:

还有另一种与向量直接相关的数据结构，称为标签点，我们在[第 4 章](04.html#5UNGG0-4d291c9fed174a6992fd24938c2f9c77)、*实现健壮机器学习系统的常用方法*中介绍过。简而言之，它是对应于`LIBSVM`和`LIBLINEAR`格式的数据结构，用于存储由特征向量加上标签(例如，回归中的自变量和因变量)组成的 ML 数据:

*   **libsvm**:[http://www . csie . NTU . edu . tw/~ cjlin/libsvm/](http://www.csie.ntu.edu.tw/~cjlin/libsvm/)

*   **liblinear**:[http://www . csie . NTU . edu . tw/~ cjlin/liblinear/](http://www.csie.ntu.edu.tw/~cjlin/liblinear/)

# 请参见

*   构造函数的文档可在[https://spark . Apache . org/docs/latest/API/Java/org/Apache/spark/mllib/linalg/sparsevector . html # constructor _ summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/SparseVector.html#constructor_summary)获得

*   方法调用的文档可在[https://spark . Apache . org/docs/latest/API/Java/org/Apache/spark/mllib/linalg/sparsevector . html # method _ summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/SparseVector.html#method_summary)获得

# 使用 Spark 2.0 创建密集矩阵和设置

在这个食谱中，我们探索了矩阵创建的例子，这些例子是您在 Scala 编程中最需要的，同时阅读了许多机器学习开源库的源代码。

Spark 提供了两种不同类型的本地矩阵工具(密集和稀疏)，用于在本地存储和操作数据。为简单起见，考虑矩阵的一种方法是将其可视化为向量列。

# 准备好

这里要记住的关键是，配方涵盖了存储在一台机器上的本地矩阵。我们将在 Spark2.0 ML 库中使用另一个配方 *D* *来存储和操作分布式矩阵，本章将对此进行介绍。*

# 怎么做...

1.  在 IntelliJ 或您选择的 IDE 中启动一个新项目。确保包含必要的 JAR 文件。
2.  导入矢量和矩阵操作所需的包:

```
 import org.apache.spark.sql.{SparkSession}import org.apache.spark.mllib.linalg._import breeze.linalg.{DenseVector => BreezeVector}import Array._import org.apache.spark.mllib.linalg.SparseVector
```

3.  设置火花会话和应用程序参数，以便火花可以运行:

```
val spark = SparkSession.builder.master("local[*]").appName("myVectorMatrix").config("spark.sql.warehouse.dir", ".").getOrCreate()
```

4.  这里我们看一下从 Scala 数组创建一个 ML 向量特征。让我们定义一个 2x2 密集矩阵，并用一个数组实例化它:

```
val MyArray1= Array(10.0, 11.0, 20.0, 30.3)val denseMat3 = Matrices.dense(2,2,MyArray1)   
```

输出如下:

```
DenseMat3=10.0  20.0  11.0  30.3 
```

构建密集矩阵并通过初始化在一个步骤中赋值:

通过内联定义数组，直接构造密集的局部矩阵。这是一个 3x3 的数组，有九个成员。你可以把它想象成三列三个向量(3x3):

```
val denseMat1 = Matrices.dense(3,3,Array(23.0, 11.0, 17.0, 34.3, 33.0, 24.5, 21.3,22.6,22.2))
```

输出如下:

```
    denseMat1=
    23.0  34.3  21.3  
    11.0  33.0  22.6  
    17.0  24.5  22.2

```

这是另一个用向量展示密集局部矩阵的内联实例化的例子。这是一种常见的情况，您将向量收集到一个矩阵中(列顺序)，然后对整个集合执行运算。最常见的情况是收集向量，然后使用分布式矩阵进行分布式并行操作。

在 Scala 中，我们对数组使用`++`运算符来实现连接:

```
val v1 = Vectors.dense(5,6,2,5)val v2 = Vectors.dense(8,7,6,7)val v3 = Vectors.dense(3,6,9,1)val v4 = Vectors.dense(7,4,9,2)val Mat11 = Matrices.dense(4,4,v1.toArray ++ v2.toArray ++ v3.toArray ++ v4.toArray)println("Mat11=\n", Mat11)
```

输出如下:

```
    Mat11=
    5.0  8.0  3.0  7.0  
   6.0  7.0  6.0  4.0  
   2.0  6.0  9.0  9.0  
   5.0  7.0  1.0  2.0

```

# 它是如何工作的...

1.  此方法构造函数的签名是(列主密集矩阵):

```
DenseMatrix(int numRows, int numCols, double[] values)DenseMatrix(int numRows, int numCols, double[] values, boolean isTransposed)
```

2.  方法继承自以下内容，这使得所有例程都可以使用它们的具体方法:
    *   接口类 java.lang.Object

    *   java.io .可序列化

    *   [数]矩阵

3.  有几个感兴趣的方法调用:
    1.  根据向量中提供的值生成对角矩阵:

```
static DenseMatrix(Vector vector) 
```

```
static eye(int n) 
```

```
boolean isTransposed()
```

```
static DenseMatrix rand(int numRows, int numCols, java.util.Random rng) 
```

```
static DenseMatrix randn(int numRows, int numCols, java.util.Random rng) 
```

```
DenseMatrix transpose() 
```

```
DenseVector Copy() 
```

```
SparseVector toSparse() 
```

```
Int numNonzeros()
```

```
Double[] Values()
```

# 还有更多...

在 Spark 中使用矩阵最困难的部分是习惯列顺序和行顺序。关键是要记住，Spark ML 使用的底层库与列存储机制配合得更好。这里有一个例子来说明:

1.  给定定义 2x2 矩阵的矩阵定义:

```
val denseMat3 = Matrices.dense(2,2, Array(10.0, 11.0, 20.0, 30.3))
```

2.  矩阵实际上存储为:

```
10.0  20.0 11.0 30.3
```

您可以在值集中从左向右移动，然后在矩阵中从一列移动到另一列。

3.  如您所见，矩阵按行存储的假设与 Spark 方法不一致。从 Spark 的角度来看，以下顺序不正确:

```
 10.0  11.0 20.0 30.3
```

# 请参见

*   构造函数的文档可在[https://spark . Apache . org/docs/latest/API/Java/org/Apache/spark/mllib/linalg/densematrix . html # constructor _ summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/DenseMatrix.html#constructor_summary)获得

*   方法调用的文档可在[https://spark . Apache . org/docs/latest/API/Java/org/Apache/spark/mllib/linalg/densematrix . html # method _ summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/DenseMatrix.html#method_summary)获得

# 使用 Spark 2.0 的稀疏局部矩阵

在这个食谱中，我们专注于稀疏矩阵的创建。在前面的配方中，我们看到了如何声明和存储局部密集矩阵。大量的机器学习问题域可以表示为矩阵中的一组特征和标签。在大规模机器学习问题中(例如，疾病通过大型人口中心的进展、安全欺诈、政治运动建模等)，很大一部分细胞将为 0 或空(例如，当前患有给定疾病的人数与健康人口的对比)。

为了有助于实时存储和高效操作，稀疏局部矩阵专门将单元高效地存储为列表和索引，从而加快加载和实时操作。

# 怎么做...

1.  在 IntelliJ 或您选择的 IDE 中启动一个新项目。确保包含必要的 JAR 文件。
2.  导入矢量和矩阵操作所需的包:

```
 import org.apache.spark.mllib.linalg.distributed.RowMatriximport org.apache.spark.mllib.linalg.distributed.{IndexedRow, IndexedRowMatrix}import org.apache.spark.mllib.linalg.distributed.{CoordinateMatrix, MatrixEntry}import org.apache.spark.sql.{SparkSession}import org.apache.spark.mllib.linalg._import breeze.linalg.{DenseVector => BreezeVector}import Array._import org.apache.spark.mllib.linalg.DenseMatriximport org.apache.spark.mllib.linalg.SparseVector
```

3.  设置 Spark 上下文和应用程序参数，以便 Spark 可以运行-查看本章的第一个配方，了解更多详细信息和变化:

```
val spark = SparkSession.builder.master("local[*]").appName("myVectorMatrix").config("spark.sql.warehouse.dir", ".").getOrCreate()
```

4.  由于我们将稀疏表示存储为压缩列存储(CCS)的方式，稀疏矩阵的创建稍微复杂一点，也称为哈威尔-波音稀疏矩阵格式。请看，*它是如何工作的...*详细解释。

我们声明并创建了一个只有三个非零成员的本地 3x2 稀疏矩阵:

```
 val sparseMat1= Matrices.sparse(3,2 ,Array(0,1,3), Array(0,1,2), Array(11,22,33))
```

让我们检查输出，这样我们就可以完全理解在较低的级别发生了什么。这三个值将被置于(0，0)、(1，1)、(2，1):

```
 println("Number of Columns=",sparseMat1.numCols)println("Number of Rows=",sparseMat1.numRows)println("Number of Active elements=",sparseMat1.numActives)println("Number of Non Zero elements=",sparseMat1.numNonzeros)println("sparseMat1 representation of a sparse matrix and its value=\n",sparseMat1)
```

输出如下:

```
(Number of Columns=,2)
(Number of Rows=,3)
(Number of Active elements=,3)
(Number of Non Zero elements=,3)
sparseMat1 representation of a sparse matrix and its value= 3 x 2 CSCMatrix
(0,0) 11.0
(1,1) 22.0
(2,1) 33.0)
```

为了进一步说明，下面是 Spark 文档页面上显示的 SparseMatrix 的代码(参见以下标题为*的部分，另请参见*)。这是一个有六个非零值的 3x3 矩阵。请注意，声明的顺序是:矩阵大小、列指针、行索引和作为最后一个成员的值:

```
/* from documentation page1.0 0.0 4.00.0 3.0 5.02.0 0.0 6.0**///[1.0, 2.0, 3.0, 4.0, 5.0, 6.0], rowIndices=[0, 2, 1, 0, 1, 2], colPointers=[0, 2, 3, 6]val sparseMat33= Matrices.sparse(3,3 ,Array(0, 2, 3, 6) ,Array(0, 2, 1, 0, 1, 2),Array(1.0, 2.0, 3.0, 4.0, 5.0, 6.0))println(sparseMat33)
```

输出如下:

```
3 x 3 CSCMatrix(0,0) 1.0(2,0) 2.0(1,1) 3.0(0,2) 4.0(1,2) 5.0(2,2) 6.0
```

*   列指针= [0，2，3，6]
*   行索引= [0，2，1，0，1，2]
*   非零值= [1.0，2.0，3.0，4.0，5.0，6.0]

# 它是如何工作的...

根据我们的经验，稀疏矩阵的大部分困难来自于对**压缩行存储** ( **CRS** )和**压缩列存储** ( **CCS** )之间的区别缺乏理解。我们强烈建议读者深入研究这一主题，以清楚地了解差异。

简而言之，火花将 CCS 格式用于转置的目标矩阵:

1.  此方法调用构造函数有两个不同的签名:

在选项二中，我们指出矩阵已经被声明为转置的，所以矩阵将被不同的处理。

2.  方法继承自以下内容，这使得所有例程都可以使用它们的具体方法:
    *   接口类 java.lang.Object
    *   java.io .可序列化
    *   [数]矩阵
3.  有几个感兴趣的方法调用:
    *   根据向量中提供的值生成对角矩阵:

```
static SparseMatrix spdiag(Vector vector)
```

```
static speye(int n)
```

```
boolean isTransposed()
```

```
static SparseMatrix sprand(int numRows, int numCols, java.util.Random rng)
```

```
static SparseMatrix sprandn(int numRows, int numCols, java.util.Random rng)
```

```
SparseMatrix transpose()
```

```
SparseMatrix Copy()
```

```
DenseMatrix toDense()
```

```
Int numNonzeros()
```

```
Double[] Values()
```

# 还有更多...

重申一下，在很多机器学习应用程序中，由于特征空间的大维度特性不是线性分布的，您最终会处理稀疏性。为了说明这一点，我们举一个最简单的例子，我们有 10 个客户表明他们对产品线中的四个主题很感兴趣:

|  | **主题 1** | **主题 2** | **主题 3** | **主题 4** |
| **客户 1** | one | Zero | Zero | Zero |
| **客户 2** | Zero | Zero | Zero | one |
| **客户 3** | Zero | Zero | Zero | Zero |
| **客户 4** | Zero | one | Zero | Zero |
| **客户 5** | one | one | one | Zero |
| **客户 6** | Zero | Zero | Zero | Zero |
| **客户 7** | Zero | Zero | one | Zero |
| **客户 8** | Zero | Zero | Zero | Zero |
| **客户 9** | one | Zero | one | one |
| **客户 10** | Zero | Zero | Zero | Zero |

如您所见，大多数元素都是 0，当我们将客户和主题的数量增加到数千万(M x N)时，将它们存储为密集矩阵是不可取的。稀疏因子和矩阵有助于高效地存储和操作这些稀疏结构。

# 请参见

*   构造函数的文档可在[https://spark . Apache . org/docs/latest/API/Java/org/Apache/spark/mllib/linalg/sparsematrix . html # constructor _ summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/SparseMatrix.html#constructor_summary)获得

*   方法调用的文档可在[https://spark . Apache . org/docs/latest/API/Java/org/Apache/spark/mllib/linalg/sparsematrix . html # method _ summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/SparseMatrix.html#method_summary)获得

# 使用 Spark 2.0 执行矢量算法

在本食谱中，我们探索了在 Spark 环境中使用`Breeze`库进行底层操作的矢量加法。向量允许我们收集特征，然后通过线性代数操作来处理它们，如加、减、转置、点积等。

# 怎么做...

1.  在 IntelliJ 或您选择的 IDE 中启动一个新项目。确保包含必要的 JAR 文件。
2.  导入矢量和矩阵操作所需的包:

```
 import org.apache.spark.mllib.linalg.distributed.RowMatriximport org.apache.spark.mllib.linalg.distributed.{IndexedRow, IndexedRowMatrix}import org.apache.spark.mllib.linalg.distributed.{CoordinateMatrix, MatrixEntry}import org.apache.spark.sql.{SparkSession}import org.apache.spark.mllib.linalg._import breeze.linalg.{DenseVector => BreezeVector}import Array._import org.apache.spark.mllib.linalg.DenseMatriximport org.apache.spark.mllib.linalg.SparseVector
```

3.  设置火花会话和应用程序参数，以便火花可以运行:

```
val spark = SparkSession.builder.master("local[*]").appName("myVectorMatrix").config("spark.sql.warehouse.dir", ".").getOrCreate()
```

4.  我们创建向量:

```
val w1 = Vectors.dense(1,2,3)val w2 = Vectors.dense(4,-5,6)
```

5.  我们将向量从 Spark 公共接口转换为`Breeze`(库)工件，这样我们就可以使用为向量操作提供的一组丰富的操作符:

```
val w1 = Vectors.dense(1,2,3)val w2 = Vectors.dense(4,-5,6) val w3 = new BreezeVector(w1.toArray)//w1.asBreezeval w4=  new BreezeVector(w2.toArray)// w2.asBreezeprintln("w3 + w4 =",w3+w4)println("w3 - w4 =",w3+w4)println("w3 * w4 =",w3.dot(w4)) 
```

6.  让我们看看输出，了解结果。对于向量加法、减法和乘法的操作理解，请参见*如何工作...*本食谱中的部分。

输出如下:

```
w3 + w4 = DenseVector(5.0, -3.0, 9.0)w3 - w4 = DenseVector(5.0, -3.0, 9.0)w3 * w4 =12.0 
```

7.  通过 Breeze 库转换使用稀疏和密集向量的向量操作如下:

```
val sv1 = Vectors.sparse(10, Array(0,2,9), Array(5, 3, 13))val sv2 = Vectors.dense(1,0,1,1,0,0,1,0,0,13)println("sv1 - Sparse Vector = ",sv1)println("sv2 - Dense Vector = ",sv2)println("sv1 * sv2 =", new BreezeVector(sv1.toArray).dot(new BreezeVector(sv2.toArray)))
```

这是一种替代方法，但它有使用私有函数的缺点(参见 Spark 2.x.x 本身的实际源代码)。我们推荐前面介绍的方法:

```
println("sv1  * sve2  =", sv1.asBreeze.dot(sv2.asBreeze))
```

我们看一下输出:

```
sv1 - Sparse Vector =  (10,[0,2,9],[5.0,3.0,13.0]) 
sv2 - Dense  Vector = [1.0,0.0,1.0,1.0,0.0,0.0,1.0,0.0,0.0,13.0] sv1 * sv2 = 177.0
```

# 它是如何工作的...

向量是数学人工产物，它允许我们表达大小和方向。在机器学习中，我们将对象/用户偏好收集到向量和矩阵中，以便利用大规模的分布式操作。

向量是数字的元组，通常对应于为机器学习算法收集的一些属性。向量通常是实数(测量值)，但是很多时候我们使用二进制值来显示特定主题偏好或偏见的存在或不存在。

向量可以被认为是行向量或列向量。列向量表示更适合 ML 思维。列向量表示如下:

![](../images/00047.jpeg)

行向量表示如下:

![](../images/00048.jpeg)

向量加法表示如下:

![](../images/00049.gif)

向量减法表示如下:

![](../images/00050.gif)

向量乘法或“点”积表示如下:

![](../images/00051.jpeg)

![](../images/00052.gif)

# 还有更多...

Spark ML 和 MLlib 库提供的公共接口，无论是用于稀疏向量还是密集向量，目前都缺少进行全向量运算所必需的运算符。我们必须将我们的局部向量转换为`Breeze`库向量，以获得线性代数可用的运算符。

在 Spark 2.0 之前，转换到`Breeze` ( `toBreeze`)的方法是可以使用的，但是现在方法变成了`asBreeze()`并且私有了！快速阅读源代码对于理解新范式是必要的。或许这一变化反映了 Spark 的核心开发人员希望减少对底层`Breeze`库的依赖。

如果您使用的是 Spark 2.0 之前的任何版本(Spark 1.5.1 或 1.6.1)，请使用以下代码片段进行转换。火花前 2.0 示例 1:

```
val w1 = Vectors.dense(1,2,3)val w2 = Vectors.dense(4,-5,6)val w3 = w1.toBreezeval w4= w2.toBreezeprintln("w3 + w4 =",w3+w4)println("w3 - w4 =",w3+w4)println("w3 * w4 =",w3.dot(w4))
```

火花前 2.0 示例 2:

```
println("sv1 - Sparse Vector = ",sv1)println("sv2 - Dense Vector = ",sv2)println("sv1 * sv2 =", sv1.toBreeze.dot(sv2.toBreeze))
```

# 请参见

*   `Breeze`图书馆文件可在[http://www.scalanlp.org/api/breeze/#breeze.package](http://www.scalanlp.org/api/breeze/#breeze.package)获得

*   `Linalg`图书馆文件可在[网站获得](https://spark.apache.org/docs/latest/api/java/allclasses-noframe.html)

# 使用 Spark 2.0 执行矩阵运算

在这个食谱中，我们探索了矩阵运算，如 Spark 中的加法、转置和乘法。更复杂的操作，如逆运算、奇异值分解等，将在以后的章节中介绍。Spark ML 库的原生稀疏矩阵和密集矩阵提供乘法运算符，因此无需显式转换为`Breeze`。

矩阵是分布式计算的主力。收集的最大似然特征可以排列成矩阵结构并按比例操作。很多 ML 方法如 **ALS** ( **交替最小二乘**)和 **SVD** ( **奇异值分解**)都是依靠高效的矩阵和向量运算来实现大规模的机器学习和训练。

# 怎么做...

1.  在 IntelliJ 或您选择的 IDE 中启动一个新项目。确保包含必要的 JAR 文件。
2.  导入矢量和矩阵操作所需的包:

```
 import org.apache.spark.mllib.linalg.distributed.RowMatriximport org.apache.spark.mllib.linalg.distributed.{IndexedRow, IndexedRowMatrix}import org.apache.spark.mllib.linalg.distributed.{CoordinateMatrix, MatrixEntry}import org.apache.spark.sql.{SparkSession}import org.apache.spark.mllib.linalg._import breeze.linalg.{DenseVector => BreezeVector}import Array._import org.apache.spark.mllib.linalg.DenseMatriximport org.apache.spark.mllib.linalg.SparseVector
```

3.  设置火花会话和应用程序参数，以便火花可以运行:

```
val spark = SparkSession.builder.master("local[*]").appName("myVectorMatrix").config("spark.sql.warehouse.dir", ".").getOrCreate()
```

4.  我们创建矩阵:

```
val sparseMat33= Matrices.sparse(3,3 ,Array(0, 2, 3, 6) ,Array(0, 2, 1, 0, 1, 2),Array(1.0, 2.0, 3.0, 4.0, 5.0, 6.0))val denseFeatureVector= Vectors.dense(1,2,1)val denseVec13 = Vectors.dense(5,3,0)
```

5.  将矩阵和向量相乘并打印结果。这是一个非常有用的操作，在大多数 Spark ML 案例中成为一个常见的主题。我们用一个`SparseMatrix`来说明密集、稀疏和矩阵是可以互换的，只有密度(例如非零元素的百分比)和性能才是选择的标准:

```
val result0 = sparseMat33.multiply(denseFeatureVector)println("SparseMat33 =", sparseMat33)println("denseFeatureVector =", denseFeatureVector)println("SparseMat33 * DenseFeatureVector =", result0)
```

输出如下:

```
(SparseMat33 =,3 x 3 CSCMatrix(0,0) 1.0(2,0) 2.0(1,1) 3.0(0,2) 4.0(1,2) 5.0(2,2) 6.0)denseFeatureVector =,[1.0,2.0,1.0]SparseMat33 * DenseFeatureVector = [5.0,11.0,8.0]
```

6.  将`DenseMatrix`乘以`DenseVector`。

这是为了完整性，将帮助用户更容易地遵循矩阵和向量乘法，而不用担心稀疏性:

```
println("denseVec2 =", denseVec13)println("denseMat1 =", denseMat1)val result3= denseMat1.multiply(denseVec13)println("denseMat1 * denseVect13 =", result3) 
```

输出如下:

```
    denseVec2 =,[5.0,3.0,0.0]
    denseMat1 =  23.0  34.3  21.3  
                          11.0  33.0  22.6  
                          17.0  24.5  22.2 
    denseMat1 * denseVect13 =,[217.89,154.0,158.5]

```

7.  我们演示了矩阵的换位，这是一个用列交换行的操作。如果您参与 Spark ML 或数据工程，这是一项重要的操作，几乎每天都在使用。

这里我们演示两个步骤:

```
val transposedMat1= sparseMat1.transposeprintln("transposedMat1=\n",transposedMat1)
```

输出如下:

```

Original sparseMat1 =,3 x 2 CSCMatrix
(0,0) 11.0
(1,1) 22.0
(2,1) 33.0)(transposedMat1=,2 x 3 CSCMatrix
(0,0) 11.0
(1,1) 22.0
(1,2) 33.0)1.0  4.0  7.0  
2.0  5.0  8.0  
3.0  6.0  9.0

```

```
val transposedMat1= sparseMat1.transposeprintln("transposedMat1=\n",transposedMat1)         println("Transposed twice", denseMat33.transpose.transpose) // we get the original back
```

输出如下:

```
Matrix transposed twice=1.0  4.0  7.0  
2.0  5.0  8.0  
3.0  6.0  9.0

```

转换密集矩阵，并通过输出检查新的结果矩阵:

这使得更容易看到行和列索引是如何交换的:

```
val transposedMat2= denseMat1.transposeprintln("Original sparseMat1 =", denseMat1)println("transposedMat2=" ,transposedMat2)Original sparseMat1 =23.0  34.3  21.3  11.0  33.0  22.6  17.0  24.5  22.2 transposedMat2=23.0  11.0  17.0  34.3  33.0  24.5  21.3  22.6  22.2   
```

我们声明两个 2x2 密集矩阵:

```
// Matrix multiplicationval dMat1: DenseMatrix= new DenseMatrix(2, 2, Array(1.0, 3.0, 2.0, 4.0))val dMat2: DenseMatrix = new DenseMatrix(2, 2, Array(2.0,1.0,0.0,2.0))println("dMat1 * dMat2 =", dMat1.multiply(dMat2)) //A x Bprintln("dMat2 * dMat1 =", dMat2.multiply(dMat1)) //B x A   not the same as A xB
```

输出如下:

```
dMat1 =,1.0  2.0  
               3.0  4.0  
dMat2 =,2.0  0.0  
       1.0 2.0 
dMat1 * dMat2 =,4.0   4.0  
                              10.0  8.0
//Note: A x B is not the same as B x A
dMat2 * dMat1 = 2.0   4.0   
                               7.0  10.0

```

# 它是如何工作的...

矩阵可以被认为是向量的列。矩阵是涉及线性代数变换的分布式计算的有力工具。可以通过矩阵收集和操作各种属性或特征表示。

简而言之，矩阵是二维的 *m x n* 数字数组(通常是实数)，其元素可以使用两个元素的下标来引用， *i* 和 *j* :

矩阵表示如下:

![](../images/00053.gif)

矩阵转置表示如下:

![](../images/00054.jpeg)

矩阵乘法表示如下:

![](../images/00055.gif)

矢量矩阵乘法或“点”积表示如下:

![](../images/00056.gif)

![](../images/00057.gif)

*Spark 2.0ML 库中的分布式矩阵*:在接下来的四个食谱中，我们将介绍 Spark 中的四种类型的分布式矩阵。Spark 完全支持由 RDDs 开箱即用烘焙的分布式矩阵。Spark 支持分布式计算这一事实并没有让开发人员在规划算法时不再考虑并行性。

底层关系数据库对存储在矩阵中的底层数据提供完全的并行性和容错性。Spark 与 MLLIB 和 LINALG 捆绑在一起，它们共同为非本地矩阵提供公共接口和支持，这些矩阵由于其规模或链式操作的复杂性而需要完全的集群支持。

Spark ML 提供了四种类型的分布式矩阵来支持并行性:`RowMatrix`、`IndexedRowMatrix`、`CoordinateMatrix`和`BlockMatrix`:

*   `RowMatrix`:表示与 ML 库兼容的面向行的分布式矩阵
*   `IndexedRowMatrix`:类似于`RowMatrix`，还有一个额外的好处就是对行进行索引。这是`RowMatrix`的专用版本，其中矩阵本身是从`IndexedRow`(索引，向量)数据结构的 RDD 创建的。为了可视化它，想象一个矩阵，其中每一行是一对(长，RDD)，配对它们的工作(`zip`函数)是为你完成的。这将允许你在给定的算法中沿着它的计算路径携带指数和 RDD(按比例的矩阵运算)
*   `CoordinateMatrix`:非常有用的坐标格式(例如，投影空间中的 *x* 、 *y* 、 *z* 坐标)
*   `BlockMatrix`:由局部保持矩阵的块组成的分布式矩阵

我们在一个简短的食谱中介绍了这四种类型的创建，然后快速进入一个更复杂的(代码和概念)用例，涉及`RowMatrix`，这是一个典型的 ML 用例，涉及大规模并行分布式矩阵运算(例如，乘法)和局部矩阵。

如果您计划编码或设计大型矩阵运算，则必须深入了解 Spark 内部，例如核心 Spark 以及 staging、流水线和 shuffling 在 Spark 的每个版本中是如何工作的(在每个版本中不断改进和优化)。

在开始大规模矩阵和优化之旅之前，我们还推荐以下内容:

Apache Spark 中矩阵计算和优化的来源可在[http://www . KDD . org/KDD 2016/papers/files/ADF 0163-bosa GH-ZadeHadi . pdf](http://www.kdd.org/kdd2016/papers/files/adf0163-bosagh-zadehAdoi.pdf)和[https://pdf s . semanticscholar . org/a684/fc 37 c 79 a 3276 af 12 a 21 C1 af 8d 47 F2 d6a . pdf](https://pdfs.semanticscholar.org/a684/fc37c79a3276af12a21c1af1ebd8d47f2d6a.pdf)上找到。

Spark 高效大规模分布式矩阵计算的来源见[https://www . computer . org/csdl/proceedings/big-data/2015/9926/00/07364023 . pdf](https://www.computer.org/csdl/proceedings/big-data/2015/9926/00/07364023.pdf)和[http://dl.acm.org/citation.cfm?id=2878336&pre layout = flat](http://dl.acm.org/citation.cfm?id=2878336&preflayout=flat)

在[http://net.pku.edu.cn/~cuibin/Papers/2015-SIGMOD-DMac.pdf](http://net.pku.edu.cn/~cuibin/Papers/2015-SIGMOD-DMac.pdf)和[http://dl.acm.org/citation.cfm?id=2723712](http://dl.acm.org/citation.cfm?id=2723712)可以找到探索高效分布式矩阵计算的矩阵相关性的来源

# 探索火花 2.0 中的行矩阵

在本食谱中，我们探索了由 Spark 提供的`RowMatrix`设施。`RowMatrix`，顾名思义，是一个面向行的矩阵，缺点是缺少一个可以定义并贯穿`RowMatrix`计算生命周期的索引。这些行是提供分布式计算和容错弹性的关系数据库。

该矩阵由多行本地向量组成，这些向量通过关系数据库进行并行化和分布。简而言之，每一行都是一个 RDD，但是列的总数将受到局部向量的最大大小的限制。在大多数情况下，这不是一个问题，但我们觉得我们应该提到它来完成。

# 怎么做...

1.  在 IntelliJ 或您选择的 IDE 中启动一个新项目。确保包含必要的 JAR 文件。
2.  导入矢量和矩阵操作所需的包:

```
 import org.apache.spark.mllib.linalg.distributed.RowMatriximport org.apache.spark.mllib.linalg.distributed.{IndexedRow, IndexedRowMatrix}import org.apache.spark.mllib.linalg.distributed.{CoordinateMatrix, MatrixEntry}import org.apache.spark.sql.{SparkSession}import org.apache.spark.mllib.linalg._import breeze.linalg.{DenseVector => BreezeVector}import Array._import org.apache.spark.mllib.linalg.DenseMatriximport org.apache.spark.mllib.linalg.SparseVector
```

3.  设置火花上下文和应用程序参数，以便火花可以运行。更多细节和变化见本章第一个配方:

```
val spark = SparkSession.builder.master("local[*]").appName("myVectorMatrix").config("spark.sql.warehouse.dir", ".").getOrCreate()
```

4.  作为输出返回的警告语句的数量和时间因分布式矩阵的分布式计算(非顺序)的性质而异。消息与实际输出的交错取决于执行路径，这导致输出难以读取。在下面的陈述中，为了清楚起见，我们将`log4j`消息从警告(警告-开箱即用)提升为错误(错误)。我们建议开发人员详细遵循警告消息，以掌握这些操作的并行性，并充分理解 RDD 的概念:

```
import Log4J logger and the levelimport org.apache.log4j.Loggerimport org.apache.log4j.Level
```

将级别设置为错误:

```
Logger.getLogger("org").setLevel(Level.ERROR)Logger.getLogger("akka").setLevel(Level.ERROR)
```

原来盒子是这样出来的

```
Logger.getLogger("org").setLevel(Level.WARN)Logger.getLogger("akka").setLevel(Level.WARN)
```

5.  我们定义了两种密集向量的序列数据结构。

密集局部向量的标量序列，将成为分布式`RowMatrix`的数据:

```
val dataVectors = Seq(Vectors.dense(0.0, 1.0, 0.0),Vectors.dense(3.0, 1.0, 5.0),Vectors.dense(0.0, 7.0, 0.0))
```

密集局部向量的 Scala 序列，将作为局部单位矩阵的数据。线性代数的快速检查表明，任何矩阵乘以一个单位矩阵将产生相同的原始矩阵(即 *A x I = A* )。我们喜欢用恒等式矩阵来证明乘法是有效的，并且在原始矩阵上计算的原始统计量与原始 *x* 恒等式相同:

```
val identityVectors = Seq(Vectors.dense(1.0, 0.0, 0.0),Vectors.dense(0.0, 1.0, 0.0),Vectors.dense(0.0, 0.0, 1.0))
```

6.  通过将底层密集向量并行化到 RDDs 来创建我们的第一个分布式矩阵。

展望未来，我们的密集向量现在是 RDD 支持的新分布式向量中的行(也就是说，完全支持所有 RDD 操作！).

取原始序列(由向量组成)并将其转化为 rdd。我们将在下一章详细介绍 rdd。在这一条语句中，我们将本地数据结构变成了分布式工件:

```
val distMat33 = new RowMatrix(sc.parallelize(dataVectors))
```

我们计算一些基本的统计数据来验证`RowMatrix`的构造是否正确。需要记住的一点是，密集的向量现在是行而不是列(这是许多混乱的来源):

```
println("distMatt33 columns - Count =", distMat33.computeColumnSummaryStatistics().count)println("distMatt33 columns - Mean =", distMat33.computeColumnSummaryStatistics().mean)println("distMatt33 columns - Variance =", distMat33.computeColumnSummaryStatistics().variance)println("distMatt33 columns - CoVariance =", distMat33.computeCovariance())
```

输出如下:

The statistics calculated (mean, variance, min, max, and so on) are for each column and not the entire matrix. This is the reason you see three numbers for mean and variance which corresponds to each column.

```
    distMatt33 columns - Count =            3
    distMatt33 columns - Mean =             [ 1.0, 3.0, 1.66 ]
    (distMatt33 columns - Variance =      [ 3.0,12.0,8.33 ]
    (distMatt33 columns - CoVariance = 3.0   -3.0  5.0                
                                                            -3.0  12.0  -5.0               
                                                             5.0   -5.0  8.33  
```

7.  在这一步中，我们根据单位向量的数据结构创建本地矩阵。要记住的一点是，乘法需要一个局部矩阵，而不是一个分布矩阵。请查看通话签名进行验证。我们使用`map`、`toArray`和`flatten`运算符创建一个 Scala 展平数组数据结构，该数据结构可用作创建局部矩阵的参数之一，如下一步所示:

```
val flatArray = identityVectors.map(x => x.toArray).flatten.toArray dd.foreach(println(_))
```

8.  我们创建局部矩阵作为单位矩阵，这样我们就可以验证乘法 *A * I = A* :

```
 val dmIdentity: Matrix = Matrices.dense(3, 3, flatArray)
```

9.  我们将分布式矩阵乘以本地矩阵，创建一个新的分布式矩阵。这是一个典型的用例，最终将一个又高又瘦的局部矩阵与一个大规模分布式矩阵相乘，以实现所得矩阵的规模和继承的降维:

```
val distMat44 = distMat33.multiply(dmIdentity)println("distMatt44 columns - Count =", distMat44.computeColumnSummaryStatistics().count)println("distMatt44 columns - Mean =", distMat44.computeColumnSummaryStatistics().mean)println("distMatt44 columns - Variance =", distMat44.computeColumnSummaryStatistics().variance)println("distMatt44 columns - CoVariance =", distMat44.computeCovariance())
```

10.  比较第 7 步和第 8 步，我们看到实际上操作进行得正确，我们可以通过描述性统计和协变矩阵验证 *A x I = A* 使用分布式局部矩阵。

输出如下:

```
distMatt44 columns - Count = 3distMatt44 columns - Mean = [ 1.0, 3.0, 1.66 ]distMatt44 columns - Variance = [ 3.0,12.0,8.33 ]distMatt44 columns - CoVariance = 3.0 -3.0 5.0                                   -3.0 12.0 -5.0                                    5.0 -5.0 8.33
```

# 它是如何工作的...

1.  此方法构造函数的签名如下:
    *   `RowMatrix(RDD<Vector> rows)`
    *   `RowMatrix(RDD<Vector>, long nRows, Int nCols)`
2.  方法继承自以下内容，这使得所有例程都可以使用它们的具体方法:
    *   接口类 java.lang.Object
    *   实现以下接口:
        *   记录
        *   分布式矩阵
3.  有几个感兴趣的方法调用:
    *   计算描述性统计数据，如平均值、最小值、最大值、方差等:

*k* 为主成分数

*k* 是要保留的前导奇异值的数量( *0 < k < =n* )。

# 还有更多...

当您使用稀疏或密集元素(向量或块矩阵)时，还有一些额外的因素需要考虑。乘以一个局部矩阵通常是更可取的，因为它不需要昂贵的洗牌。

虽然在处理大型矩阵时，简单和控制是首选，但四种类型的分布式矩阵简化了设置和操作。四种类型中的每一种都有优点和缺点，必须根据这三个标准来考虑和权衡:

*   底层数据的稀疏性或密度
*   使用这些设备时会发生的洗牌。
*   处理边缘情况时的网络容量利用率

出于上述原因，特别是为了减少分布式矩阵运算(例如，两个行矩阵相乘)期间所需的混洗(即网络瓶颈)，我们更喜欢与本地矩阵相乘，以显著减少混洗。虽然这一开始看起来有点违背直觉，但实际上对于我们遇到的情况来说是可以的。这样做的原因是，当我们将一个大矩阵乘以一个向量或又高又瘦的矩阵时，得到的矩阵足够小，可以放入内存。

另一个注意点是返回的信息(行或局部矩阵)必须足够小，这样才能返回给驱动程序。

对于导入，我们需要本地和分布式矢量和矩阵导入，这样我们就可以使用 ML 库。否则，默认情况下将使用 Scala 向量和矩阵。

# 请参见

*   构造函数的文档可在[https://spark . Apache . org/docs/latest/API/Java/org/Apache/spark/mllib/linalg/distributed/row matrix . html # constructor _ summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/distributed/RowMatrix.html#constructor_summary)获得

*   方法调用的文档可在[https://spark . Apache . org/docs/latest/API/Java/org/Apache/spark/mllib/linalg/distributed/row matrix . html # method _ summary](https://spark.apache.org/docs/1.5.2/api/java/org/apache/spark/mllib/linalg/distributed/RowMatrix.html#method_summary)获得

# 探索 Spark 2.0 中的分布式索引存储矩阵

在这个食谱中，我们涵盖了`IndexRowMatrix`，这是我们在本章中涵盖的第一个专门的分布式矩阵。`IndexedRowMatrix`的主要优点是索引可以和行(RDD)一起携带，行就是数据本身。

在`IndexRowMatrix`的情况下，我们有一个由开发人员定义的索引，它与一个给定的行永久配对，这对随机访问的情况非常有用。该索引不仅有助于随机访问，还用于在执行`join()`操作时识别行本身。

# 怎么做...

1.  在 IntelliJ 或您选择的 IDE 中启动一个新项目。确保包含必要的 JAR 文件。
2.  导入矢量和矩阵操作所需的包:

```
    import org.apache.spark.mllib.linalg.distributed.RowMatriximport org.apache.spark.mllib.linalg.distributed.{IndexedRow, IndexedRowMatrix}import org.apache.spark.mllib.linalg.distributed.{CoordinateMatrix, MatrixEntry}import org.apache.spark.sql.{SparkSession}import org.apache.spark.mllib.linalg._import breeze.linalg.{DenseVector => BreezeVector}import Array._import org.apache.spark.mllib.linalg.DenseMatriximport org.apache.spark.mllib.linalg.SparseVector
```

3.  设置火花上下文和应用程序参数，以便火花可以运行。更多细节和变化见本章第一个配方:

```
val spark = SparkSession.builder.master("local[*]").appName("myVectorMatrix").config("spark.sql.warehouse.dir", ".").getOrCreate()
```

4.  我们从原始数据向量开始，然后构建一个合适的数据结构(即行索引)来存放索引和向量。
5.  然后，我们继续构建`IndexedRowMatrix`并显示访问。对于那些使用过 LIBSVM 的人来说，这种格式接近于标签和向量工件，但有一个扭曲，即标签现在是索引(也就是长索引)。
6.  从一系列向量开始，作为`IndexedRowMatrix`的基础数据结构:

```
val dataVectors = Seq(Vectors.dense(0.0, 1.0, 0.0),Vectors.dense(3.0, 1.0, 5.0),Vectors.dense(0.0, 7.0, 0.0))
```

7.  从一系列向量开始，作为`IndexedRowMatrix`的基础数据结构:

```
   val distInxMat1 
 = sc.parallelize( List( IndexedRow( 0L, dataVectors(0)), IndexedRow( 1L, dataVectors(1)), IndexedRow( 1L, dataVectors(2)))) 
println("distinct elements=", distInxMat1.distinct().count()) 
```

输出如下:

```
(distinct elements=,3)
```

# 它是如何工作的...

索引是一个长数据结构，它提供了一个有意义的行索引，对应于`IndexedRowMatrix`的每一行。实现背后的动力是 rdd，它从一开始就提供了并行环境中分布式弹性数据结构的所有优势。

`IndexedRowMatrix`的主要优点是索引可以和数据本身所在的行(RDD)一起携带。当我们有`join()`操作需要一个键来选择特定的数据行时，我们可以定义索引并将其与数据(矩阵的实际行)一起携带的事实非常有用。

下图显示了`IndexedRowMatrix`的示意图，这将有助于澄清主题:

![](../images/00058.jpeg)

定义可能不清楚，因为您需要重复定义索引和数据来组成原始矩阵。下面的代码片段显示了重复(索引、数据)的内部列表，以供参考:

```
List( IndexedRow( 0L, dataVectors(0)), IndexedRow( 1L, dataVectors(1)), IndexedRow( 1L, dataVectors(2)))
```

其他操作类似于上一个配方中的`IndexRow`矩阵。

# 请参见

*   构造函数的文档可在[https://spark . Apache . org/docs/latest/API/Java/org/Apache/spark/mllib/linalg/distributed/indexedrowmatrix . html # constructor _ summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/distributed/IndexedRowMatrix.html#constructor_summary)获得

*   方法调用的文档可在[https://spark . Apache . org/docs/latest/API/Java/org/Apache/spark/mllib/linalg/distributed/indexedrowmatrix . html # method _ summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/distributed/IndexedRowMatrix.html#method_summary)获得

# 探索 Spark 2.0 中的分布式坐标矩阵

在本食谱中，我们介绍了第二种形式的专用分布式矩阵。当处理 ML 实现需要处理通常很大的 3D 坐标系(x，y，z)时，这非常方便。将坐标数据结构封装成分布式矩阵是一种方便的方法。

# 怎么做...

1.  在 IntelliJ 或您选择的 IDE 中启动一个新项目。确保包含必要的 JAR 文件。
2.  导入矢量和矩阵操作所需的包:

```
 import org.apache.spark.mllib.linalg.distributed.RowMatriximport org.apache.spark.mllib.linalg.distributed.{IndexedRow, IndexedRowMatrix}import org.apache.spark.mllib.linalg.distributed.{CoordinateMatrix, MatrixEntry}import org.apache.spark.sql.{SparkSession}import org.apache.spark.mllib.linalg._import breeze.linalg.{DenseVector => BreezeVector}import Array._import org.apache.spark.mllib.linalg.DenseMatriximport org.apache.spark.mllib.linalg.SparseVector
```

3.  设置火花上下文和应用程序参数，以便火花可以运行。更多细节和变化见本章第一个配方:

```
val spark = SparkSession.builder.master("local[*]").appName("myVectorMatrix").config("spark.sql.warehouse.dir", ".").getOrCreate()
```

4.  我们从`MatrixEntry`的一个 SEQ 开始，它对应于每个坐标，将被放置在`CoordinateMatrix`中。请注意，条目不能再是实数了(毕竟它们是 x，y，z 坐标):

```
val CoordinateEntries = Seq(MatrixEntry(1, 6, 300),MatrixEntry(3, 1, 5),MatrixEntry(1, 7, 10))
```

5.  我们实例化调用并构造`CoordinateMatrix`。我们需要一个额外的步骤来创建 rdd，我们已经在构造函数中通过使用用于并行化的 Spark 上下文(即`sc.parallelize`)展示了这一点:

```
val distCordMat1 = new CoordinateMatrix( sc.parallelize(CoordinateEntries.toList)) 
```

6.  我们打印第一个`MatrixEntry`来验证矩阵元素。我们将在下一章讨论 RDDs，但是注意`count()`本身是一个动作，使用`collect()`是多余的:

```
 println("First Row (MatrixEntry) =",distCordMat1.entries.first())
```

输出如下:

```
    First Row (MatrixEntry) =,MatrixEntry(1,6,300.0)

```

# 它是如何工作的...

1.  `CoordinateMatrix`是一个专门的矩阵，其中每个条目都是一个坐标系或三个数字的元组(长、长、长对应于 *x* 、 *y* 、 *z* 坐标)。一个相关的数据结构是`MatrixEntry`，其中坐标将被存储，然后放置在`CoordinateMatrix`的一个位置。下面的代码片段演示了`MaxEntry`的使用，这本身似乎就是一个混淆的来源。

2.  下图显示了`CoordinateMatrix`的示意图，这将有助于澄清主题:

![](../images/00059.jpeg)

包含三个坐标的代码片段是:

```
MatrixEntry(1, 6, 300), MatrixEntry(3, 1, 5), MatrixEntry(1, 7, 10)
```

`MaxEntry`只不过是一个保持坐标所需的结构。除非你需要修改 Spark 提供的源代码(见 GitHub `CoordinateMatrix.scala`)来定义一个更专业的容器(压缩)，否则没有必要再进一步理解它:

稀疏坐标系还带来了高效存储、检索和操作的额外好处(例如，所有设备相对于位置的安全威胁矩阵)。

# 请参见

*   构造函数的文档可在[https://spark . Apache . org/docs/latest/API/Java/org/Apache/spark/mllib/linalg/distributed/coordinationmatrix . html # constructor _ summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/distributed/CoordinateMatrix.html#constructor_summary)获得

*   方法调用的文档可在[https://spark . Apache . org/docs/latest/API/Java/org/Apache/spark/mllib/linalg/distributed/coordinationmatrix . html # method _ summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/distributed/CoordinateMatrix.html#method_summary)获得

*   MaxEntry 的文档可在[http://spark.apache.org/docs/latest/api/java/index.html](http://spark.apache.org/docs/latest/api/java/index.html)获得

# 探索 Spark 2.0 中的分布式块矩阵

在这个食谱中，我们探索`BlockMatrix`，这是一个很好的抽象，也是其他矩阵块的占位符。简而言之，它是可以作为单元访问的其他矩阵(矩阵块)的矩阵。

我们通过将`CoordinateMatrix`转换为`BlockMatrix`来快速查看一个简化的代码片段，然后快速检查它的有效性，并访问它的一个属性来显示它设置正确。BlockMatrix 代码需要更长的时间来设置，它需要一个现实生活中的应用程序(没有足够的空间)来演示和展示它的属性。

# 怎么做...

1.  在 IntelliJ 或您选择的编辑器中启动一个新项目，并确保所有必要的 JAR 文件(Scala 和 Spark)对您的应用程序可用。
2.  导入矢量和矩阵操作所需的包:

```
import org.apache.spark.mllib.linalg.distributed.RowMatriximport org.apache.spark.mllib.linalg.distributed.{IndexedRow, IndexedRowMatrix}import org.apache.spark.mllib.linalg.distributed.{CoordinateMatrix, MatrixEntry}import org.apache.spark.sql.{SparkSession}import org.apache.spark.mllib.linalg._import breeze.linalg.{DenseVector => BreezeVector}import Array._import org.apache.spark.mllib.linalg.DenseMatriximport org.apache.spark.mllib.linalg.SparseVector
```

3.  设置火花上下文和应用程序参数，以便火花可以运行。有关更多细节和变化，请参见本章中的第一个配方:

```
val spark = SparkSession.builder.master("local[*]").appName("myVectorMatrix").config("spark.sql.warehouse.dir", ".").getOrCreate()
```

4.  快速创建一个`CoordinateMatrix`作为转换的基础:

```
val distCordMat1 = new CoordinateMatrix( sc.parallelize(CoordinateEntries.toList))
```

5.  我们取`CoordinateMatrix`转换成`BlockMatrix`:

```
val distBlkMat1 =  distCordMat1.toBlockMatrix().cache() 
```

6.  对于这种类型的矩阵，这是一个非常有用的调用。在现实生活中，在继续计算之前，通常需要检查设置:

```
distBlkMat1.validate() 
println("Is block empty =", distBlkMat1.blocks.isEmpty()) 
```

输出如下:

```
Is block empty =,false
```

# 它是如何工作的...

矩阵块将被定义为(int，int，matrix)的元组。这个矩阵的独特之处在于，它具有`Add()`和`Multiply()`功能，可以将另一个`BlockMatrix`作为分布式矩阵的第二个参数。虽然一开始设置有点混乱(尤其是在数据到达的时候)，但有一些助手功能可以帮助您验证您的工作，并确保`BlockMatrix`设置正确。这种类型的矩阵可以转换为本地、`IndexRowMatrix`和`CoordinateMatrix`。`BlockMatrix`最常见的用例之一是拥有一个`BlockMatrix`的`CoordinateMatrices`。

# 请参见

*   构造函数的文档可在[https://spark . Apache . org/docs/latest/API/Java/org/Apache/spark/mllib/linalg/distributed/blockmatrix . html # constructor _ summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/distributed/BlockMatrix.html#constructor_summary)获得

*   方法调用的文档可在[https://spark . Apache . org/docs/latest/API/Java/org/Apache/spark/mllib/linalg/distributed/blockmatrix . html # method _ summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/distributed/BlockMatrix.html#method_summary)获得