# 前言

Education is not the learning of facts, but the training of the mind to think. - Albert Einstein

数据是我们这个时代的新硅，而机器学习，加上受生物学启发的认知系统，是核心基础，不仅促成而且加速了第四次工业革命的诞生。这本书献给我们的父母，他们通过极端的艰难和牺牲，使我们的教育成为可能，并教会我们永远践行善良。

*Apache Spark 2.x 机器学习食谱*由四位背景不同的朋友精心打造，他们带来了跨多个行业和学科的丰富经验。这个团队对手头的主题有丰富的经验。这本书不仅是关于友谊，也是关于支撑Spark和机器学习的科学。我们想把我们的想法放在一起，为社区写一本书，这本书不仅结合了 Spark 的 ML 代码和现实世界的数据集，还提供了与上下文相关的解释、参考资料和阅读材料，以便更深入地理解和促进进一步的研究。这本书反映了当我们开始使用 Apache Spark 时，我们的团队希望拥有的东西。

我自己对机器学习和人工智能的兴趣始于 80 年代中期，当时我有机会阅读了两个重要的人工产物，这两个产物碰巧在 1986 年 2 月的《人工智能》杂志第 28 卷第 1 期上被连续列出。虽然对我这一代的工程师和科学家来说，这是一段漫长的旅程，但幸运的是，弹性分布式计算、云计算、图形处理器、认知计算、优化和高级机器学习方面的进步已经实现了几十年的梦想。所有这些进步对于当前一代的 ML 爱好者和数据科学家来说都是可以实现的。

我们生活在历史上最罕见的时期之一——多个技术和社会学趋势在同一时间点融合的时期。云计算的弹性以及对 ML 和深度学习网络的内置访问将为创造和占领新市场提供一系列全新的机会。Apache Spark 作为近乎实时的弹性分布式计算和数据虚拟化的通用语言(T0)或 T2 通用语言(T3)的出现，为智能公司提供了大规模使用最大似然技术的机会，而无需在专业数据中心或硬件上进行大量投资。

*Apache Spark 2.x 机器学习食谱*是 Apache Spark 机器学习 API 最全面的治疗方法之一，Spark 的精选子组件为您提供了在掌握机器学习和 Apache Spark 高端职业之前所需的基础。这本书的编写目标是提供清晰性和可访问性，它反映了我们自己的经验(包括阅读源代码)和使用 Apache Spark 的学习曲线，Apache Spark 是从 Spark 1.0 开始的。

*Apache Spark 2.x 机器学习烹饪书*通过从业者的视角，生活在 Apache Spark、机器学习和 Scala 的交汇点上，从业者不仅要了解代码，还要了解给定 Spark ML 算法或 API 的细节、理论和内部工作方式，才能在新经济中建立成功的职业生涯。

这本书通过将可下载的现成运行的 Apache Spark ML 代码食谱与背景、可操作的理论、参考资料、研究和现实生活数据集相结合，将烹饪书的格式提升到了一个全新的水平，以帮助读者理解 Spark 为机器学习库提供的广泛设施背后的*是什么、*、*如何、*以及*为什么要*。这本书从奠定成功所需的基础开始，然后迅速发展，涵盖了 Apache Spark 中所有有意义的 ML 算法。

# 这本书涵盖了什么

[第 1 章](01.html#PNV60-4d291c9fed174a6992fd24938c2f9c77)、*使用 Scala 的 Spark 实用机器学习*，涵盖了使用机器学习和使用 Apache Spark 编程安装和配置真实开发环境。使用截图，它会引导您下载、安装和配置 Apache Spark 和 IntelliJ IDEA 以及必要的库，这些库将反映开发人员在现实环境中的桌面。然后，它会识别并列出 40 多个具有真实数据集的数据存储库，这些数据集可以帮助读者试验并进一步推进代码配方。最后一步，我们在 Spark 上运行我们的第一个 ML 程序，然后提供如何将图形添加到机器学习程序中的指导，这些将在后续章节中使用。

[第二章](02.html#1T1400-4d291c9fed174a6992fd24938c2f9c77)、*刚刚够用的机器学习线性代数用 Spark* 讲述了线性代数(向量和矩阵)的使用，这是机器学习中一些最有纪念意义的著作的基础。它提供了 Apache Spark 中可用的 DenseVector、SparseVector 和 matrix 设施的综合处理，并在本章中提供了菜谱。它提供了本地和分布式矩阵的配方，包括行矩阵、索引矩阵、坐标矩阵和块矩阵，以提供对该主题的详细解释。我们包括这一章是因为只有通过逐行阅读大部分源代码，并理解矩阵分解和向量/矩阵算法在 Spark 中更复杂的算法下是如何工作的，才能掌握 Spark 和 ML/MLlib。

[第 3 章](03.html#3EK180-4d291c9fed174a6992fd24938c2f9c77)， *Spark 的机器学习三大数据火枪手-完美结合，*提供了对 Apache spark 中弹性分布式数据操纵和扯皮三大支柱的端到端处理。从实践者的角度来看，这一章包含了涵盖关系数据库、数据框架和数据集设施的详细方法。通过 17 个食谱、例子、参考文献和解释的详尽列表，它为在机器学习科学中建立成功的职业生涯奠定了基础。本章提供了功能性(代码)和非功能性(SQL 接口)编程方法，以巩固知识库，反映一级公司成功的 Spark ML 工程师的真实需求。

[第 4 章](04.html#5UNGG0-4d291c9fed174a6992fd24938c2f9c77)、*实现健壮机器学习系统的常见方法*，通过 16 个简短但切中要点的代码方法，涵盖并排除了大多数机器学习系统中常见的任务，读者可以在自己的真实系统中使用。它涵盖了一系列技术，从标准化数据到评估模型输出，通过 Spark 的 ML/MLlib 工具使用最佳实践度量，读者可能不容易看到这些工具。这是我们日常工作中在大多数情况下使用的食谱的组合，但为了节省空间和其他食谱的复杂性，它们被单独列出。

[第 5 章](05.html#8CTUK0-4d291c9fed174a6992fd24938c2f9c77)，*Spark 2.0 中带回归和分类的实用机器学习-第一部分*，是探索 Apache Spark 中分类和回归的两章的第一章。本章从广义线性回归(GLM)开始，将其扩展到 Lasso，Ridge，Spark 中提供了不同类型的优化。本章接着讨论等渗回归、多层感知器(神经网络)生存回归和一个 vs-Rest 分类器。

[第 6 章](06.html#9PO920-4d291c9fed174a6992fd24938c2f9c77)，*Spark 2.0 中回归分类的实用机器学习-第二部分*，是回归分类两章中的第二章。本章涵盖了基于 RDD 的回归系统，从线性，逻辑和脊套索，使用随机梯度体面和 BFGS 优化在Spark。最后三个方法涵盖了支持向量机(SVM)和朴素贝叶斯，最后是一个详细的 ML 管道的方法，这些管道在 Spark ML 生态系统中获得了突出的地位。

[第 7 章](07.html#B4LIC0-4d291c9fed174a6992fd24938c2f9c77)、*可随 Spark* 扩展的推荐引擎，讲述了如何利用 Spark 的 ML 库设施来探索您的数据集并构建电影推荐引擎。在深入研究 Spark 中的协作过滤技术之前，它使用了一个大数据集和一些食谱以及图表和文字记录来探索推荐者的各种方法。

[第 8 章](08.html#BUDHI0-4d291c9fed174a6992fd24938c2f9c77)、*用 Apache Spark 2.0* 进行无监督聚类，涵盖了无监督学习中使用的技术，如 KMeans、used、and Expectation)、Power 迭代聚类(PIC)和潜在 Dirichlet 分配(LDA)，同时也涵盖了为什么以及如何帮助读者理解核心概念。使用 Spark Streaming，这一章从一个实时的 KMeans 聚类方法开始，通过无监督的方式将输入流分类到有标签的类中。

[第 9 章](09.html#D0O5Q0-4d291c9fed174a6992fd24938c2f9c77)、*优化-带着梯度下降下山*，这是一个独特的章节，引导你完成优化，因为它适用于机器学习。它从一个封闭形式的公式和二次函数优化(例如，成本函数)开始，到使用梯度下降(GD)来从头开始解决回归问题。这一章通过使用 Scala 代码开发读者的技能集，同时提供了如何从头开始编码和理解随机下降(GD)的深入解释，有助于深入了解引擎盖下方。这一章以 Spark 的一个 ML API 结束，以实现我们从头开始编写的相同概念。

[第 10 章](10.html#DMM2O0-4d291c9fed174a6992fd24938c2f9c77)、*用决策树和集成模型*构建机器学习系统，涵盖了使用 Spark 的机器库进行深度分类和回归的树和集成模型。我们使用三个真实世界的数据集来探索使用决策树、随机森林树和梯度增强树的分类和回归问题。除了一步一步探索 Apache Spark 机器库的即插即用代码食谱之外，本章还对这些方法进行了深入的解释。

[第 11 章](11.html#EN3LS0-4d291c9fed174a6992fd24938c2f9c77)、*大数据中的高维诅咒*，揭开了降维的艺术和科学的神秘面纱，并提供了 Spark 的 ML/MLlib 库的完整覆盖，这在大规模机器学习中促进了这一重要概念。这一章对理论(什么和为什么)进行了充分和深入的介绍，然后继续介绍 Spark 中可供读者使用的两种基本技术(如何)。这一章包括单值分解(SVD)，它与第二章有很好的联系，然后继续深入研究主成分分析(PCA)，并编写代码。

[第 12 章](12.html#F89000-4d291c9fed174a6992fd24938c2f9c77)*使用 Spark 2.0 ML 库*实现文本分析，介绍了 Spark 中可用于大规模实现文本分析的各种技术。它从基础(如术语频率(TF)和相似性技术(如 Word2Vec))开始，提供了全面的处理，并继续为现实生活中的 Spark ML 项目分析维基百科的完整转储。本章最后深入讨论了在 Spark 中使用潜在狄利克雷分配实现潜在语义分析(LSA)和主题建模(LDA)的方法和代码。

[第 13 章](13.html#G12EK0-4d291c9fed174a6992fd24938c2f9c77)、*Spark stream 和机器学习库*首先介绍了 Spark stream 和未来的发展方向，然后继续提供基于 RDD 的(DStream)和结构化流的配方，以建立基线。在写这本书的时候，这一章接着介绍了 Spark 中所有可用的 ML 流算法。本章提供了代码，并展示了如何实现流数据帧和流数据集，然后在进入流知识管理(无监督学习)和流线性模型(如使用真实数据集的线性和逻辑回归)之前，介绍了用于调试的 queueStream。

# 这本书你需要什么

请使用软件列表文档中的详细信息。

要执行本书中的方法，您需要一个运行 Windows 7 及以上版本或 Mac 10 的系统，并安装以下软件:

*   Apache Spark 2.x
*   Oracle JDK SE 1.8.x
*   捷脑智能社区版 2016.2.X 或更高版本
*   面向 IntelliJ 2016.2.x 的 Scala 插件
*   Jfreechart 1.0.19 版
*   微风-核心 0.12
*   Cloud9 1.5.0 JAR
*   19/19200
*   Hadoop-流媒体 2.2.0
*   Jcommon 1.0.23
*   Lucene-分析仪-通用 6.0.0
*   Lucene-核心-6.0.0
*   Spark流水槽组件 2.0.0
*   Spark流-卡夫卡-组件 2.0.0

本书的代码包中提供的软件列表中提到了该软件的硬件要求。

# 这本书是给谁的

这本书是为 Scala 开发人员编写的，他们对机器学习技术有相当好的接触和理解，但是缺乏 Spark 的实际实现。假设有机器学习算法的扎实知识，以及一些用 Scala 实现 ML 算法的实践经验。但是，您不需要熟悉 Spark ML 库和生态系统。

# 部分

在这本书里，你会发现几个经常出现的标题(准备，如何做…，如何工作…，还有更多…，另见)。为了给出如何完成配方的明确说明，我们使用以下部分:

# 准备好

本节告诉您配方中的预期内容，并描述如何设置配方所需的任何软件或任何初步设置。

# 怎么做…

本节包含遵循配方所需的步骤。

# 它是如何工作的…

这一部分通常包括对前一部分发生的事情的详细解释。

# 还有更多…

本节包含关于配方的附加信息，以便读者更好地了解配方。

# 请参见

本节提供了该配方的其他有用信息的有用链接。

# 约定

在这本书里，你会发现许多区分不同种类信息的文本样式。以下是这些风格的一些例子和对它们的意义的解释。文本中的码字、数据库表名、文件夹名、文件名、文件扩展名、路径名、伪 URL、用户输入和 Twitter 句柄如下所示:“Mac 用户注意，我们在 Mac 机器上的`/Users/USERNAME/spark/spark-2.0.0-bin-hadoop2.7/`目录中安装了 Spark 2.0。”

代码块设置如下:

```scala
object HelloWorld extends App { 
   println("Hello World!") 
 } 
```

任何命令行输入或输出都编写如下:

```scala
 mysql -u root -p
```

**新名词**和**重要词语**以粗体显示。您在屏幕上看到的单词，例如在菜单或对话框中看到的单词，会出现在如下文本中:“配置全局库。选择 Scala SDK 作为您的全局库。”

Warnings or important notes appear like this. Tips and tricks appear like this.

# 读者反馈

我们随时欢迎读者的反馈。让我们知道你对这本书的看法——你喜欢或不喜欢什么。读者反馈对我们来说很重要，因为它有助于我们开发出你真正能从中获益的标题。要给我们发送一般反馈，只需发送电子邮件`feedback@packtpub.com`，并在您的邮件主题中提及书名。如果您对某个主题有专业知识，并且对写作或投稿感兴趣，请参见我们位于[www.packtpub.com/authors](http://www.packtpub.com/authors)的作者指南。

# 客户支持

现在，您已经自豪地拥有了一本书，我们有许多东西可以帮助您从购买中获得最大收益。

# 下载示例代码

你可以从你在[http://www.packtpub.com](http://www.packtpub.com)的账户下载这本书的示例代码文件。如果您在其他地方购买了这本书，您可以访问[http://www.packtpub.com/support](http://www.packtpub.com/support)并注册，以便将文件直接通过电子邮件发送给您。您可以按照以下步骤下载代码文件:

1.  使用您的电子邮件地址和密码登录或注册我们的网站。
2.  将鼠标指针悬停在顶部的“支持”选项卡上。
3.  点击代码下载和勘误表。
4.  在搜索框中输入图书的名称。
5.  选择要下载代码文件的书籍。
6.  从您购买这本书的下拉菜单中选择。
7.  点击代码下载。

您也可以通过点击图书网页上的“代码文件”按钮来下载代码文件。可以通过在搜索框中输入图书名称来访问此页面。请注意，您需要登录您的 Packt 帐户。下载文件后，请确保使用最新版本的解压缩文件夹:

*   视窗系统的 WinRAR / 7-Zip
*   zipeg/izp/un ARX for MAC
*   适用于 Linux 的 7-Zip / PeaZip

该书的代码包也托管在 GitHub 上，网址为[https://GitHub . com/packt publishing/Apache-Spark-2x-机器学习-Cookbook](https://github.com/PacktPublishing/Apache-Spark-2x-Machine-Learning-Cookbook) 。我们还有来自丰富的书籍和视频目录的其他代码包，可在获得。看看他们！

# 正误表

尽管我们尽了最大努力来确保我们内容的准确性，但错误还是会发生。如果你在我们的某本书里发现一个错误，也许是文本或代码中的错误，如果你能向我们报告，我们将不胜感激。通过这样做，你可以让其他读者免受挫折，并帮助我们改进这本书的后续版本。如果您发现任何勘误表，请访问[http://www.packtpub.com/submit-errata](http://www.packtpub.com/submit-errata)，选择您的书籍，点击勘误表提交表格链接，并输入您的勘误表的详细信息。一旦您的勘误表得到验证，您的提交将被接受，勘误表将上传到我们的网站或添加到该标题勘误表部分下的任何现有勘误表列表中。要查看之前提交的勘误表，请前往[https://www.packtpub.com/books/content/support](https://www.packtpub.com/books/content/support)并在搜索栏中输入图书名称。所需信息将出现在勘误表部分。

# 海盗行为

互联网上版权材料的盗版是所有媒体的一个持续问题。在 Packt，我们非常重视版权和许可证的保护。如果您在互联网上遇到任何形式的我们作品的非法拷贝，请立即向我们提供位置地址或网站名称，以便我们寻求补救。请通过`copyright@packtpub.com`联系我们，获取疑似盗版资料的链接。我们感谢您在保护我们的作者方面的帮助，以及我们为您带来有价值内容的能力。

# 问题

如果您对本书的任何方面有问题，可以在`questions@packtpub.com`联系我们，我们将尽最大努力解决问题。