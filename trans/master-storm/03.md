# 风暴并行性和数据分区

在前两章中，我们已经介绍了 Storm、Storm 的安装以及开发示例拓扑。 在本章中，我们将重点介绍拓扑在多台 Storm 计算机/节点上的分布。 本章涵盖以下几点：

*   拓扑的并行性
*   如何在代码级别配置并行性
*   风暴集群中不同类型的流分组
*   有保证的消息处理
*   刻度元组

# 拓扑的并行度

并行性是指将作业分布在多个节点/实例上，其中每个实例都可以独立工作，并有助于数据处理。 让我们首先看一下负责 Storm 集群并行性的进程/组件。

# 工作进程

风暴拓扑跨风暴群集中的多个管理节点执行。 集群中的每个节点都可以运行一个或多个称为**工作进程**的 JVM，它们负责处理拓扑的一部分。

工作进程特定于其中一个特定拓扑，并且可以执行该拓扑的多个组件。 如果同时运行多个拓扑，则它们都不会共享任何工作器，从而在拓扑之间提供一定程度的隔离。

# 执行者 / 遗嘱执行人 / 实施者

在每个工作进程中，可以有多个线程执行部分拓扑。 这些线程中的每一个都称为**执行器**。 执行器只能执行其中一个组件，即拓扑中的任何喷嘴或螺栓。

每个执行器都是单个线程，只能串行执行分配给它的任务。 在拓扑运行时，可以动态更改为管口或螺栓定义的执行器数量，这意味着您可以轻松控制拓扑中各种组件的并行度。

# 要求极高 / 考验 / 使费尽心机 / 分派任务

这是 Storm 中最细粒度的任务执行单元。 每个任务都是一个喷嘴或螺栓的实例。 定义 Storm 拓扑时，可以指定每个管口和螺栓的任务数。 一旦定义了任务数，就不能在运行时更改组件的任务数。 每个任务可以单独执行，也可以与相同类型的另一个任务一起执行，或者与同一喷嘴或螺栓的另一个实例一起执行。

下图描述了工作进程、执行器和任务之间的关系。 在下图中，每个组件有两个执行器，每个执行器承载不同数量的任务。

此外，如您所见，为一个组件定义了两个执行器和八个任务(每个执行器承载四个任务)。 如果您不能从此配置中获得足够的性能，您可以轻松地将组件的执行器数量更改为四个或八个以提高性能，并且任务将在该组件的所有执行器之间均匀分布。 下图显示了执行者、任务和工作者之间的关系：

![](../images/00021.jpeg)

# 在代码级别配置并行性

Storm 提供了一个 API，用于在代码级别设置工作进程数、执行器数和任务数。 以下部分显示如何在代码级配置并行性。

我们可以使用`org.apache.storm.Config`类的`setNumWorkers`方法在代码级别设置工作进程的数量。 以下是实际显示这些设置的代码片段：

```scala
Config conf = new Config(); 
conf.setNumWorkers(3); 
```

在上一章中，我们将工作人员数量配置为三个。 Storm 将为`SampleStormTopology`和`SampleStormClusterTopology`拓扑分配三个工作者。

我们可以通过在`org.apache.storm.topology.TopologyBuilder`类的`setSpout(args,args,parallelism_hint)`或`setBolt(args,args,parallelism_hint)`方法中传递`parallelism_hint`参数来设置代码级别的执行器数量。 以下是实际显示这些设置的代码片段：

```scala
builder.setSpout("SampleSpout", new SampleSpout(), 2); 
// set the bolt class 
builder.setBolt("SampleBolt", new SampleBolt(), 4).shuffleGrouping("SampleSpout"); 
```

在上一章中，我们为`SampleSpout`设置了`parallelism_hint=2`，为`SampleBolt`设置了`parallelism_hint=4`。 执行时，Storm 将为`SampleSpout`分配两个执行器，为`SampleBolt`分配四个执行器。

我们可以配置可以在 Executor 内部执行的任务数量。 以下是实际显示这些设置的代码片段：

```scala
builder.setSpout("SampleSpout", new SampleSpout(), 2).setNumTasks(4); 
```

在前面的代码中，我们已经配置了`SampleSpout`的两个执行器和四个任务。 对于`SampleSpout`，Storm 将为每个执行器分配两个任务。 默认情况下，如果用户未在代码级别设置任务数，Storm 将为每个执行器运行一个任务。

# 工作进程、执行器和任务分配

假设为拓扑设置的工作进程数为 3，`SampleSpout`的执行器数为 3，`SampleBolt`的执行器数为 3。 此外，`SampleBolt`的任务数为 6，这意味着每个`SampleBolt`执行器将有两个任务。 下图显示了拓扑在运行时的样子：

![](../images/00022.jpeg)

# 重新平衡拓扑的并行度

正如上一章所解释的，Storm 的一个关键特性是它允许我们在运行时修改拓扑的并行性。 在运行时更新拓扑并行性的过程称为**重新平衡**。

有两种方法可以重新平衡拓扑：

*   使用 Storm Web UI
*   使用 Storm CLI

上一章介绍了 Storm Web UI。 本节介绍如何使用 Storm CLI 工具重新平衡拓扑。 以下是我们需要在 Storm CLI 上执行以重新平衡拓扑的命令：

```scala
> bin/storm rebalance [TopologyName] -n [NumberOfWorkers] -e [Spout]=[NumberOfExecutos] -e [Bolt1]=[NumberOfExecutos] [Bolt2]=[NumberOfExecutos]
```

`rebalance`命令将首先在消息超时期间停用拓扑，然后在 Storm 群集中平均重新分配工作进程。 几秒钟或几分钟后，拓扑将恢复到以前的激活状态，并重新启动输入流的处理。

# 重新平衡 SampleStormClusterTopology 拓扑的并行度

让我们首先通过在管理计算机上运行`jps`命令来检查 Storm 集群中正在运行的工作进程的数量：

在 Supervisor-1 上运行`jps`命令：

```scala
> jps
24347 worker
23940 supervisor
24593 Jps
24349 worker  
```

两个工作进程被分配给-1\f25 Supervisor-1\f6 机器。

现在，在 Supervisor-2 上运行`jps`命令：

```scala
> jps
24344 worker
23941 supervisor
24543 Jps
```

一个工作进程分配给-2\f25 Supervisor-2\f6 机器。

Storm 群集上共有三个工作进程在运行。

让我们尝试将`SampleStormClusterTopology`重新配置为使用两个工作进程，将`SampleSpout`重新配置为使用四个执行器，并将`SampleBolt`重新配置为使用四个执行器：

```scala
> bin/storm rebalance SampleStormClusterTopology -n 2 -e SampleSpout=4 -e SampleBolt=4

0     [main] INFO  backtype.storm.thrift  - Connecting to Nimbus at nimbus.host.ip:6627
58   [main] INFO  backtype.storm.command.rebalance  - Topology SampleStormClusterTopology is rebalancing
```

在管理计算机上重新运行`jps`命令以查看工作进程的数量。

在 Supervisor-1 上运行`jps`命令：

```scala
> jps
24377 worker
23940 supervisor
24593 Jps 
```

在 Supervisor-2 上运行`jps`命令：

```scala
> jps
24353 worker
23941 supervisor
24543 Jps  
```

在本例中，前面显示了两个工作进程。 第一个工作进程分配给 Supervisor-1，另一个分配给 Supervisor-2。 根据系统上运行的拓扑数量和每个主控引擎上可用插槽的数量，工作人员的分布可能会有所不同。 理想情况下，Storm 会尝试在所有节点之间均匀分配负载。

# 风暴集群中不同类型的流分组

定义拓扑时，我们用螺栓处理流的数量创建一个计算图。 在更细粒度的级别上，每个螺栓执行拓扑中的多个任务。 因此，特定螺栓的每个任务将仅从订阅的流中获得元组的子集。

Storm 中的流分组提供了对订阅流的螺栓的许多任务中如何进行这种元组划分的完全控制。 可以在使用`org.apache e.storm.topology.TopologyBuilder.setBolt`方法定义螺栓时返回的`org.apache.storm.topology.InputDeclarer`实例上定义螺栓分组。

Storm 支持以下类型的流分组。

# 混洗分组

随机分组以均匀、随机的方式跨任务分布元组。 每个任务将处理相同数量的元组。 如果您希望跨任务均匀分配处理负载，并且不需要任何数据驱动分区，则此分组非常理想。 这是 Storm 中最常用的分组之一。

# 字段分组

此分组使您能够根据元组中的某些字段对流进行分区。 例如，如果您希望特定用户的所有 tweet 都转到单个任务，则可以按以下方式使用按用户名的字段分组对 tweet 流进行分区：

```scala
builder.setSpout("1", new TweetSpout()); 
builder.setBolt("2", new TweetCounter()).fieldsGrouping("1", new Fields("username")) 
```

由于字段分组是*散列(字段)%(No.。 任务数)*，它不能保证每个任务都会得到要处理的元组。 例如，如果您在字段上应用了字段分组，例如*X*，并且只有两个可能的值*A*和*B*，并为螺栓创建了两个任务，则*散列(A)%2*和*散列(B)%2*都可能返回相等的值，这将导致所有元组都被路由到单个任务，而另一个完全被路由到单个任务

字段分组的另一个常见用法是联接流。 由于分区仅基于字段值，而不是流类型，因此我们可以使用任何公共连接字段连接两个流。 字段的名称不必相同。 例如，在订单处理域中，我们可以连接`Order`流和`ItemScanned`流，以查看订单何时完成：

```scala
builder.setSpout("1", new OrderSpout()); 
builder.setSpount("2", new ItemScannedSpout()); 
builder.setBolt("joiner", new OrderJoiner()) 
.fieldsGrouping("1", new Fields("orderId")) 
.fieldsGrouping("2", new Fields("orderRefId")); 
```

由于流上的连接因应用程序的不同而有所不同，因此您将自己定义连接，比如在一个时间窗口内连接，这可以通过组合字段分组来实现。

# 所有分组

All Grouping 是一个特殊的分组，它不划分元组，而是将它们复制到所有任务，也就是说，每个元组将被发送到每个螺栓的任务进行处理。

所有分组的一个常见用例是向螺栓发送信号。 例如，如果您要对流进行某种过滤，您可以将过滤参数传递或更改给所有螺栓，方法是通过一个流将这些参数发送给所有螺栓，该流由所有螺栓的所有任务使用 All 分组订阅。 另一个例子是向聚合螺栓中的所有任务发送重置消息。

# 全局分组

全局分组不对流进行分区，而是将完整的流发送到螺栓的任务(最小的 ID)。通常情况下，当您需要拓扑中的 Reduce 阶段时，您希望将拓扑中先前步骤的结果合并到单个螺栓中。

全局分组乍看起来可能是多余的，因为如果您只有一个输入流，则可以通过将螺栓的并行度定义为 1 来获得相同的结果。 但是，当您有多个数据流通过不同的路径进入时，您可能只希望减少其中一个数据流，而其他数据流则是并行进程。

例如，考虑以下拓扑。 在这种情况下，您可能希望将来自**Bolt C**的所有元组合并到单个**Bolt D**任务中，同时可能仍然希望**Bolt E**到**Bolt D**的元组具有并行性：

![](../images/00023.jpeg)

# 直接分组

在直接分组中，发射器决定每个元组的处理位置。 例如，假设我们有一个日志流，并且我们希望根据资源类型处理每个日志条目，这些条目将由特定的螺栓任务处理。 在这种情况下，我们可以使用直接分组。

直接分组只能用于直接流。 要将流声明为直接流，请使用`backtype.storm.topology.OutputFieldsDeclarer.declareStream`方法，该方法接受`boolean`参数。 一旦有了要发射到的直接流，就可以使用`backtype.storm.task.OutputCollector.emitDirect`而不是 emit 方法来发射它。 `emitDirect`方法接受`taskId`参数来指定任务。 您可以使用`backtype.storm.task.TopologyContext.getComponentTasks`方法获取组件的任务数。

# 本地或随机分组

如果元组源任务和目标螺栓任务在同一工作进程中运行，则使用此分组将仅在同一工作进程上运行的目标任务之间充当混洗分组，从而最大限度地减少任何网络跳跃，从而提高性能。

如果源工作进程上没有正在运行的目标螺栓任务，则此分组的行为将类似于前面提到的随机分组。

# 无分组

当您不关心元组在不同任务之间的划分方式时，不使用分组。 从 Storm 0.8 开始，这相当于使用混洗分组。

# 自定义分组

如果前面的分组都不符合您的用例，您可以通过实现`backtype.storm.grouping.CustomStreamGrouping`接口来定义您自己的自定义分组。

下面是一个根据元组中的类别对流进行分区的自定义分组示例：

```scala
public class CategoryGrouping implements CustomStreamGrouping, Serializable { 
  private static final Map<String, Integer> categories = ImmutableMap.of 
  ( 
    "Financial", 0,  
    "Medical", 1,  
    "FMCG", 2,  
    "Electronics", 3 
  ); 

  private int tasks = 0; 

  public void prepare(WorkerTopologyContext context, GlobalStreamId stream, List<Integer> targetTasks)  
  { 
    tasks = targetTasks.size(); 
  } 

  public List<Integer> chooseTasks(int taskId, List<Object> values) { 
    String category = (String) values.get(0); 
    return ImmutableList.of(categories.get(category) % tasks); 
  } 
} 
```

下图以图形方式表示风暴分组：

![](../images/00024.jpeg)

# 有保证的消息处理

在 Storm 拓扑中，喷嘴发出的单个元组可能会导致在拓扑的后期阶段生成多个元组。 例如，考虑以下拓扑：

![](../images/00025.jpeg)

这里，**喷嘴 A**发出元组**T(A)**，该元组由分别发出元组**T(AB)**和**T(AC)**的**螺栓 B**和**螺栓 C**处理。 因此，当处理完元组**T(A)**产生的所有元组--即元组树**T(A)**、**T(AB)**和**T(AC)**时，我们说元组已经处理完毕。

当元组树中的一些元组由于运行时错误或可为每个拓扑配置的超时而无法处理时，Storm 会将其视为失败的元组。

以下是 Storm 保证消息处理所需的六个步骤：

1.  用唯一的消息 ID 标记喷嘴发出的每个元组。这可以通过使用`org.apache.storm.spout.SpoutOutputColletor.emit`方法来完成，该方法接受`messageId`参数。 Storm 使用此消息 ID 跟踪由此元组生成的元组树的状态。 如果使用不带`messageId`参数的 emit 方法之一，Storm 将不会跟踪它进行完整处理。 当消息处理完成后，Storm 将使用与发出元组时使用的相同的`messageId`发送确认。
2.  SPOUT 实现的一种通用模式是，它们从消息队列(比方说 RabbitMQ)读取消息，将元组生成到拓扑中进行进一步处理，然后在收到元组已完成处理的确认后将消息出列。
3.  当拓扑中的某个螺栓在处理消息的过程中需要生成新的元组时，例如，前面拓扑中的**螺栓 B**，那么它应该发出与它从 spout 获得的原始元组锚定的新的元组。 这可以通过使用`org.apache.storm.task.OutputCollector`类中的重载 emit 方法来实现，该类接受锚定元组作为参数。 如果要从同一个输入元组发出多个元组，则锚定每个传出元组。

4.  无论何时处理完螺栓的 Execute 方法中的元组，都要使用`org.apache.storm.task.OutputCollector.ack`方法发送确认。 当确认到达发出的喷嘴时，您可以安全地将消息标记为正在处理，并将其从消息队列中出列(如果有的话)。
5.  同样，如果在处理元组时出现问题，则应该使用`org.apache.storm.task.OutputCollector.fail`方法发回失败信号，以便 Storm 可以重播失败的消息。
6.  Storm Bolts 中处理的一般模式之一是处理中的元组，发出新的元组，并在 Execute 方法结束时发送确认。 Storm 提供了在 Execute 方法结束时自动发送确认的`org.apache.storm.topology.base.BasicBasicBolt`类。 如果要发出失败信号，请从 Execute 方法中抛出`org.apache.storm.topology.FailedException`。

此模型产生至少一次的消息处理语义，并且您的应用程序应该准备好处理某些消息将被多次处理的场景。 Storm 还提供只需一次的消息处理语义，我们将在[第 5 章](05.html#318PC0-6149dd15e07b443593cc93f2eb31ee7b)、*三叉戟拓扑和使用*中讨论这一点。

尽管您可以使用这里提到的方法在 Storm 中实现一些有保证的消息处理，但始终需要考虑您是否真的需要它，因为您可以通过冒着 Storm 无法完全处理某些消息的风险来获得巨大的性能提升。 这是您在设计应用程序时可以考虑的权衡。

# 刻度元组

在某些用例中，在执行某些操作之前，螺栓需要缓存数据几秒钟，例如每隔 5 秒清除缓存，或者在单个请求中向数据库中插入一批记录。

刻度元组是我们可以在每个螺栓级别配置的系统生成(Storm 生成)元组。 开发人员可以在编写螺栓时在代码级别配置 Tick 元组。

我们需要覆盖螺栓中的以下方法以启用记号元组：

```scala
@Override 
public Map<String, Object> getComponentConfiguration() { 
  Config conf = new Config(); 
  int tickFrequencyInSeconds = 10; 
  conf.put(Config.TOPOLOGY_TICK_TUPLE_FREQ_SECS, 
  tickFrequencyInSeconds); 
  return conf; 
} 
```

在前面的代码中，我们已将刻度元组时间配置为 10 秒。 现在，Storm 将在每 10 秒后开始生成一个滴答元组。

此外，我们还需要在螺栓的 Execute 方法中添加以下代码来标识元组的类型：

```scala
@Override 
public void execute(Tuple tuple) { 
  if (isTickTuple(tuple)) { 
    // now you can trigger e.g. a periodic activity 
  } 
  else { 
    // do something with the normal tuple 
  } 
} 

private static boolean isTickTuple(Tuple tuple) { 
  return
  tuple.getSourceComponent().equals(Constants.SYSTEM_COMPONENT_ID) && tuple.getSourceStreamId().equals(Constants.SYSTEM_TICK_STREAM_ID); 
} 
```

如果`isTickTuple()`方法的输出为真，则输入元组为刻度元组。 否则，它是由前一个螺栓发出的普通元组。

Be aware that tick tuples are sent to bolts/spouts just like regular tuples, which means they will be queued behind other tuples that a bolt/spout is about to process via its `execute()` or `nextTuple()` method, respectively. As such, the time interval you configure for tick tuples is, in practice, served on a best-effort basis. For instance, if a bolt is suffering from high execution latency--for example, due to being overwhelmed by the incoming rate of regular, non-tick tuples--then you will observe that the periodic activities implemented in the bolt will get triggered later than expected.

# 简略的 / 概括的 / 简易判罪的 / 简易的

在本章中，我们介绍了如何定义 Storm 的并行性、如何在多个节点之间分配作业以及如何在螺栓的多个实例之间分配数据。 本章还介绍了两个重要特性：有保证的消息处理和记号元组。

在下一章中，我们将介绍有关 Storm 的三叉戟高级抽象。 三叉戟主要是用来解决实时交易问题的，而这并不是普通的 Storm 所能解决的。