# 零、前言

近年来，收集、存储和分析的数据量呈爆炸式增长，特别是与 Web 和移动设备上的活动相关的数据量，以及通过传感器网络从物理世界收集的数据。 虽然大规模数据存储、处理、分析和建模以前是最大的机构(如 Google、Yahoo！、Facebook、Twitter 和 Salesforce)的领域，但许多组织越来越多地面临如何处理海量数据的挑战。

当面对如此大量的数据和实时使用这些数据的普遍需求时，人力系统很快就会变得不可行。 这导致了所谓的大数据和机器学习系统的兴起，这些系统从这些数据中学习，以做出自动化决策。

为了应对在没有任何令人望而却步的成本的情况下处理越来越大规模的数据这一挑战，Google、Yahoo！、Amazon 和 Facebook 等公司出现了新的开源技术，这些技术旨在通过在计算机集群中分布数据存储和计算来使处理海量数据变得更容易。

其中应用最广泛的是 Apache Hadoop，这使得存储大量数据(通过 Hadoop 分布式文件系统，或 HDFS)和对这些数据运行计算(通过 Hadoop MapReduce，一个跨计算机集群中多个节点并行执行计算任务的框架)变得更加容易和便宜。

然而，MapReduce 有一些重要的缺点，包括启动每个作业的开销很高，并且依赖于将中间数据和计算结果存储到磁盘，这两者都使得 Hadoop 相对不适合迭代或低延迟性质的用例。 Apache Spark 是一个全新的分布式计算框架，旨在针对低延迟任务进行优化，并将中间数据和结果存储在内存中，从而解决 Hadoop 框架的一些主要缺陷。 Spark 提供了一个干净、功能强大且易于理解的 API 来编写应用程序，并且与 Hadoop 生态系统完全兼容。

此外，Spark 提供了 Scala、Java、Python 和 R 的原生 API。Scala 和 Python API 分别允许在 Spark 应用程序中直接使用 Scala 或 Python 语言的所有优点，包括使用相关的解释器进行实时、交互式的探索。 Spark 本身现在提供了分布式机器学习和数据挖掘模型的工具包(Spark MLlib 在 1.6 中，Spark ML 在 2.0 中)，该模型正在大力开发中，并且已经包含了用于许多常见机器学习任务的高质量、可伸缩和高效的算法，我们将在本书中深入研究其中一些。

将机器学习技术应用于海量数据集是具有挑战性的，主要是因为大多数著名的机器学习算法都不是为并行体系结构设计的。 在许多情况下，设计这样的算法并不是一件容易的事情。 机器学习模型的本质通常是迭代的，因此 Spark 对于这个用例很有吸引力。 虽然并行计算有许多相互竞争的框架，但 Spark 是少数几个将速度、可伸缩性、内存处理和容错与编程简便性和灵活、表现力和强大的 API 设计相结合的框架之一。

在本书中，我们将关注机器学习技术在现实世界中的应用。 虽然我们可能会简要研究机器学习算法的一些理论方面和机器学习所需的数学，但本书通常会采取实用的应用方法，重点是使用示例和代码来说明如何有效地使用 Spark 和 MLlib 的功能，以及其他著名的和免费提供的机器学习和数据分析包，以创建有用的机器学习系统。

# 这本书涵盖了哪些内容

[第 1 章](01.html)，*使用 Spark*启动和运行，展示了如何安装和设置 Spark 框架的本地开发环境，以及如何使用 Amazon EC2 在云中创建 Spark 集群。 我们将介绍 Spark 编程模型和 API，并使用 Scala、Java 和 Python 创建一个简单的 Spark 应用程序。

[第 2 章](02.html)，*《机器学习的数学》*提供了机器学习的数学介绍。 理解数学及其许多技术对于很好地把握算法的内部工作原理并获得最佳结果是非常重要的。

[第 3 章](03.html)，*设计机器学习系统*，给出了一个机器学习系统的实际用例。 基于这个说明性的用例，我们将为 Spark 中的一个智能系统设计一个高级架构。

[第 4 章](04.html)，*使用 Spark*获取、处理和准备数据，详细说明如何获取机器学习系统中使用的数据，特别是从各种免费和公开的来源获取数据。 我们将学习如何使用可用的工具、库和 Spark 的功能来处理、清理原始数据，并将其转换为可在机器学习模型中使用的特性。

[第 5 章](05.html)，*使用 Spark*构建推荐引擎，讨论基于协作过滤方法创建推荐模型。 此模型将用于向给定用户推荐项目，以及创建与给定项目相似的项目列表。 这里将介绍评估推荐模型性能的标准指标。

[第 6 章](07.html)，*使用 Spark*构建分类模型，详细介绍了如何创建二进制分类模型，以及如何将标准性能评估度量用于分类任务。

[第 7 章](07.html)，*使用 Spark*构建回归模型，介绍如何创建回归模型，扩展了第 6 章*使用 Spark*构建分类模型中创建的分类模型。 这里将详细介绍回归模型的性能评估指标。

[第 8 章](06.html)，*使用 Spark*构建集群模型，探索如何创建集群模型以及如何使用相关的评估方法。 您将学习如何分析和可视化生成的集群。

[第 9 章](09.html)，*使用 Spark*降维，带我们了解从数据中提取底层结构并降维的方法。 您将学习一些常见的降维技术，以及如何应用和分析它们。 您还将了解如何将生成的数据表示用作另一个机器学习模型的输入。

[第 10 章](10.html)，*使用 Spark*进行高级文本处理介绍了处理大规模文本数据的方法，包括从文本中提取特征和处理文本数据中典型的高维特征的技术。

[第 11 章](11.html)，*Spark Streaming 的实时机器学习*概述了 Spark Streaming，以及它如何适应在线和增量学习方法，以便在数据流上应用机器学习。

[第 12 章](12.html)，*Spark ML*管道 API 提供了一组统一的 API，这些 API 构建在数据帧之上，帮助用户创建和调整机器学习管道。

# 这本书你需要什么？

在这本书中，我们假设您有一些使用 Scala 或 Python 编程的基本经验，并且有一些机器学习、统计和数据分析的基本知识。

# 这本书是写给谁的？

本书面向对大规模机器学习方法感兴趣但不一定熟悉 Spark 的入门级到中级数据科学家、数据分析师、软件工程师和从事机器学习或数据挖掘的从业者。 您可能对统计或机器学习软件(可能包括 MATLAB、SCRICIT-LEARN、Mahout、R、Weka 等)或分布式系统(包括一些 Hadoop)有一定的经验。

# 公约

在本书中，您将发现许多区分不同类型信息的文本样式。 下面是这些风格的一些例子，并解释了它们的含义。

文本、数据库表名、文件夹名、文件名、文件扩展名、路径名、虚拟 URL、用户输入和 Twitter 句柄中的代码字如下所示：“Spark 将运行 Spark 的用户脚本放在`bin`目录中。”

代码块设置如下：

```scala
val conf = new SparkConf()
.setAppName("Test Spark App")
.setMaster("local[4]")
val sc = new SparkContext(conf)

```

任何命令行输入或输出都如下所示：

```scala
>tar xfvz spark-2.1.0-bin-hadoop2.7.tgz
>cd spark-2.1.0-bin-hadoop2.7

```

**新术语**和**重要单词**以粗体显示。 您在屏幕上看到的文字(例如，在菜单或对话框中)显示在文本中，如下所示：“您可以通过单击帐户|安全凭证|访问凭证从 AWS 主页获取这些文字。”

Warnings or important notes appear in a box like this. Tips and tricks appear like this.

# 读者反馈

欢迎读者的反馈。 让我们知道你对这本书的看法-你喜欢什么或不喜欢什么。 读者反馈对我们很重要，因为它可以帮助我们开发出真正能让您获得最大收益的图书。 要向我们发送一般反馈，只需向
发送电子邮件至`feedback@packtpub.com`，并在邮件主题中提及书名。 如果有一个你有专长的主题，并且你有兴趣写一本书或为一本书做贡献，请参阅我们的作者指南，网址是：C[www.Packtpub.com/Authors](http://www.packtpub.com/authors)。

# 客户支持

现在您已经成为 Packt 图书的拥有者，我们有很多东西可以帮助您从购买中获得最大价值。

# 下载示例代码

您可以从您的帐户[http://www.packtpub.com](http://www.packtpub.com)下载本书的示例代码文件。 如果您在其他地方购买了本书，您可以访问[http://www.packtpub.com/support](http://www.packtpub.com/support)并注册，以便将文件通过电子邮件直接发送给您。

您可以通过以下步骤下载代码文件：

1.  使用您的电子邮件地址和密码登录或注册我们的网站。
2.  将鼠标指针悬停在顶部的支持选项卡上。
3.  单击 Code Downloads&Errata(代码下载和勘误表)。
4.  在搜索框中输入图书的名称。
5.  选择要为其下载代码文件的图书。
6.  从您购买本书的下拉菜单中选择。
7.  单击 Code Download(代码下载)。

下载文件后，请确保使用以下最新版本解压缩或解压缩该文件夹：

*   WinRar/7-用于 Windows 的 Zip
*   适用于 Mac 的 Zipeg/iZip/UnRarX
*   Linux 版 7-Zip/PeaZip

该书的代码包也托管在 giHub 的[https://github.com/PacktPublishing/Machine-Learning-with-Spark-Second-Edition](https://github.com/PacktPublishing/Machine-Learning-with-Spark-Second-Edition)上。 我们还在[https://github.com/PacktPublishing/](https://github.com/PacktPublishing/)上提供了我们丰富的图书和视频目录中的其他代码包。 看看他们！

# 下载本书的彩色图片

我们还为您提供了一个 PDF 文件，其中包含本书中使用的屏幕截图/图表的彩色图像。 彩色图像将帮助您更好地了解输出中的更改。 您可以从[https://www.packtpub.com/sites/default/files/downloads/MachineLearningwithSparkSecondEdition_ColorImages.pdf](https://www.packtpub.com/sites/default/files/downloads/MachineLearningwithSparkSecondEdition_ColorImages.pdf)下载此文件。

# 错误 / 排错 / 勘误表

虽然我们已经竭尽全力确保内容的准确性，但错误还是会发生。 如果您在我们的一本书中发现错误--可能是文本或代码中的错误--如果您能向我们报告，我们将不胜感激。 通过这样做，您可以将其他读者从挫折中解救出来，并帮助我们改进本书的后续版本。 如果您发现任何勘误表，请访问[http://www.packtpub.com/submit-errata](http://www.packtpub.com/submit-errata)进行报告，选择您的图书，单击勘误表提交表链接，然后输入勘误表的详细信息。 一旦您的勘误表被核实，您提交的勘误表将被接受，勘误表将被上传到我们的网站或添加到该书目勘误表部分下的任何现有勘误表列表中。

要查看之前提交的勘误表，请转到[https://www.packtpub.com/books/content/support](https://www.packtpub.com/books/content/support)，并在搜索字段中输入图书名称。 所需信息将显示在勘误表部分下。

# 海盗行为 / 剽窃 / 著作权侵害 / 非法翻印

在互联网上盗版版权材料是所有媒体持续存在的问题。 在 Packt，我们非常重视版权和许可证的保护。 如果您在互联网上发现任何形式的非法复制我们的作品，请立即提供我们的位置、地址或网站名称，以便我们采取补救措施。

请通过`copyright@packtpub.com`联系我们，并附上疑似盗版材料的链接。

我们感谢您在保护我们的作者方面的帮助，以及我们为您提供有价值内容的能力。

# 问题 / 不确定 / 异议 / 难题

如果您对本书的任何方面有任何问题，可以通过`questions@packtpub.com`与我们联系，我们将尽最大努力解决问题。