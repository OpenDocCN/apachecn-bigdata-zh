# 前言

Apache Spark 是一个开源的并行处理框架，已经存在了很长时间。Apache Spark 的众多用途之一是跨集群计算机的数据分析应用程序。

这本书将帮助您实现一些实用的和经过验证的技术，以改善 Apache Spark 的编程和管理方面。您不仅将学习如何使用 Spark 和 Python API 创建具有大数据的高性能分析，还将发现测试、免疫和并行化 Spark 作业的技术。

本书涵盖了 PySpark 的安装和设置、RDD 运营、大数据清理和争论，以及将数据汇总和汇总成有用的报告。您将学习如何从所有流行的数据托管平台获取数据，包括 HDFS、Hive、JSON 和 S3，并使用 PySpark 处理大型数据集，以获得实用的大数据体验。这本书还将帮助你在本地机器上制作原型，并随后继续处理生产和大规模生产中的混乱数据。

# 这本书是给谁的

这本书是为开发人员、数据科学家、业务分析师或任何需要可靠地分析大量大规模真实世界数据的人准备的。无论您的任务是创建公司的商业智能功能，还是为您的机器学习模型创建出色的数据平台，或者希望使用代码来放大业务的影响，这本书都是为您准备的。

# 这本书涵盖了什么

[第 1 章](00.html)、*安装 Pyspark 并设置您的开发环境*，涵盖了 Pyspark 的安装以及学习 Spark 中的核心概念，包括**弹性分布式数据集** ( **RDDs** )、SparkContext 和 Spark 工具，如 SparkConf 和 SparkShell。

[第](00.html)章 [2](00.html) 、*使用 RDDs 将您的大数据带入 Spark 环境*解释了如何使用 RDDs 将您的大数据带入 Spark 环境，使用各种工具来交互和修改这些数据，以便提取有用的见解。

[第三章](00.html)、*大数据清理和与 Spark 笔记本*的角力，讲述了如何在笔记本应用中使用 Spark，从而促进 RDDs 的有效使用。

[第 4 章](00.html)、*将数据汇总和汇总为有用的报告*，介绍了如何使用 map 和 reduce 函数计算平均值，执行更快的平均值计算，以及使用具有键/值对数据点的透视表。

[第 5 章](00.html)、*使用 MLlib* 进行强大的探索性数据分析，检查 Spark 使用包括线性回归和支持向量机在内的模型执行回归任务的能力。

[第 6 章](00.html)、*用 SparkSQL* 给你的大数据加上结构，解释了如何用 SparkSQL 模式操作数据框架，并使用 Spark DSL 为结构化数据操作构建查询。

[第 7 章](00.html)、*转换和动作*，查看 Spark 转换以推迟计算，然后考虑应该避免的转换。我们还将使用`reduce`和`reduceByKey`方法从数据集进行计算。

[第 8 章](00.html)、*不可变设计*解释了如何使用 DataFrame 操作进行转换，以期讨论高度并发环境中的不变性。

[第九章](00.html)、*避免洗牌降低运营费用*，涵盖洗牌和应该使用的 Spark API 的操作。然后，我们将测试在 Apache Spark 中导致洗牌的操作，以了解应该避免哪些操作。

[第 10 章](00.html)、*以正确的格式保存数据*解释了如何以正确的格式保存数据，以及如何使用 Spark 的标准 API 以纯文本保存数据。

[第 11 章](00.html)、*使用火花键/值 API* ，讨论键/值对上可用的转换。我们将查看键/值对上的操作，并查看键/值数据上可用的分区器。

[第 12 章](00.html)*测试 Apache Spark Jobs* ，进一步详细介绍了在不同版本的 Spark 中测试 Apache Spark Jobs。

[第 13 章](00.html)、*利用 Spark GraphX API* ，讲述了如何利用 Spark GraphX API。我们将使用边缘应用编程接口和顶点应用编程接口进行实验。

# 充分利用这本书

这本书需要一些 PySpark、Python、Java 和 Scala 的基本编程经验。

# 下载示例代码文件

你可以从你在[www.packt.com](http://www.packt.com)的账户下载这本书的示例代码文件。如果您在其他地方购买了这本书，您可以访问[www.packt.com/support](http://www.packt.com/support)并注册将文件直接通过电子邮件发送给您。

您可以按照以下步骤下载代码文件:

1.  登录或注册[www.packt.com](http://www.packt.com)。
2.  选择“支持”选项卡。
3.  点击代码下载和勘误表。
4.  在搜索框中输入图书的名称，并按照屏幕指示进行操作。

下载文件后，请确保使用最新版本的解压缩文件夹:

*   视窗系统的 WinRAR/7-Zip
*   zipeg/izp/un ARX for MAC
*   适用于 Linux 的 7-Zip/PeaZip

这本书的代码包也托管在 GitHub 上，网址为:如果代码有更新，它将在现有的 GitHub 存储库中更新。

我们还有来自丰富的图书和视频目录的其他代码包，可在**[【https://github.com/PacktPublishing/】](https://github.com/PacktPublishing/)**获得。看看他们！

# 下载彩色图像

我们还提供了一个 PDF 文件，其中包含本书中使用的截图/图表的彩色图像。可以在这里下载:[http://www . packtpub . com/sites/default/files/downloads/9781838644130 _ color images . pdf](http://www.packtpub.com/sites/default/files/downloads/9781838644130_ColorImages.pdf)。

# 使用的约定

本书通篇使用了许多文本约定。

`CodeInText`:表示文本中的码字、数据库表名、文件夹名、文件名、文件扩展名、路径名、虚拟网址、用户输入和推特句柄。下面是一个例子:“将下载的`WebStorm-10*.dmg`磁盘镜像文件作为另一个磁盘挂载到系统中。”

代码块设置如下:

```
test("Should use immutable DF API") {
    import spark.sqlContext.implicits._
    //given
    val userData =
        spark.sparkContext.makeRDD(List(
            UserData("a", "1"),
            UserData("b", "2"),
            UserData("d", "200")
        )).toDF()
```

当我们希望将您的注意力吸引到代码块的特定部分时，相关的行或项目以粗体显示:

```
class ImmutableRDD extends FunSuite {
    val spark: SparkContext = SparkSession
        .builder().master("local[2]").getOrCreate().sparkContext

test("RDD should be immutable") {
    //given
    val data = spark.makeRDD(0 to 5)
```

任何命令行输入或输出都编写如下:

```
total_duration/(normal_data.count())
```

**粗体**:表示一个新的术语，一个重要的单词，或者你在屏幕上看到的单词。例如，菜单或对话框中的单词像这样出现在文本中。下面是一个示例:“从管理面板中选择系统信息。”

Warnings or important notes appear like this. Tips and tricks appear like this.

# 取得联系

我们随时欢迎读者的反馈。

**一般反馈**:如果你对这本书的任何方面有疑问，在你的信息主题中提到书名，发邮件给我们`customercare@packtpub.com`。

**勘误表**:虽然我们已经尽了最大的努力来保证内容的准确性，但是错误还是会发生。如果你在这本书里发现了一个错误，如果你能向我们报告，我们将不胜感激。请访问[www.packt.com/submit-errata](http://www.packt.com/submit-errata)，选择您的图书，点击勘误表提交链接，并输入详细信息。

**盗版**:如果您在互联网上遇到任何形式的我们作品的非法拷贝，如果您能提供我们的位置地址或网站名称，我们将不胜感激。请通过`copyright@packt.com`联系我们，并提供材料链接。

**如果你有兴趣成为一名作者**:如果有一个你有专长的话题，你有兴趣写或者投稿一本书，请访问[authors.packtpub.com](http://authors.packtpub.com/)。

# 复习

请留下评论。一旦你阅读并使用了这本书，为什么不在你购买它的网站上留下评论呢？然后，潜在的读者可以看到并使用您不带偏见的意见来做出购买决定，我们在 Packt 可以了解您对我们产品的看法，我们的作者可以看到您对他们的书的反馈。谢谢大家！

更多关于 Packt 的信息，请访问[packt.com](http://www.packt.com/)。