# 前言

数据的持续增长，再加上需要根据这些数据做出越来越复杂的决策，这些都造成了巨大的障碍，阻碍了组织使用传统的分析方法及时得出见解。大数据领域已经变得与这些框架如此相关，以至于其范围由这些框架能够处理的内容来定义。无论您是仔细检查数百万访问者的点击流以优化在线广告投放，还是筛选数十亿笔交易以识别欺诈迹象，对机器学习和图形处理等高级分析的需求比以往任何时候都更加明显，以便从海量数据中自动收集见解。

Apache Spark 是所有学术界和行业的大数据处理、分析和数据科学的事实标准，它提供了机器学习和图形处理库，允许公司利用高度可扩展和集群计算机的能力轻松解决复杂问题。Spark 的承诺是更进一步，让使用 Scala 编写分布式程序感觉像为 Spark 编写常规程序。Spark 将极大地提升 ETL 管道的性能，缓解 MapReduce 程序员每天对 Hadoop 之神绝望的痛苦。

在本书中，我们使用了 Spark 和 Scala，努力将机器学习、图形处理、流和 SQL 的最先进的高级数据分析带到 Spark，以及它们对 MLlib、ML、SQL、GraphX 和其他库的贡献。

我们从 Scala 开始，然后转到 Spark 部分，最后，用 Spark 和 Scala 介绍了大数据分析的一些高级主题。在附录中，我们将看到如何为 SparkR、PySpark、Apache Zeppelin 和内存中的 Alluxio 扩展您的 Scala 知识。这本书不应该从头读到尾。跳到一个看起来像你正在努力完成的事情或者只是点燃你的兴趣的章节。

快乐阅读！

# 这本书涵盖了什么

[第 1 章](01.html#KVCC1-21aec46d8593429cacea59dbdcd64e1c)*Scala 介绍*，将使用 Spark 基于 Scala 的 API 教授大数据分析。Spark 本身是用 Scala 编写的，自然，作为起点，我们将讨论 Scala 的简单介绍，比如它的历史、用途的基本方面，以及如何在 Windows、Linux 和 Mac OS 上安装 Scala。之后，将简要讨论 Scala 网络框架。然后，我们将提供 Java 和 Scala 的对比分析。最后，我们将深入到 Scala 编程中，开始使用 Scala。

[第二章](02.html#1NA0K1-21aec46d8593429cacea59dbdcd64e1c)*面向对象的 Scala* 说面向对象编程(OOP)范式提供了一个全新的抽象层。简而言之，本章讨论了面向对象语言的一些最大优势:可发现性、模块化和可扩展性。特别是，我们将看到如何在 Scala 中处理变量；Scala 中的方法、类和对象；包和包对象；特性和特性线性化；和 Java 互操作性。

[第三章](03.html#2OM4A1-21aec46d8593429cacea59dbdcd64e1c)、*功能编程概念*，展示了 Scala 中的功能编程概念。更具体地说，我们将学习几个主题，例如为什么 Scala 是数据科学家的武器库，为什么学习 Spark 范式、纯函数和高阶函数(HOFs)很重要。还将展示一个使用 HOFs 的真实用例。然后，我们将看到如何使用 Scala 的标准库来处理集合之外的高阶函数中的异常。最后，我们将看看功能性 Scala 如何影响对象的可变性。

[第 4 章](04.html#3FIHQ1-21aec46d8593429cacea59dbdcd64e1c)、*集合 API*，介绍了最吸引 Scala 用户的特性之一——集合 API。它非常强大和灵活，并且耦合了许多操作。我们还将展示 Scala Collection API 的功能，以及如何使用它来适应不同类型的数据并解决各种不同的问题。在本章中，我们将介绍 Scala 集合 API、类型和层次结构、一些性能特征、Java 互操作性和 Scala 隐含性。

[第五章](05.html#4D4J81-21aec46d8593429cacea59dbdcd64e1c)、*攻坚大数据——星火来党、*概述数据分析与大数据；我们看到了大数据带来的挑战，分布式计算如何应对这些挑战，以及函数式编程提出的方法。我们介绍了谷歌的 MapReduce、Apache Hadoop，最后是 Apache Spark，看看他们是如何接受这种方法和这些技术的。我们将探讨 Apache Spark 的发展:Apache Spark 最初创建的原因，以及它可以为大数据分析和处理带来的价值。

[第 6 章](06.html#55U1S1-21aec46d8593429cacea59dbdcd64e1c)、*开始与 Spark - REPL 和 RDDs 合作，*讲述 Spark 如何工作；然后，我们介绍 rdd，Apache Spark 背后的基本抽象，并看到它们只是暴露类似 Scala 的 API 的分布式集合。我们将研究 Apache Spark 的部署选项，并将其作为 Spark shell 在本地运行。我们将学习 Apache Spark 的内部结构，什么是关系数据库，关系数据库、转换和动作的 Dag 和谱系。

[第 7 章](07.html#6A5N81-21aec46d8593429cacea59dbdcd64e1c)、*特别 RDD 行动、*重点介绍了 rdd 如何量身定制以满足不同需求，以及这些 rdd 如何提供新功能(和危险！)此外，我们还研究了 Spark 提供的其他有用对象，例如广播变量和累加器。我们将学习聚合技术，洗牌。

[第 8 章](08.html#75QNI1-21aec46d8593429cacea59dbdcd64e1c)、*介绍一个小结构——SparkSQL，*讲述如何使用 Spark 作为 RDDs 的更高级抽象来分析结构化数据，以及 SparkSQL 的 API 如何使查询结构化数据变得简单而健壮。此外，我们还介绍了数据集，并研究了数据集、数据框架和关系数据库之间的差异。我们还将学习连接操作和窗口函数，使用 DataFrame APIs 进行复杂的数据分析。

[第 9 章](09.html#8IL201-21aec46d8593429cacea59dbdcd64e1c)、*流我向上，Scotty - Spark Streaming，*带您了解 Spark Streaming，以及我们如何利用它来使用 Spark API 处理数据流。此外，在这一章中，读者将学习各种处理实时数据流的方法，使用一个实际的例子来消费和处理来自推特的推文。我们将研究与 Apache Kafka 的集成，以进行实时处理。我们还将关注结构化流，它可以为您的应用程序提供实时查询。

[第 10 章](10.html#9MSNC1-21aec46d8593429cacea59dbdcd64e1c)、*一切都是连通的——GraphX、*在这一章中，我们学习了有多少现实世界的问题可以用图来建模(和解决)。我们将以脸书为例来看图论，Apache Spark 的图形处理库 GraphX、VertexRDD 和 EdgeRDDs、图形运算符、aggregateMessages、TriangleCounting、Pregel API 以及 PageRank 算法等用例。

[第 11 章](11.html#A73GU1-21aec46d8593429cacea59dbdcd64e1c)、*学习机器学习- Spark MLlib 和 ML* ，本章的目的是提供统计机器学习的概念性介绍。我们将重点介绍 Spark 的机器学习 API，称为 Spark MLlib 和 ML。然后我们将讨论如何使用决策树和随机森林算法解决分类任务，以及使用线性回归算法解决回归问题。我们还将展示如何在训练分类模型之前，在特征提取中使用单向编码和降维算法。在后面的部分中，我们将展示一个开发基于协同过滤的电影推荐系统的分步示例。

[第 12 章](12.html#BD87E1-21aec46d8593429cacea59dbdcd64e1c)、*高级机器学习最佳实践*，用 Spark 提供了机器学习的一些高级主题的理论和实践方面。我们将看到如何使用网格搜索、交叉验证和超参数调整来优化机器学习模型的性能。在后面的部分，我们将介绍如何使用 ALS 开发一个可扩展的推荐系统，这是一个基于模型的推荐算法的例子。最后，主题建模应用程序将作为文本聚类技术进行演示

[第 13 章](13.html#C9ROA1-21aec46d8593429cacea59dbdcd64e1c)，*我叫 Bayes，Naive Bayes，*陈述大数据中的机器学习是一个激进的组合，在学术界和工业界的研究领域都产生了巨大的影响。大数据对 ML、数据分析工具和算法提出了巨大的挑战，以找到真正的价值。然而，基于这些庞大的数据集做出未来预测从来都不容易。考虑到这一挑战，在本章中，我们将更深入地探讨 ML，并了解如何使用简单而强大的方法来构建可扩展的分类模型和概念，例如多项式分类、贝叶斯推理、朴素贝叶斯、决策树，以及朴素贝叶斯与决策树的比较分析。

[第 14 章](14.html#CTSK41-21aec46d8593429cacea59dbdcd64e1c)、*是时候整理一下了——用 Spark MLlib 集群您的数据，*让您开始了解 Spark 如何在集群模式下使用其底层架构工作。在前几章中，我们看到了如何使用不同的 Spark APIs 开发实际应用程序。最后，我们将了解如何在集群上部署完整的 Spark 应用程序，无论是否安装了现有的 Hadoop。

[第 15 章](15.html#DKP1K1-21aec46d8593429cacea59dbdcd64e1c)、*使用 Spark ML 进行文本分析、*概述了使用 Spark ML 进行文本分析的精彩领域。文本分析是机器学习中的一个广泛领域，在许多用例中非常有用，例如情感分析、聊天机器人、电子邮件垃圾检测、自然语言处理等等。我们将学习如何使用 Spark 进行文本分析，重点是使用 10，000 个样本推特数据集进行文本分类的用例。我们还将研究 LDA，这是一种在不太了解实际文本的情况下从文档中生成主题的流行技术，并将在 Twitter 数据上实现文本分类，看看它是如何结合在一起的。

[第 16 章](16.html#E9OE01-21aec46d8593429cacea59dbdcd64e1c)、 *Spark Tuning、*更深入地挖掘了 Apache Spark 的内部，并表示虽然 Spark 在让我们感觉好像只是在使用另一个 Scala 集合方面很棒，但我们不应该忘记 Spark 实际上是在分布式系统中运行的。因此，在本章中，我们将介绍如何监控 Spark 作业、Spark 配置、Spark 应用程序开发中的常见错误以及一些优化技术。

[第 17 章](17.html#F7AFE1-21aec46d8593429cacea59dbdcd64e1c)、*前往集群之地的时间-在集群上部署 Spark，*探索 Spark 如何以其底层架构在集群模式下工作。我们将看到集群中的 Spark 体系结构、Spark 生态系统和集群管理，以及如何在独立、Mesos、Yarn 和 AWS 集群上部署 Spark。我们还将看到如何在基于云的 AWS 集群上部署您的应用程序。

[第 18 章](18.html#GCGLC1-21aec46d8593429cacea59dbdcd64e1c)、*测试和调试 Spark、*解释了如果应用程序是分布式的，那么测试它会有多困难；然后，我们看到一些方法来解决这个问题。我们将介绍如何在分布式环境中进行测试，以及测试和调试 Spark 应用程序。

[第 19 章](19.html#H0HH61-21aec46d8593429cacea59dbdcd64e1c)、 *PySpark & SparkR、*涵盖了另外两个使用 R 和 Python 编写 Spark 代码的流行 API，即 PySpark 和 SparkR。特别是，我们将介绍如何开始使用 PySpark 以及如何使用 PySpark 与 DataFrame APIs 和 UDF 交互，然后我们将使用 PySpark 进行一些数据分析。本章的第二部分介绍了如何开始使用 SparkR。我们还将看到如何进行数据处理和操作，以及如何使用 SparkR 处理 RDD 和数据帧，最后，使用 SparkR 进行一些数据可视化。

[附录 A](20.html#HLGTI1-21aec46d8593429cacea59dbdcd64e1c) 、*用 Alluxio 加速火花*，展示了如何用 Alluxio 配合火花来提高加工速度。Alluxio 是一个开源的分布式内存存储系统，对于提高包括 Apache Spark 在内的许多跨平台应用程序的速度非常有用。我们将探索使用 Alluxio 的可能性，以及 Alluxio 集成将如何提供更高的性能，而无需在每次运行 Spark 作业时将数据缓存在内存中。

[附录 B](21.html#I7KO81-21aec46d8593429cacea59dbdcd64e1c)*与 Apache Zepp**e**Lin*的互动数据分析表示，从数据科学的角度来看，数据分析的互动可视化也很重要。Apache Zeppelin 是一款基于网络的笔记本，用于交互式和大规模数据分析，具有多个后端和解释器。在本章中，我们将讨论如何使用 Apache Zeppelin 进行大规模数据分析，并在后端使用 Spark 作为解释器。

# 这本书你需要什么

所有示例都是在 Ubuntu Linux 64 位上使用 Python 和 3.5 版本实现的，包括 TensorFlow 库 1.0.1 版本。然而，在书中，我们展示了仅与 Python 2.7 兼容的源代码。Python 3.5+兼容的源代码可以从 Packt 存储库中下载。您还需要以下 Python 模块(最好是最新版本):

*   Spark 2.0.0(或更高版本)
*   Hadoop 2.7(或更高版本)
*   Java (JDK 和 JRE) 1.7+/1.8+
*   Scala 2.11.x(或更高版本)
*   Python 2.7+/3.4+
*   R 3.1+和 RStudio 1.0.143(或更高)
*   月食火星、氧气或月神(最新)
*   Maven Eclipse 插件(2.9 或更高版本)
*   Eclipse 的 Maven 编译器插件(2.3.2 或更高版本)
*   Eclipse 的 Maven 汇编插件(2.4.1 或更高版本)

**操作系统:** Linux 发行版更好(包括 Debian、Ubuntu、Fedora、RHEL 和 CentOS)，更具体来说，对于 Ubuntu，建议拥有完整的 14.04 (LTS) 64 位(或更高版本)安装、VMWare player 12 或 Virtual box。您可以在 Windows (XP/7/8/10)或 Mac OS X (10.4.7+)上运行 Spark 作业。

**硬件配置:**处理器酷睿 i3、酷睿 i5(推荐)或酷睿 i7(以获得最佳效果)。然而，多核处理将提供更快的数据处理和可扩展性。对于独立模式，您至少需要 8-16 GB 内存(推荐)，对于单个虚拟机，至少需要 32 GB 内存，对于集群，则需要更高的内存。您还需要足够的存储空间来运行繁重的作业(取决于您要处理的数据集大小)，并且最好至少有 50 GB 的可用磁盘存储空间(用于独立的单词丢失和 SQL 仓库)。

# 这本书是给谁的

任何希望学习如何利用 Spark 的力量进行数据分析的人都会发现这本书非常有用。不需要了解 Spark 或 Scala，尽管先前的编程经验(尤其是使用其他 JVM 语言)会有助于更快地理解概念。Scala 在过去几年中一直观察到采用率稳步上升，尤其是在数据科学和分析领域。与 Scala 齐头并进的是 Apache Spark，它是用 Scala 编程的，广泛应用于分析领域。这本书将帮助您利用这两种工具的力量来理解大数据。

# 约定

在这本书里，你会发现许多区分不同种类信息的文本样式。以下是这些风格的一些例子和对它们的意义的解释。文本中的码字、数据库表名、文件夹名、文件名、文件扩展名、路径名、伪 URL、用户输入和 Twitter 句柄如下所示:“下一行代码读取链接，并将其分配给至`BeautifulSoup`函数。”

代码块设置如下:

```
package com.chapter11.SparkMachineLearningimport org.apache.spark.mllib.feature.StandardScalerModelimport org.apache.spark.mllib.linalg.{ Vector, Vectors }import org.apache.spark.sql.{ DataFrame }import org.apache.spark.sql.SparkSession

```

当我们希望将您的注意力吸引到代码块的特定部分时，相关的行或项目以粗体显示:

```
val spark = SparkSession.builder.master("local[*]").config("spark.sql.warehouse.dir", "E:/Exp/").config("spark.kryoserializer.buffer.max", "1024m").appName("OneVsRestExample")        .getOrCreate()

```

任何命令行输入或输出都编写如下:

```
$./bin/spark-submit --class com.chapter11.RandomForestDemo \--master spark://ip-172-31-21-153.us-west-2.compute:7077 \--executor-memory 2G \--total-executor-cores 2 \file:///home/KMeans-0.0.1-SNAPSHOT.jar \file:///home/mnist.bz2

```

**新名词**和**重要词语**以粗体显示。您在屏幕上看到的单词，例如菜单或对话框中的单词，会出现在文本中，如下所示:“单击“下一步”按钮会将您移动到下一个屏幕。”

Warnings or important notes appear like this. Tips and tricks appear like this.

# 读者反馈

我们随时欢迎读者的反馈。让我们知道你对这本书的看法——你喜欢或不喜欢什么。读者反馈对我们来说很重要，因为它有助于我们开发出你真正能从中获益的标题。要给我们发送一般反馈，只需发送电子邮件`feedback@packtpub.com`，并在您的邮件主题中提及书名。如果您对某个主题有专业知识，并且对写作或投稿感兴趣，请参见我们位于[www.packtpub.com/authors](http://www.packtpub.com/authors)的作者指南。

# 客户支持

现在，您已经自豪地拥有了一本书，我们有许多东西可以帮助您从购买中获得最大收益。

# 下载示例代码

你可以从你在[http://www.packtpub.com](http://www.packtpub.com)的账户下载这本书的示例代码文件。如果您在其他地方购买了这本书，您可以访问[http://www.packtpub.com/support](http://www.packtpub.com/support)并注册，以便将文件直接通过电子邮件发送给您。您可以按照以下步骤下载代码文件:

1.  使用您的电子邮件地址和密码登录或注册我们的网站。
2.  将鼠标指针悬停在顶部的“支持”选项卡上。
3.  点击代码下载和勘误表。
4.  在搜索框中输入图书的名称。
5.  选择要下载代码文件的书籍。
6.  从您购买这本书的下拉菜单中选择。
7.  点击代码下载。

下载文件后，请确保使用最新版本的解压缩文件夹:

*   视窗系统的 WinRAR / 7-Zip
*   zipeg/izp/un ARX for MAC
*   适用于 Linux 的 7-Zip / PeaZip

这本书的代码包也托管在 GitHub 上，网址为 https://GitHub . com/PacktPublishing/Scala-and-Spark-for-Big-Data-Analytics。我们还有来自丰富的图书和视频目录的其他代码包，可在[https://github.com/PacktPublishing/](https://github.com/PacktPublishing/)获得。看看他们！

# 下载这本书的彩色图片

我们还为您提供了一个 PDF 文件，其中包含本书中使用的截图/图表的彩色图像。彩色图像将帮助您更好地理解输出中的变化。您可以从[https://www . packtpub . com/sites/default/files/downloads/scalaandparkforbigdata analytics _ color images . pdf](https://www.packtpub.com/sites/default/files/downloads/ScalaandSparkforBigDataAnalytics_ColorImages.pdf)下载此文件

# 正误表

尽管我们尽了最大努力来确保我们内容的准确性，但错误还是会发生。如果你在我们的某本书里发现一个错误，也许是文本或代码中的错误，如果你能向我们报告，我们将不胜感激。通过这样做，你可以让其他读者免受挫折，并帮助我们改进这本书的后续版本。如果您发现任何勘误表，请访问[http://www.packtpub.com/submit-errata](http://www.packtpub.com/submit-errata)，选择您的书籍，点击勘误表提交表格链接，并输入您的勘误表的详细信息。一旦您的勘误表得到验证，您的提交将被接受，勘误表将上传到我们的网站或添加到该标题勘误表部分下的任何现有勘误表列表中。要查看之前提交的勘误表，请前往[https://www.packtpub.com/books/content/support](https://www.packtpub.com/books/content/support)并在搜索栏中输入图书名称。所需信息将出现在勘误表部分。

# 海盗行为

互联网上版权材料的盗版是所有媒体的一个持续问题。在 Packt，我们非常重视版权和许可证的保护。如果您在互联网上遇到任何形式的我们作品的非法拷贝，请立即向我们提供位置地址或网站名称，以便我们寻求补救。请通过`copyright@packtpub.com`联系我们，获取疑似盗版资料的链接。我们感谢您在保护我们的作者方面的帮助，以及我们为您带来有价值内容的能力。

# 问题

如果您对本书的任何方面有问题，可以在`questions@packtpub.com`联系我们，我们将尽最大努力解决问题。