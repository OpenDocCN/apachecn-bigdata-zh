# 零、前言

我已经写了一本关于 Hadoop 生态系统的介绍性书籍，现在我很高兴被 Packt 邀请写一本关于 Apache Spark 的书。 作为一个有支持和维护背景的实干家，我对系统构建和集成很感兴趣。 所以，我总是问这样的问题：“如何使用这些系统？”“它们是如何组合在一起的？” 以及“它们与什么结合在一起？” 在这本书中，我将描述 Spark 的每个模块，并用实际例子解释如何使用它们。 我还将展示如何使用额外的库来扩展 Spark 的功能，比如来自[http://h2o.ai/](http://h2o.ai/)的 H2O。

我将展示如何将 Apache Spark 的 Graph 处理模块与 Aurelius(现在的 DataStAX)的 Titan 图形数据库结合使用。 这通过将 Spark GraphX 和 Titan 组合在一起，提供了基于图形的处理和存储的耦合。 流一章将展示如何使用 Apache Flume 和 Kafka 等工具将数据传递到 Spark Streams。

考虑到在过去几年中出现了向基于云的服务的大规模迁移，我将研究一下[https://databricks.com/](https://databricks.com/)上提供的 Spark 云服务。 我将从实用的角度来这样做，本书并不试图回答“服务器或云”的问题，因为我认为它是另一本书的主题；它只是研究可用的服务。

# 这本书涵盖了哪些内容

[第 1 章](1.html "Chapter 1. Apache Spark")，*Apache Spark*将完整概述 Spark、其模块的功能以及可用于处理和存储的工具。 本章将简要介绍 SQL、Streaming、GraphX、MLlib、Databricks 和 Spark 上的配置单元。

[第 2 章](2.html "Chapter 2. Apache Spark MLlib")，*Apache Spark MLlib*介绍了 MLlib 模块，其中 MLlib 代表机器学习库。 本文描述了我将在本书中使用的 Apache Hadoop 和 Spark 集群，以及涉及到的操作系统-CentOS。 它还描述了正在使用的开发环境：Scala 和 SBT。 它提供了安装和构建 Apache Spark 的示例。 解释了一个使用朴素贝叶斯算法进行分类的实例，以及使用 KMeans 进行聚类的例子。 最后，使用一个示例构建来扩展 Spark，使其包括 Bert Greevenbosch([www.bertgreevenbosch.nl](http://www.bertgreevenbosch.nl))的一些人工神经网络(ANN)工作。 我一直对神经网络感兴趣，能够(在他的许可下)在这一章中使用伯特的作品是一件令人愉快的事情。 因此，本章的最后一个主题是使用简单的人工神经网络对包括失真图像在内的一些小图像进行分类。 结果和由此产生的分数都相当不错！

[第 3 章](3.html "Chapter 3. Apache Spark Streaming")，*Apache Spark Streaming*介绍了 Apache Spark 与 Storm 的比较，特别是 Spark Streaming，但我认为 Spark 提供了更多的功能。 例如，一个 Spark 模块中使用的数据可以传递到另一个模块并在其中使用。 此外，正如本章所示，Spark Streaming 很容易与 Flume 和 Kafka 等大数据移动技术集成。

因此，流一章首先给出了检查点的概述，并解释了您可能想要使用它的时间。 它给出了如何使用 Scala 代码的示例，并展示了数据可以存储在 HDFS 上。 然后给出了 Scala 中的实际示例，以及 TCP、File、Flume 和 Kafka 流的执行示例。 最后两个选项是通过处理 RSS 数据流并最终将其存储在 HDFS 上来显示的。

[第 4 章](4.html "Chapter 4. Apache Spark SQL")，*Apache Spark SQL*解释了 Scala 代码术语中的 Spark SQL 上下文。 它将文件 I/O 解释为文本、拼接和 JSON 格式。 使用 Apache Spark 1.3，它通过示例解释了数据框的使用，并展示了数据框可用于数据分析的方法。 它还通过基于 Scala 的示例介绍了 Spark SQL，展示了如何创建临时表，以及如何对临时表使用基于 SQL 的操作。

接下来，介绍配置单元上下文。 最初，创建本地上下文，然后对其执行配置单元 QL 操作。 然后，介绍了一种将现有的分布式 CDH 5.3 配置单元集成到Spark配置单元上下文的方法。 然后显示针对此上下文的操作，以更新群集上的配置单元数据库。 通过这种方式，可以创建和调度 Spark 应用程序，以便由实时 Spark 引擎驱动配置单元操作。

最后，介绍了创建用户定义函数(UDF)的功能，然后在针对临时表的 SQL 调用中使用创建的 UDF。

[第 5 章](5.html "Chapter 5. Apache Spark GraphX")，*Apache Spark GraphX*介绍了 Apache Spark GraphX 模块和图形处理模块。 它通过实例实现了从基数计算到三角形处理的一系列图形函数。 然后介绍了 Kenny Bastani 的 Mazerunner 工作，它集成了 Neo4j NoSQL 数据库和 Apache Spark。 这项工作已得到肯尼的许可；请访问[www.kennybasani.com](http://www.kennybastani.com)。

本章首先介绍了 Docker，然后是 Neo4j，然后介绍了 Neo4j 接口。 最后，它通过提供的 REST 接口使用 Mazerunner 提供的一些功能。

[第 6 章](6.html "Chapter 6. Graph-based Storage")，*基于图形的存储*，在本书中介绍了 Apache Spark Graph 处理时，研究了基于图形的存储。 我寻找一款可以与 Hadoop 集成的产品，它是开源的，可以扩展到非常高的程度，并且可以与 Apache Spark 集成。

尽管它在社区支持和开发方面仍然是一个相对年轻的产品，但我认为 Aurelius 的 Titan(现在的 DataSTax)符合这一要求。 在我撰写本文时，可用的 0.9.x 版本使用 Apache TinkerPop 进行图形处理。

本章提供了使用 Gremlin shell 和 Titan 创建和存储图形的工作示例。 它展示了如何将 HBase 和 Cassandra 用于后端 Titan 存储。

[第 7 章](7.html "Chapter 7. Extending Spark with H2O")，*用 H2O 扩展 Spark*，讨论了由[http://h2o.ai/](http://h2o.ai/)开发的 H2O 库集，这是一个机器学习库系统，可用于扩展 Apache Spark 的功能。 在本章中，我将研究 H2O 的来源和安装，以及数据分析的流程界面。 研究了 Sphing Water 的体系结构，以及数据质量和性能调优。

最后，创建并执行了一个深度学习的实例。 [第 2 章](2.html "Chapter 2. Apache Spark MLlib")，*Spark MLlib*，使用简单的 ANN 进行神经分类。 本章使用高度可配置和可调的 H2O 深度学习神经网络进行分类。 正如你将看到的，结果是一个快速而准确的训练神经模型。

[第 8 章](8.html "Chapter 8. Spark Databricks")，*Spark Databricks*介绍了[AWS](https://databricks.com/)基于 https://databricks.com/云的 Apache Spark 集群系统。 它提供了设置 AWS 帐户和 Databricks 帐户的分步过程。 然后在笔记本、文件夹、作业、库、开发环境等方面逐步介绍[https://databricks.com/](https://databricks.com/)帐户功能。

它研究了 Databricks 中基于表的存储和处理，还介绍了 Databricks 实用程序功能的 DBUtils 包。 这些都是通过示例来完成的，目的是让您更好地理解如何使用这个基于云的系统。

[第 9 章](9.html "Chapter 9. Databricks Visualization")，*Databricks Visualization*通过专注于数据可视化和仪表板，扩展了 Databricks 的覆盖范围。 然后研究 Databricks REST 接口，展示如何使用各种示例 REST API 调用远程管理集群。 最后，它从表的文件夹和库的角度查看数据移动。

本章的群集管理部分显示，可以使用 Spark 版本提供的脚本在 AWS EC2 上启动 Apache Spark。 [Spark](https://databricks.com/)服务提供了一种轻松创建多个基于 https://databricks.com/的 Spark 集群并调整其大小的方法，从而使此功能更上一层楼。 如这两章所示，它为集群管理和使用以及用户访问和安全性提供了额外的功能。 考虑到给我们带来 Apache Spark 的人创建了这项服务，它一定值得考虑和研究。

# 这本书你需要什么

本书中的实际示例使用 Scala 和 SBT 进行基于 Apache Spark 的代码开发和编译。 还使用 CentOS 6.5 Linux 服务器上的 Cloudera CDH 5.3 Hadoop 集群。 Linux Bash shell 和 Perl 脚本都使用，以帮助 Spark 应用程序并提供数据提要。 Hadoop 管理命令用于在 Spark 应用程序测试期间移动和检查数据。

根据前面的技能概述，读者对 Linux、Apache Hadoop 和 Spark 有一个基本的了解会很有用。 话虽如此，考虑到今天互联网上有大量的信息可用，我不想阻止一个勇敢的读者去尝试。 我相信从错误中学到的东西比从成功中学到的东西更多是可能的。

# 这本书是给谁看的

这本书是为那些对 Apache Hadoop 和 Spark 感兴趣并想了解更多关于 Spark 的人而写的。 它是为想要了解 Spark 如何通过 H2O 这样的系统扩展使用的用户而编写的。 它是为对图形处理感兴趣但想要了解更多图形存储的用户编写的。 如果读者想了解云中的 Apache Spark，那么他/她可以了解[https://databricks.com/](https://databricks.com/)，这是由给他们带来 Spark 的人开发的基于云的系统。 如果你是一名开发人员，对 Spark 有一定的经验，想要加强你在 Spark 世界中的知识，那么这本书是你的理想之选。 要理解本书，需要具备 Linux、Hadoop 和 Spark 的基本知识；还需要对 Scala 有一定的了解。

# 公约

在本书中，您将发现许多区分不同类型信息的文本样式。 下面是这些风格的一些例子，并解释了它们的含义。

文本中的代码字、数据库表名、文件夹名、文件名、文件扩展名、路径名、虚拟 URL、用户输入和 Twitter 句柄如下所示：“第一步是确保 Cloudera 存储库文件存在于服务器 hc2nn 和所有其他 Hadoop 集群服务器上的`/etc/yum.repos.d`目录下。”

代码块设置如下：

```scala
export AWS_ACCESS_KEY_ID="QQpl8Exxx"
export AWS_SECRET_ACCESS_KEY="0HFzqt4xxx"

./spark-ec2  \
    --key-pair=pairname \
    --identity-file=awskey.pem \
    --region=us-west-1 \
    --zone=us-west-1a  \
    launch cluster1
```

任何命令行输入或输出都如下所示：

```scala
[hadoop@hc2nn ec2]$ pwd

/usr/local/spark/ec2

[hadoop@hc2nn ec2]$ ls
deploy.generic  README  spark-ec2  spark_ec2.py

```

**新术语**和**重要单词**以粗体显示。 您在屏幕上看到的文字(例如，在菜单或对话框中)会出现在文本中，如下所示：“选择**用户操作**选项，然后选择**管理访问键**。”

### 备注

警告或重要说明会出现在这样的框中。

### 提示

提示和技巧如下所示。

# 读者反馈

欢迎读者的反馈。 让我们知道你对这本书的看法-你喜欢什么或不喜欢什么。 读者反馈对我们很重要，因为它可以帮助我们开发出真正能让您获得最大收益的图书。

要向我们发送一般反馈，只需发送电子邮件`<[feedback@packtpub.com](mailto:feedback@packtpub.com)>`，并在邮件主题中提及书名。

如果有一个您擅长的主题，并且您有兴趣撰写或投稿一本书，请参阅我们的作者指南，网址为[www.Packtpub.com/Authors](http://www.packtpub.com/authors)。

# 客户支持

现在您已经成为 Packt 图书的拥有者，我们有很多东西可以帮助您从购买中获得最大价值。

## 下载示例代码

您可以从您的帐户[http://www.packtpub.com](http://www.packtpub.com)为您购买的所有 Packt Publishing 图书下载示例代码文件。 如果您在其他地方购买了本书，您可以访问[http://www.packtpub.com/support](http://www.packtpub.com/support)并注册，以便将文件通过电子邮件直接发送给您。

## 勘误表

虽然我们已经竭尽全力确保内容的准确性，但错误还是会发生。 如果您在我们的一本书中发现错误--可能是文本或代码中的错误--如果您能向我们报告，我们将不胜感激。 通过这样做，您可以将其他读者从挫折中解救出来，并帮助我们改进本书的后续版本。 如果您发现任何勘误表，请访问[http://www.packtpub.com/submit-errata](http://www.packtpub.com/submit-errata)，选择您的图书，单击**勘误表提交表**链接，然后输入勘误表的详细信息。 一旦您的勘误表被核实，您提交的勘误表将被接受，勘误表将被上传到我们的网站或添加到该书目勘误表部分下的任何现有勘误表列表中。

要查看之前提交的勘误表，请转到[https://www.packtpub.com/books/content/support](https://www.packtpub.com/books/content/support)，并在搜索字段中输入图书名称。 所需信息将显示在**勘误表**部分下。

## 盗版

在互联网上盗版版权材料是所有媒体持续存在的问题。 在 Packt，我们非常重视版权和许可证的保护。 如果您在互联网上发现任何形式的非法复制我们的作品，请立即提供我们的位置、地址或网站名称，以便我们采取补救措施。

请拨打`<[copyright@packtpub.com](mailto:copyright@packtpub.com)>`与我们联系，并提供疑似盗版材料的链接。

我们感谢您在保护我们的作者方面的帮助，以及我们为您提供有价值内容的能力。

## 问题

如果您对本书的任何方面有任何问题，您可以拨打`<[questions@packtpub.com](mailto:questions@packtpub.com)>`与我们联系，我们将尽最大努力解决问题。