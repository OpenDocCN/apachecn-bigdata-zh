# 第一章：阿帕奇火花

Apache Spark 是一个分布式的、高度可伸缩的内存数据分析系统，提供了用 Java、Scala、Python 以及 R 等语言开发应用程序的能力。它是目前 Apache 顶级项目中贡献/参与率最高的项目之一。 Apache 系统(如 Mahout)现在将其用作处理引擎，而不是 MapReduce。 此外，正如将在[第 4 章](4.html "Chapter 4. Apache Spark SQL")、*Apache Spark SQL*中所示，可以使用配置单元上下文让 Spark 应用程序直接处理往返于 Apache 配置单元的数据。

Apache Spark 提供了四个主要的子模块，它们是 SQL、MLlib、GraphX 和 Streaming。 它们都将在各自的章节中进行解释，但简单的概述在这里会很有用。 这些模块是可互操作的，因此可以在它们之间传递数据。 例如，可以将流数据传递给 SQL，并且可以创建临时表。

下图解释了本书将如何介绍 Apache Spark 及其模块。 最上面的两行显示了 Apache Spark 及其前面描述的四个子模块。 然而，只要有可能，我总是试图通过举例说明如何使用额外的工具扩展功能：

![Apache Spark](graphics/B01989_01_01.jpg)

例如，在[第 3 章](3.html "Chapter 3. Apache Spark Streaming")、*Apache Spark Streaming*中解释的数据流模块将具有工作示例，展示如何使用 Apache**Kafka**和**Flume**执行数据移动。 根据可用的数据处理功能，**MLlib**或机器学习模块将检查其功能，但也将使用 H2O 系统和深度学习对其进行扩展。

当然，前面的数字是简化的。 它代表了本书中呈现的系统关系。 例如，与上图所示相比，Apache Spark 模块和 HDFS 之间的路由要多得多。

Spark SQL 一章还将展示 Spark 如何使用配置单元上下文。 因此，可以开发 Spark 应用程序来创建基于配置单元的对象，并对存储在 HDFS 中的配置单元表运行配置单元 QL。

[第 5 章](5.html "Chapter 5. Apache Spark GraphX")，*Apache Spark GraphX*和第 6 章，*基于图形的存储*将展示如何使用 Spark GraphX 模块处理大数据规模的图形，以及如何使用 Titan 图形数据库存储这些图形。 Titan 将允许存储大数据规模的图表，并以图表的形式进行查询。 它将通过一个例子说明，Titan 可以同时使用**HBase**和**Cassandra**作为存储机制。 当使用 HBase 时，将会显示隐含地使用 HDFS 作为一种廉价可靠的分布式存储机制，Titan使用 HDFS 作为一种廉价可靠的分布式存储机制。

所以，我认为这一节已经解释了 Spark 是一个内存处理系统。 当大规模使用时，它不能单独存在-数据必须驻留在某个地方。 它可能会与 Hadoop 工具集以及相关的生态系统一起使用。 幸运的是，Cloudera 等 Hadoop 堆栈提供程序提供了 CDH Hadoop 堆栈和集群管理器，可以与 Apache Spark、Hadoop 和大多数当前稳定的工具集集成。 在本书中，我将使用一个安装在 CentOS 6.564 位服务器上的小型 CDH 5.3 集群。 您可以使用替代配置，但我发现 CDH 提供了我需要的大多数工具，并且自动进行配置，为我留出了更多的开发时间。

在提到本书中将介绍的 Spark 模块和软件之后，下一节将描述大数据集群的可能设计。

# 概述

在本节中，我希望提供本书中将介绍的 Apache Spark 功能的概述，以及将用来扩展它的系统。 我还将尝试研究 Apache Spark 的未来，因为它与云存储集成在一起。

当您查看 Apache Spark 网站([http://spark.apache.org/](http://spark.apache.org/))上的文档时，您会看到有一些主题涵盖了 SparkR 和百吉饼。 虽然我将在本书中介绍四个主要的 Spark 模块，但我不会讨论这两个主题。 我在这本书中的时间和范围有限，所以我将把这些主题留给读者调查或留待将来的日期。

## 火花机器学习

Spark MLlib模块在个域上提供机器学习功能。 Spark 网站上提供的文档介绍了使用的数据类型(例如，向量和 LabeledPoint 结构)。 本模块提供的功能包括：

*   统计学
*   分类 / 同 taxonomy / 种类 / 类别，等级
*   回归 / 后退 / 逆行 / 复原
*   协同过滤
*   聚类
*   降维
*   特征提取
*   频繁模式挖掘
*   优化 / 最佳化

本书的[第 2 章](2.html "Chapter 2. Apache Spark MLlib")，*Apache Spark MLlib*介绍并讨论了基于 Scala 的KMeans、NaiveBayes 和人工神经网络的实际示例。

## 火花流

流处理是 Apache Spark 的另一个热门话题。 它涉及到将 Spark 中的数据作为流进行处理，并涵盖了诸如输入和输出操作、转换、持久性和检查点等主题。

[第 3 章](3.html "Chapter 3. Apache Spark Streaming")，*Apache Spark Streaming*涵盖了这一处理领域，并提供了不同类型的流处理的实际示例。 它讨论了批处理和窗口流配置，并提供了一个检查点设置的实际示例。 它还介绍了流处理的不同示例，包括 Kafka 和 Flume。

可以使用流数据的方式还有很多种。 可以使用其他 Spark 模块功能(例如，SQL、MLlib 和 GraphX)来处理流。 您可以在 Kinesis 或 ZeroMQ 等系统中使用 Spark Streaming。 您甚至可以为自己的用户定义数据源创建自定义接收器。

## 火花 SQL

从 Spark 版本 1.3 开始，Apache Spark 中引入了数据框，因此 Spark 数据可以以表格形式进行处理，并且表格函数(如 SELECT、FILTER、GROUPBY)可以用来处理数据。 Spark SQL 模块与 Parquet 和 JSON 格式集成，允许以更好地表示数据的格式存储数据。 这也为与外部系统集成提供了更多选择。

还可以引入将 Apache Spark 集成到 Hadoop Have 大数据数据库中的想法。 基于配置单元上下文的 Spark 应用程序可用于操作基于配置单元的表格数据。 这个将 Spark 的快速内存分布式处理能力带入了蜂巢的大数据存储能力。 它有效地让蜂巢使用 Spark 作为处理引擎。

## 火花图处理

Apache Spark GraphX模块允许 Spark 在内存图处理中提供快速、大数据。 图形由顶点和边(连接顶点的线)列表表示。 GraphX 能够使用 Property、Structural、Join、Aggregation、Cache 和 Uncache 操作符创建和操作图形。

它引入了两种新的数据类型来支持 Spark 中的图形处理：VertexRDD 和 EdgeRDD 来表示图形的顶点和边。 并介绍了 PageRank、三角形处理等图形处理实例函数。 其中许多函数将在[第 5 章](5.html "Chapter 5. Apache Spark GraphX")，*Apache Spark GraphX*中介绍。

## 扩展的生态系统

在检查大数据处理系统时，我认为重要的是不仅要看系统本身，还要看如何扩展它，以及它如何与外部系统集成，以便提供更高级别的功能。 在这种规模的书中，我不可能涵盖所有的选择，但希望通过引入一个主题，我可以激发读者的兴趣，这样他们就可以进一步研究。

我使用了 H2O 机器学习库系统来扩展 Apache Spark 的机器学习模块。 通过使用一个基于 H2O 深度学习 Scala 的示例，我展示了如何将神经处理引入 Apache Spark。 然而，我意识到我只是触及了 H2O 功能的皮毛。 我只使用了一个小的神经簇和单一类型的分类功能。 此外，H2O 还有比深度学习更多的东西。

随着图形处理在未来几年变得越来越被接受和使用，基于图形的存储也将越来越多地被接受和使用。 我使用 MazerRunner 原型应用程序研究了 Spark 在 NoSQL 数据库 Neo4J 中的使用。 我还研究了 Aurelius(DataStAX)Titan 数据库用于基于图形的存储。 同样，Titan 是一个处于初级阶段的数据库，它既需要社区的支持，也需要进一步的发展。 但我想研究一下 Apache Spark 集成的未来选项。

## 星火的未来

下一节将展示 Apache Spark 版本包含允许在 AWS EC2 存储上创建 Spark 集群的脚本。 有一系列选项可供集群创建者定义属性，如集群大小和存储类型。 但是这种类型的集群很难调整大小，这使得管理不断变化的需求变得困难。 如果数据量随时间变化或增长，可能需要更大的集群和更多的内存。

幸运的是，开发 Apache Spark 的人创建了一个新的初创公司，名为 Databricks[https://databricks.com/](https://databricks.com/)，它提供基于 Web 控制台的 Spark 集群管理，以及许多其他功能。 它提供了按笔记本、用户访问控制、安全性和大量其他功能来组织工作的想法。 这在这本书的末尾有描述。

这是一项刚刚起步的服务，目前只在亚马逊 AWS 上提供基于云的存储，但未来可能会扩展到谷歌和 Microsoft Azure。 其他基于云的提供商，即 Google 和 Microsoft Azure，也在扩展他们的服务，这样他们就可以在云中提供 Apache Spark 处理。

# 集群设计

正如我已经提到的，Apache Spark 是一个分布式、内存中的并行处理系统，它需要一个与关联的存储机制。 因此，在构建大数据集群时，您可能会使用 Hadoop 等分布式存储系统，以及 Sqoop、Flume 和 Kafka 等工具来移动数据。

我想介绍一下大数据集群中边缘节点的概念。 集群中的那些节点将是面向客户端的，这些节点上驻留着面向客户端的组件，如 Hadoop NameNode 或 Spark master。 大数据群集的大部分可能位于防火墙之后。 然后，边缘节点将降低防火墙造成的复杂性，因为它们将是唯一可访问的节点。 下图显示了一个简化的大数据集群：

![Cluster design](graphics/B01989_01_02.jpg)

它显示了四个简化的群集机架，带有交换机和边缘节点计算机，穿过防火墙面向客户端。 当然，这是风格化和简单化的，但你明白我的意思。 一般的处理节点隐藏在防火墙(虚线)后面，根据 Hadoop、Apache Spark、ZooKeeper、Flume 和/或 Kafka，它们可用于一般处理。 下图显示了几个大数据群集边缘节点，并尝试显示哪些应用程序可能驻留在这些节点上。

边缘节点应用程序将是类似于 Hadoop NameNode 或 Apache Spark 主服务器的主应用程序。 它将是将数据传入和传出集群的组件，如 Flume、Sqoop 和 Kafka。 它可以是使客户端用户可以使用用户界面的任何组件，类似于配置单元：

![Cluster design](graphics/B01989_01_03.jpg)

通常，防火墙在为群集增加安全性的同时，也会增加复杂性。 需要打开系统组件之间的端口，以便它们可以相互通信。 例如，许多组件都使用 ZooKeeper 进行配置。 发布订阅消息传递系统 Apache Kafka 使用 ZooKeeper 配置其主题、组、消费者和生产者。 因此，通往 ZooKeeper 的客户端端口(可能跨越防火墙)需要打开。

最后，需要考虑将系统分配给群集节点。 例如，如果 Apache Spark 使用 Flume 或 Kafka，则将使用内存通道。 需要考虑由数据流引起的这些通道的大小和使用的内存。 Apache Spark 不应该与其他 Apache 组件竞争内存使用。 根据您的数据流和内存使用情况，可能需要在不同的集群节点上安装 Spark、Hadoop、ZooKeeper、Flume 和其他工具。

通常，充当群集 NameNode 服务器或 Spark 主服务器的边缘节点需要比防火墙内的群集处理节点更多的资源。 例如，CDH 集群节点管理器服务器需要额外内存，Spark 主服务器也是如此。 您应该监控边缘节点的资源使用情况，并根据需要根据资源和/或应用程序位置进行调整。

本节简要介绍了如何使用 Apache Spark、Hadoop 和其他工具为大数据集群做好准备。 然而，在大数据集群中，Apache Spark 集群本身是如何配置的呢？ 例如，可以有许多类型的 Spark 群集管理器。 下一节将研究这一点，并描述每种类型的 Apache Spark 集群管理器。

# 集群管理

下面的图借用自 spk.apache.org网站，演示了 Apache Spark 集群管理器在主应用程序、从应用程序(辅助应用程序)、执行器应用程序和 Spark 客户端应用程序中的角色：

![Cluster management](graphics/B01989_01_04.jpg)

正如您将从本书中的许多示例中看到的那样，Spark 上下文可以通过 Spark 配置对象和 Spark URL 定义。 Spark 上下文连接到 Spark 集群管理器，然后 Spark 集群管理器跨应用程序的工作节点分配资源。 集群管理器跨集群工作者节点分配执行器。 它将应用程序 JAR 文件复制到工作进程，最后分配任务。

以下小节描述了目前可用的 Apache Spark 集群管理器选项。

## 本地

通过指定 Spark 配置本地 URL，可以在本地运行应用程序。 通过指定local[n]，可以让 Spark 使用`<n>`线程在本地运行应用程序。 这是一个有用的开发和测试选项。

## 独立

独立模式使用 Apache Spark 提供的基本集群管理器。 Spark 主 URL 将如下：

```
Spark://<hostname>:7077

```

这里，`<hostname>`是运行 Spark Master 的主机的名称。 我指定了`7077`作为端口，这是默认值，但它是可配置的。 这个简单的集群管理器目前只支持 FIFO(先进先出)调度。 通过设置每个应用程序的资源配置选项，您可以设法允许并发应用程序调度。 例如，使用`spark.core.max`在应用程序之间共享内核。

## 阿帕奇纱线

在更大的范围内，当与 Hadoop Spare 集成时，Apache Spark 集群管理器可以是纱线，并且应用程序可以在两种模式中的一种模式下运行。 如果 Spark master 值设置为纱线集群，则应用程序可以提交到集群，然后终止。 群集将负责分配资源和运行任务。 但是，如果应用程序主程序被提交为纱线客户端，则应用程序在处理的生命周期中保持活动状态，并向纱线请求资源。

## = 0= Apache Meos

Apache Mesos 是一个开源系统，用于跨集群共享资源。 它允许多个框架通过管理和调度资源来共享集群。 它是一个集群管理器，使用 Linux 容器提供隔离，允许 Hadoop、Spark、Kafka、Storm 等多个系统安全地共享一个集群。 它高度可扩展到数千个节点。 它是一个基于主从的系统，具有容错能力，使用 ZooKeeper 进行配置管理。

对于单个主节点 Mesos 集群，Spark 主 URL 将采用以下格式：

```
Mesos://<hostname>:5050

```

其中`<hostname>`是 Mesos 主服务器的主机名，端口定义为`5050`，这是默认的 Mesos 主端口(这是可配置的)。 如果在一个大规模的高可用性 Mesos 集群中有多个 Mesos 主服务器，则 Spark 主 URL 将如下所示：

```
Mesos://zk://<hostname>:2181

```

因此，Mesos 主服务器的选举将由 ZooKeeper 控制。 `<hostname>`将是 ZooKeeper 仲裁中的主机名称。 此外，端口号`2181`是 ZooKeeper 的默认主端口。

## Amazon EC2

ApacheSpark 版本包含在云中针对基于 Amazon AWS EC2 的服务器运行 Spark 的脚本。 下面的清单显示了安装在名为`/usr/local/spark/`目录下的 LinuxCentOS 服务器上的 Spark 1.3.1。 EC2 资源位于 Spark Release EC2 子目录中：

```
[hadoop@hc2nn ec2]$ pwd

/usr/local/spark/ec2

[hadoop@hc2nn ec2]$ ls
deploy.generic  README  spark-ec2  spark_ec2.py

```

要在 EC2 上使用 Apache Spark，您需要设置 Amazon AWS 帐户。 您可以在此处设置初始免费帐户进行试用：[http://aws.amazon.com/free/](http://aws.amazon.com/free/)。

如果您查看[第 8 章](8.html "Chapter 8. Spark Databricks")，*Spark Databricks*，您将看到这样的帐户已经设置好，并且用于访问[https://databricks.com/](https://databricks.com/)。 您需要做的下一件事是访问您的 AWS IAM 控制台，并选择**Users**选项。 您可以创建或选择用户。 选择**用户操作**选项，然后选择**管理访问密钥**。 然后，选择**创建访问密钥**，然后选择**下载凭证**。 确保下载的密钥文件是安全的，假设您在 Linux 上 chmod 该文件，并具有仅供用户访问的权限`= 600`。

现在，您将拥有您的**访问密钥 ID**、**秘密访问密钥**、密钥文件和密钥对名称。 现在可以使用`spark-ec2`脚本创建 Spark EC2 集群，如下所示：

```
export AWS_ACCESS_KEY_ID="QQpl8Exxx"
export AWS_SECRET_ACCESS_KEY="0HFzqt4xxx"

./spark-ec2  \
 --key-pair=pairname \
 --identity-file=awskey.pem \
 --region=us-west-1 \
 --zone=us-west-1a  \
 launch cluster1

```

这里，`<pairname>`是您在创建访问详细信息时提供的密钥对名称；`<awskey.pem>`是您下载的文件。 您要创建的集群的名称称为`<cluster1>`。 这里选择的地区是美国西部，`us-west-1`。 如果你像我一样住在太平洋，选择一个更近的地区(比如`ap-southeast-2`)可能会更明智。 但是，如果您遇到许可访问问题，则需要尝试其他区域。 还要记住，像这样使用基于云的 Spark 集群通常会有更高的延迟和更差的 I/O。 您与多个用户共享您的群集主机，并且您的群集可能位于偏远地区。

您可以使用此基本命令的一系列选项来配置您创建的基于云的 Spark 集群。 可以使用`–s`选项：

```
-s <slaves>

```

这允许您定义要在 Spark EC2 集群中创建多少个工作节点，也就是说，对于一个 6 节点集群、1 个主工作节点和 5 个从工作节点，`–s 5`。 您可以定义群集运行的 Spark 版本，而不是默认的最新版本。 以下选项使用 Spark 版本 1.3.1 启动群集：

```
--spark-version=1.3.1

```

用于创建集群的实例类型将定义使用了多少内存，以及有多少内核可用。 例如，以下选项将实例类型设置为`m3.large`：

```
--instance-type=m3.large

```

Amazon AWS 的当前实例类型位于：[http://aws.amazon.com/ec2/instance-types/](http://aws.amazon.com/ec2/instance-types/)。

下图显示了当前(截至 2015 年 7 月)AWS M3 实例类型、型号详细信息、内核、内存和存储。 目前有许多实例类型可用；例如，T2、M4、M3、C4、C3、R3 等等。 检查当前可用性并适当选择：

![Amazon EC2](graphics/B01989_01_05.jpg)

定价也非常重要。 当前的 aws 存储类型价格位于：[http://aws.amazon.com/ec2/pricing/](http://aws.amazon.com/ec2/pricing/)。

价格通过下拉菜单按地区显示，按小时显示价格。 请记住，每种存储类型都是由内核、内存和物理存储定义的。 价格还由操作系统类型定义，即 Linux、RHEL 和 Windows。 只需通过顶级菜单选择操作系统即可。

下图显示了撰写本文时(2015 年 7 月)的定价示例，仅供参考。 价格会随着时间和服务提供商的不同而有所不同。 它们将根据您需要的存储大小和您愿意投入的时间长度而有所不同。

还要注意将您的数据移出任何存储平台的成本。 试着从长远考虑。 检查一下，比方说，五年后，您是否需要将所有或部分基于云的数据移动到下一个系统。 检查移动数据的流程，并将该成本包括在您的计划中。

![Amazon EC2](graphics/B01989_01_06.jpg)

如前所述，上图按操作系统、区域、存储类型和小时显示了 AWS 存储类型的成本。 成本是按个单位小时计算的，因此像[EC2](https://databricks.com/)这样的系统在整整一个小时过去之前不会终止 https://databricks.com/实例。 这些成本将随时间变化，需要通过(对于 AWS)AWS 计费控制台进行监控。

当您想要调整 Spark EC2 集群的大小时，也可能会遇到问题，因此在开始之前，您需要确保主从配置。 确定您将需要多少工作人员，以及您需要多少内存。 如果您觉得您的需求会随着时间的推移而改变，那么您可以考虑使用[Spark](https://databricks.com/)，如果您确实希望在云中使用 https://databricks.com/。 转到[第 8 章](8.html "Chapter 8. Spark Databricks")，*Spark Databricks*，了解如何设置和使用[https://databricks.com/](https://databricks.com/)。

在下一节中，我将研究 Apache Spark 集群的性能，以及可能影响它的问题。

# 性能

在继续介绍介绍 Apache Spark 的功能领域及其扩展的其余章节之前，我想研究一下性能领域。 需要考虑哪些问题和领域？ 什么可能会影响 Spark 应用程序的性能，从集群级别开始，到实际的 Scala 代码结束？ 我不想重复 Spark 网站所说的，所以看看下面的 URL：`http://spark.apache.org/docs/<version>/tuning.html`。

这里，`<version>`将与您正在使用的 Spark 版本相关联，即，对于特定版本，为最新版本或 1.3.1 版本。 所以，在看过那一页之后，我将简要地提到一些主题领域。 我将在这一部分列出一些概括性的观点，而不是暗示重要性的顺序。

## 集群结构

您的大数据群集的大小和结构将影响性能。 如果您有一个基于云的集群，与非共享硬件集群相比，您的 IO 和延迟将受到影响。 您将与多个客户共享底层硬件，并且群集硬件可能是远程的。

此外，集群组件在服务器上的定位可能会导致资源争用。 例如，如果可能，请仔细考虑在大型集群中定位 Hadoop NameNodes、Spark 服务器、ZooKeeper、Flume 和 Kafka 服务器。 对于高工作负载，您可以考虑将服务器隔离到各个系统。 您还可以考虑使用诸如 Mesos 之类的 Apache 系统来共享资源。

此外，还要考虑潜在的并行性。 对于大型数据集，Spark 集群中的工作进程数量越多，并行的机会就越大。

## Hadoop 文件系统

您可以考虑使用 HDFS 的替代方案，具体取决于您的群集要求。 例如，MapR 使用基于 NFS 的 MapR-FS 读写文件系统来提高性能。 此文件系统具有完全读写功能，而 HDFS 设计为一次写入、多次读取的文件系统。 它提供了比 HDFS 更高的性能。 它还与 Hadoop 和 Spark集群工具集成。 MapR 的架构师 Bruce Penn 在[https://www.mapr.com/blog/author/bruce-penn](https://www.mapr.com/blog/author/bruce-penn)上写了一篇有趣的文章描述了它的特性。

只需查找标题为`Comparing MapR-FS and HDFS NFS and Snapshots`的博客帖子。 本文中的链接描述了 MapR 体系结构，以及可能的性能提升。

## 数据局部性

数据局部性或正在处理的数据的位置将影响延迟和 Spark 处理。 数据来源是 AWS S3、HDFS、本地文件系统/网络还是远程来源？

正如前面的调优链接提到的，如果数据是远程的，则必须将功能和数据放在一起进行处理。 Spark 将尝试使用可能的最佳数据局部性级别进行任务处理。

## 内存

为了避免任务的**OOM**(**Out of Memory**)消息，在您的 Apache Spark 集群上，您可以考虑以下几个方面：

*   考虑 Spark Worker 节点上可用的物理内存级别。 还能增加吗？
*   考虑数据分区。 您可以增加 Spark 应用程序代码使用的数据中的分区数量吗？
*   您能否增加存储部分，即 JVM 用于存储和缓存 RDD 的内存？
*   考虑调整用于减少内存的数据结构。
*   考虑序列化您的 RDD 存储以减少内存使用。

## 编码

尝试调整您的代码以提高 Spark 应用程序的性能。 例如，在 ETL 周期的早期过滤基于应用程序的数据。 调整您的并行度，尝试找到代码中资源开销较大的部分，并找到替代方案。

# 云

尽管本书的大部分内容将集中在基于物理服务器的集群上安装 Apache Spark 的示例([https://databricks.com/](https://databricks.com/)除外)，但我想指出的是，有多种基于云的选择。 有使用 Apache Spark 作为集成组件的基于云的系统，也有将 Spark 作为服务提供的基于云的系统。 尽管这本书不能深入地涵盖所有这些问题，但我认为提到其中的一些会很有用：

*   本书分两章介绍了 Databricks。 它提供基于 Spark 云的服务，目前使用的是 AWS EC2。 有计划将该服务扩展到其他云供应商([https://databricks.com/](https://databricks.com/))。
*   在撰写本书时(2015 年 7 月)，Microsoft Azure 已经扩展到提供 Spark 支持。
*   Apache Spark 和 Hadoop 可以安装在 Google Cloud 上。
*   Oryx 系统建立在 Spark 和 Kafka 的顶端，用于实时、大规模的机器学习([http://oryx.io/](http://oryx.io/))。
*   用于服务机器学习预测的 velox 系统基于 Spark 和 KeystoneML([https://github.com/amplab/velox-modelserver](https://github.com/amplab/velox-modelserver))。
*   PredictionIO 是一项开源机器学习服务，构建在 Spark、HBase 和 Splet([https://prediction.io/](https://prediction.io/))之上。
*   SeldonIO 是一个基于 Spark、Kafka 和 Hadoop([http://www.seldon.io/](http://www.seldon.io/))的开源预测分析平台。

# 摘要

作为本章的结束语，我想邀请您逐步了解下一章中的每一个基于 Scala 代码的示例。 Apache Spark 的发展速度给我留下了深刻的印象，发布的频率也给我留下了深刻的印象。 所以，尽管在撰写本文时，Spark 已经达到 1.4，但我相信您将使用更高版本。 如果你遇到问题，理性地解决它们。 尝试联系 Spark 用户组寻求帮助(`<[user@spark.apache.org](mailto:user@spark.apache.org)>`)，或查看 Spark 网站[http://spark.apache.org/](http://spark.apache.org/)。

我总是对听到人们的声音很感兴趣，并与 LinkedIn 等网站上的人们建立联系。 我渴望听到人们参与的项目和新的机会。 我很想听听关于 Apache Spark 的情况，您是如何使用它的，以及您构建的系统是否得到了规模化使用。 我可以在领英上联系到：[linkedin.com/profile/view？id=73219349](http://linkedin.com/profile/view?id=73219349)。

或者，可以通过我的网站[http://semtech-solutions.co.nz/](http://semtech-solutions.co.nz/)联系我，或者最后通过电子邮件联系我：`<[info@semtech-solutions.co.nz](mailto:info@semtech-solutions.co.nz)>`。