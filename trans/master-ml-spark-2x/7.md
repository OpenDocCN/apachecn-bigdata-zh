# 使用 GraphX 进行图形分析

在我们这个相互联系的世界里，图形无处不在。**万维网** ( **WWW** )只是一个复杂结构的例子，我们可以考虑一个图，其中网页表示通过它们之间的传入和传出链接连接的实体。在脸书的社交图中，数百万用户组成了一个网络，将全球的朋友联系在一起。我们今天看到的和可以收集数据的许多其他重要结构都配备了自然图形结构；也就是说，在一个非常基本的层面上，它们可以被理解为*顶点*的集合，这些顶点通过我们称之为*边*以某种方式相互连接。概括地说，这个观察反映了图形是多么普遍。有价值的是，这些图是经过充分研究的结构，有许多算法可以让我们获得关于这些图代表什么的重要见解。

Spark 的 GraphX 库是研究大规模图形的天然切入点。利用来自 Spark 核心的 rdd 对顶点和边进行编码，我们可以使用 GraphX 对大量数据进行图形分析。要进行概述，您将在本章中了解以下主题:

*   基本图形属性和重要图形操作
*   GraphX 如何表示属性图以及如何使用它们
*   以各种方式加载图形数据，并生成合成图形数据进行实验
*   使用 GraphX 的核心引擎的基本图形属性
*   使用名为 Gephi 的开源工具可视化图形
*   使用 GraphX 的两个关键 API 实现高效的图形并行算法。
*   使用图形框架，将数据框架扩展到图形，并使用优雅的查询语言研究图形
*   在社交图上运行 GraphX 中可用的重要图形算法，包括转发和一起出现在电影中的演员的图形

# 基本图论

在深入研究 Spark GraphX 及其应用之前，我们将首先在基本层面上定义图，并解释它们可能具有哪些属性，以及在我们的上下文中哪些结构值得研究。在介绍这些性质的过程中，我们将给出更多我们在日常生活中考虑的具体的图的例子。

# 图形

为了形式化引言中简要描述的图的概念，在纯数学层面上，图 *G = (V，E)* 可以描述为一对*顶点* V 和*边* E，如下所示:

*V = {v <sub class="calibre25">1</sub> ，...，v <sub class="calibre25">n</sub> }*

*E = {e <sub class="calibre25">1</sub> ，...，e <sub class="calibre25">m</sub> }*

我们称 V 中的元素 *v <sub class="calibre25">i</sub>* 为顶点，*E<sub class="calibre25">I</sub>*E 为边，其中每条边连接两个顶点*V<sub class="calibre25">1</sub>T11】和*V<sub class="calibre25">2</sub>T15】实际上只是一对顶点，即 *e <sub class="calibre25">i</sub> = (v <sub class="calibre25">1</sub> ，v <sub class="calibre25">让我们构建一个由五个顶点和六条边组成的简单图，如下图数据所示:</sub>***

*V ={v <sub class="calibre25">1</sub> ，v <sub class="calibre25">2</sub> ，v <sub class="calibre25">3</sub> ，v <sub class="calibre25">4</sub> ，v <sub class="calibre25">5</sub> }*

*E = {e <sub class="calibre25">1</sub> = (v <sub class="calibre25">1</sub> ，v <sub class="calibre25">2</sub> ，e <sub class="calibre25">2</sub> = (v <sub class="calibre25">1</sub> ，v <sub class="calibre25">3</sub> ，e <sub class="calibre25">3</sub> = (v <sub class="calibre25">2</sub> ，v <sub class="calibre25">3</sub> )，*

*e <sub class="calibre25">4</sub> = (v <sub class="calibre25">3</sub> ，v <sub class="calibre25">4</sub> )，e <sub class="calibre25">5</sub> = (v <sub class="calibre25">4</sub> ，v <sub class="calibre25">1</sub> ，e <sub class="calibre25">6</sub> = (v <sub class="calibre25">4</sub> ，v <sub class="calibre25">5</sub> )}*

这是图表的样子:

![](../images/00152.jpeg)

Figure 1: A simple undirected graph with five vertices and six edges

注意在*图 1* 中的图的实现中，节点彼此之间的相对位置、边的长度以及其他视觉属性对于图来说是不重要的。事实上，我们可以通过变形以任何其他方式显示该图形。图形定义完全决定了其*拓扑*。

# 有向图和无向图

按照惯例，在构成边 *e* 的一对顶点中，我们称第一个顶点为*源*，第二个顶点为*目标*。这里自然的解释是，边 *e* 所代表的连接有一个*方向；*从源头流向目标。注意在*图 1* 中，显示的图形是无向的；也就是说，我们没有区分来源和目标。

使用完全相同的定义，我们可以创建图形的有向版本，如下图所示。请注意，该图在呈现方式上略有不同，但顶点和边的连接保持不变:

![](../images/00153.jpeg)

Figure 2: A directed graph with the same topology as the previous one. In fact, forgetting edge directions would yield the same graph as in Figure 1

每个有向图自然都有一个相关联的无向图，通过简单地忘记所有的边方向来实现。从实际的角度来看，大多数图的实现本质上都是建立在有向边上的，并且在需要时会抑制方向的附加信息。举个例子，把前面的图想象成一组由关系连接的五个人，*友谊*。我们可能会说友谊是一种对称的属性，因为如果你是我的朋友，我也是你的朋友。根据这种解释，方向性在这个例子中不是一个非常有用的概念，所以实际上，我们最好把它当作一个无向图的例子。相比之下，如果我们运行一个允许用户主动向其他用户发送好友请求的社交网络，有向图可能更好地编码这些信息。

# 顺序和程度

对于任何有向或无向的图，我们都可以在本章后面读到一些感兴趣的基本性质。我们称顶点数|V|图的*阶*和边数|E|其*度*，有时也称其*化合价*。顶点的度数是将该顶点作为源或目标的边的数量。在有向图和给定顶点 *v* 的情况下，我们可以额外区分*内角* *、*即所有指向 *v* 的边之和，*外角*即所有从 *v* 开始的边之和。举个例子，*图 1* 中的无向图有 5 阶 6 次，与*图 2* 中的有向图相同。在后者中，顶点 v1 具有 2 度外和 1 度内，而 v5 具有 0 度外和 1 度内。

在最后两个例子中，我们用顶点和边各自的标识符来标注它们，如定义 *G = (V，E)* 所指定的。对于随后的大多数图形可视化，我们将假设顶点和边的身份是隐式已知的，而是通过用附加信息标记我们的图形来表示它们。我们明确区分标识符和标签的原因是 GraphX 标识符不能是字符串，我们将在下一节中看到这一点。下图显示了一个带有一组人的关系的标记图的示例:

![](../images/00154.jpeg)

Figure 3: A directed labelled graph showing a group of people and their relationships

# 有向无环图

我们要讨论的下一个概念是无环性。*循环图*是这样一种图，其中至少有一个顶点有一条通过该图的路径，将该顶点与其自身连接起来。我们称这样的道路为*循环*。在无向图中，任何创建循环的链都可以，而在有向图中，如果我们可以通过跟随有向边到达起始顶点，我们就只谈论循环。例如，考虑一下我们之前看到的一些图表。在*图 2* 中，正好有一个由 *{e2，e4，e5}* 形成的循环，而在其无向版本中，如图 1*图 1* 所示，正好有两个循环，即 *{e2，e4，e5}* 和 *{e1，e 2，e3}* 。

这里有几个循环图的特例值得一提。首先，如果一个顶点通过单条边连接到它自己，我们会说这个图有一个*循环*。其次，一个不包含任何双环的有向图，也就是说，在两个方向上都没有由边连接的顶点对，称为*定向* *图*。第三，有三个环的图被称为包含*个三角形*。三角形的概念是一个重要的概念，因为它经常被用来评估图的连通性，我们将在后面讨论。下图显示了具有不同类型循环的人工示例:

![](../images/00155.jpeg)

Figure 4: A toy graph illustrating loops or self-edges, two-loops and triangles.

一般来说，研究任意自然数的图中的 n-环 *n* 可以告诉你很多关于图的事情，但是三角形是最常见的。由于有向循环不仅计算成本更高，而且比它们的无向图更少，我们通常只在图中寻找无向三角形；也就是说，我们会忘记它的定向结构。

在许多应用中反复出现的一类重要图是**有向无环图** ( **DAGs** )。我们已经从最后一段知道了什么是 DAG，即没有循环的有向图，但是由于 DAG 是如此普遍，我们应该在它们上面多花一点时间。

在这之前的所有章节中，我们都隐含地使用了 DAG 的一个实例，那就是 Spark 的作业执行图。请记住，任何 Spark 作业都由按特定顺序执行的阶段组成。阶段由在每个分区上执行的任务组成，其中一些任务可能是独立的，而其他任务则相互依赖。因此，我们可以将 Spark 作业的执行解释为由作为顶点的阶段(或任务)组成的有向图，其中一条边表示下一个阶段所需的一个计算的输出。典型的例子可能是需要前一映射级输出的缩减级。自然地，这个执行图不包含任何循环，因为这将意味着我们要无限地将一些操作符的输出馈送到图中，防止我们的程序最终停止。因此，这个执行图可以表示为，并且实际上是在 Spark 调度器中实现的，如 DAG:

![](../images/00156.jpeg)

Figure 5: Visualizing a chain of operations carried out on RDDs with Spark. The execution graph is by definition a DAG.

# 连接的组件

图的另一个重要性质是*连通性*。如果有一条边的路径连接我们选择的任意两个顶点，不管边的方向如何，那么这个图就是*连通的*。所以，对于有向图，我们完全忽略了这个定义的方向。有向图的连通性有什么更严格的定义？如果任意两个顶点通过有向边链相连，则称该图为*强连通*。请注意，强连通性是强加给有向图的一个非常强的假设。特别地，任何强连通图都是循环的。这些定义允许我们定义紧密相关的(强)连接组件的概念。每个图都可以分解成连通的组成部分。如果它是连接的，那么正好有一个这样的组件。如果不是，至少有两个。形式上定义，连通分支是给定图中仍然连通的最大子图。强连接组件也是如此。连通性是一个重要的度量，因为它允许我们将图的顶点聚类成自然属于一起的组。

例如，人们可能对社交图中表示友谊的连接组件的数量感兴趣。在一个小图中，可能有许多独立的组件。然而，图越大，人们可能会怀疑它更有可能只有一个连接的组件，遵循普遍接受的原理，即每个人都通过大约六个连接相互连接。

我们将在下一节看到如何用 GraphX 计算连接的组件；现在，让我们只检查一个简单的例子。在下图*、*中，我们看到一个有十二个顶点的有向图:

![](../images/00157.jpeg)

Figure 6: Connected and strongly connected components can easily be read off in small graphs, but this becomes increasingly difficult for larger graphs.

我们可以立即看到它有三个相连的组件，即三组顶点 *{1，2，3}，{4，5}* ，以及 *{6，7，8，9，10，11，12}* 。对于强连接的组件，这需要比快速目视检查多一点的努力。我们可以看到 *{4，5}* 形成了一个强连接的组件， *{8，9，10，11}* 也是如此。所有其他六个顶点形成它们自己的强连通分量，也就是说，它们是孤立的。这个例子继续表明，对于一个有数百万顶点的大规模图形，使用正确的可视化工具，我们可能会幸运地找到大致连接的组件，但是强连接的组件计算起来有点复杂，这只是 Spark GraphX 派上用场的一个用例。

# 树

有了连通分量的定义，我们可以转向另一类有趣的图，即树。*树*是一个连通图，其中有一条路径将任意给定的顶点连接到另一个顶点。由一组不相连的树组成的图叫做森林。在下图中，我们看到了在众所周知的 Iris 数据集上运行的示意性*决策树*。请注意，这只是为了说明，也就是说，为了展示如何将该算法的输出视为一个图形:

![](../images/00158.jpeg)

Figure 7: A simple decision tree ran on Iris, classifying into the three categories Setosa, Virginica and Versicolor by means of two features, namely petal length (PL) and petal width (PW)

# 多重图

一般来说，没有环或多条边的图叫做*简单的*。我们将在本章的应用中遇到的大多数图都不具有这个性质。通常，根据真实数据构建的图形在顶点之间会有多条边。在文献中，有多条边的图被称为多图或伪图。在这一章中，我们将坚持多重图的概念，并遵循这样一个惯例，即这样的多重图也可以包括循环。由于 Spark 支持多图(包括循环)，这个概念在应用中非常有用。在下图中，我们看到一个具有多个连通分量的复杂多重图:

![](../images/00159.jpeg)

Figure 8: A slightly more involved social multigraph with loops and multiple edges.

# 属性图

在我们继续介绍 GraphX 作为一个图形处理引擎之前，让我们看看我们以前见过的图形的扩展。我们已经将标记图视为命名顶点和边的一种便捷方式。一般来说，我们将在应用程序中考虑的图形数据将有更多的信息附加到顶点和边上，我们需要一种方法来在图形中建模这些附加信息。为此，我们可以利用*属性图*的概念。

从图形作为一对顶点和边的基本定义来看，不可能直接将附加信息附加到这两个结构上。历史上，避免这种情况的一种方法是放大图，创建更多对应于属性的顶点，这些顶点通过编码与新顶点关系的新边与原始顶点相连。例如，在我们前面的朋友图的例子中，如果我们也想在我们的图中编码家庭地址，代表一个人的每个顶点必须连接到代表他们的地址的顶点，它们之间的边*位于*。不需要太多的想象就能意识到这种方法会产生很大的复杂性，尤其是当顶点属性相互关联的时候。在所谓的**资源描述框架** ( **RDF** )中，通过主谓宾*三元组*来表示图中的属性，其结果被称为 RDF 模型。rdf 本身就是一个主题，比我们介绍的要灵活一点。无论如何，熟悉这个概念并理解它的局限性是好的。

相反，在*属性图*中，我们可以用基本上任意的附加结构来增加顶点和边。和任何事情一样，在这种普遍性中获得灵活性通常是一种权衡。在我们的例子中，在许多图数据库中实现的基本图允许对查询进行强大的优化，而对于属性图，当涉及到性能时，我们应该小心。当我们展示 Spark GraphX 如何实现属性图时，我们将在下一节更详细地讨论这个主题。

在本章的其余部分，我们将对属性图使用以下约定。附加到顶点的附加数据称为*顶点数据*，用于边的附加数据称为*边数据*。为了给出一个更复杂的顶点和边数据的例子，请看下图来扩展我们的朋友图。此示例还显示了我们所说的*三元组*的含义，即一条边及其相邻顶点及其所有属性:

![](../images/00160.jpeg)

Figure 9: A property graph showing friends augmented by address data, connected by more than one relation. Property data is encoded in JSON format.

请注意，在前面的例子中，我们故意保持简单，但是在更现实的场景中，我们需要嵌套的数据结构——例如，回答欠了多少钱以及什么时候到期。

在我们的上下文中，属性图的一个有趣的特殊情况是*加权图*，其中边、顶点或两者都有权重，例如，整数或浮点数附加在它们上面。这方面的一个典型例子是由一组城市作为顶点组成的图，连接它们的边表示位置之间的距离。在这种情况下会出现一些经典问题。一个例子是找到两个给定城市之间的最短路径。一个相关的问题是*旅行推销员问题*，在这个问题中，一个假设的推销员被要求使用尽可能短的路线访问每个城市。

作为本节的结束语，重要的是要知道，在文献中，有一个广泛使用的顶点同义概念，即节点。我们在这里不使用这个术语，因为在 Spark 的上下文中，它可能很容易与工作人员执行任务的计算节点混淆。相反，我们将在整个章节中坚持顶点。同样，每当我们谈到一个图，我们通常假设它是一个*有限的* *图*，也就是说，顶点和边的数量是有限的，这在实践中很难算作限制。

# GraphX 分布式图形处理引擎

除了我们在本书中已经遇到过几次的用于机器学习的 Spark MLlib，以及我们将在、*借贷俱乐部贷款预测*中介绍的 Spark Streaming 等，Spark GraphX 是 Spark 生态圈的核心组件之一。GraphX 是为通过构建在 RDDs 之上以高效的方式处理大型图形而定制的。

使用上一节中开发的命名法，GraphX 中的图是一个带循环的有限多重图，这里所说的*图*，实际上指的是前面讨论的属性图扩展。接下来，我们将看到图形是如何在 GraphX 内部构建的。

对于所使用的例子，我们建议在本地启动`spark-shell`，这将自动为 GraphX 提供依赖关系。要测试这在您的设置中是否正常工作，请尝试使用 Scala 的通配符运算符导入完整的 GraphX 核心模块，如下所示:

```
import org.apache.spark.graphx._
```

在屏幕上，您应该会看到以下提示:

![](../images/00161.jpeg)

如果您更愿意按照示例使用 sbt 构建包，您应该在您的`build.sbt`中包含以下`libraryDependencies`:

```
"org.apache.spark" %% "spark-graphx" % "2.1.1"
```

这样做应该允许您导入 GraphX，如前所示，创建一个您选择的应用程序，您可以用 spark-submit 来调用它。

# GraphX 中的图形表示

回想一下，对于我们来说，属性图是一个有向多重图，它的循环具有顶点和边的自定义数据对象。GraphX 的中心入口点是`Graph` API，它有以下签名:

```
class Graph[VD, ED] {val vertices: VertexRDD[VD]val edges: EdgeRDD[ED]}
```

因此，在内部，GraphX 中的图由一个顶点 RDD 编码和一个边表示。这里`VD`是顶点数据类型，`ED`是我们属性图的边数据类型。我们将更详细地讨论`VertexRDD`和`EdgeRDD`，因为它们对于接下来的内容至关重要。

在 Spark GraphX 中，顶点具有`Long`类型的唯一标识符，称为`VertexId`。事实上，`VertexRDD[VD]`只是`RDD[(VertexId, VD)]`的一个扩展，但是经过了优化，并且包含了我们将详细讨论的一系列实用功能。因此，简单地说，GraphX 中的顶点是带有标识符和顶点数据的 rdd，这与早期开发的直觉是齐头并进的。

为了解释`EdgeRDD`的概念，让我们快速解释一下`Edge`在 GraphX 中是什么。在简化形式中，`Edge`由以下签名定义:

```
case class Edge[ED] (var srcId: VertexId,var dstId: VertexId,var attr: ED)
```

因此，边完全由源顶点标识(由`srcId`给出)、目标或目的顶点标识(作为`dstId`提供)和`ED`数据类型的属性对象`attr`确定。类似于前面的顶点 RDDs，我们可以把`EdgeRDD[ED]`理解为`RDD[Edge[ED]]`的延伸。因此，GraphX 中的边是由`ED`类型的边的 RDD 给出的，这也与我们到目前为止讨论的一致。

We now know that as of Spark 2.1, graphs in GraphX are essentially pairs of vertex and edge RDDs. This is important information, as it allows us, in principle, to apply the full functionality and power of RDDs from Spark core to these graphs. As a word of warning, though, graphs come with a lot of functionality that is optimized for the purpose of graph processing. Whenever you find yourself using basic RDD functionality, see if you can find a specific graph equivalent, which will likely be more performant.

举一个具体的例子，让我们用刚刚学到的知识从头开始构建一个图。我们假设您有一个可用的 Spark 上下文`sc`。我们将创建一个人与人相互连接的图，即上一节*图 3* 中的图，即一个带标签的图。在我们刚刚获得的 GraphX 语言中，为了创建这样的图，我们需要顶点和边数据类型都是`String`类型。我们通过使用`parallelize`来创建顶点，如下所示:

```
import org.apache.spark.rdd.RDDval vertices: RDD[(VertexId, String)] = sc.parallelize(Array((1L, "Anne"),(2L, "Bernie"),(3L, "Chris"),(4L, "Don"),(5L, "Edgar")))
```

同样，我们可以创建边；注意以下定义中`Edge`的使用:

```
val edges: RDD[Edge[String]] = sc.parallelize(Array(Edge(1L, 2L, "likes"),Edge(2L, 3L, "trusts"),Edge(3L, 4L, "believes"),Edge(4L, 5L, "worships"),Edge(1L, 3L, "loves"),Edge(4L, 1L, "dislikes")))
```

准备好这两个 rdd 就足以创建`Graph`，就像下面的行一样简单:

```
val friendGraph: Graph[String, String] = Graph(vertices, edges)
```

请注意，我们明确写出了所有变量的类型，这只是为了清晰起见。我们可以忽略它们，依靠 Scala 编译器来为我们推断它们。此外，如前面的签名所示，我们可以使用`friendGraph.vertices`访问顶点，使用`friendGraph.edges`访问边。为了让我们第一次看到什么是可能的，我们现在可以收集所有的顶点并打印如下:

```
friendGraph.vertices.collect.foreach(println)
```

以下是输出:

![](../images/00162.jpeg)

请注意，这并不使用任何特定于 GraphX 的功能，只是我们从 RDDs 中已经知道的功能。作为另一个例子，让我们计算源标识大于目标标识的所有边。这可以通过以下方式实现:

```
friendGraph.edges.map( e => e.srcId > e.dstId ).filter(_ == true).count
```

这给出了预期的答案，即`1`，但有一个缺点。一旦我们在图上调用`.edges`，我们就完全失去了之前拥有的所有图结构。假设我们想进一步处理一个有变换边的图，这不是办法。在这种情况下，最好使用内置的`Graph`功能，如下面的`mapEdges`方法:

```
val mappedEdgeGraph: Graph[String, Boolean] = friendGraph.mapEdges( e => e.srcId > e.dstId )
```

请注意，这种情况下的返回值仍然是一个图形，但是边缘数据类型现在是`Boolean`，正如预期的那样。稍后我们将看到更多图形处理可能性的例子。看完这个例子，让我们后退一步，讨论为什么 Spark GraphX 会像现在这样实现图形。一个原因是我们可以有效地利用*数据并行度*和*图形并行度。*在前面的章节中，我们已经遇到了 Spark 中的 RDDs 和数据帧如何通过将数据保存在每个节点的内存中，从而在分区之间分配数据来利用数据并行性。所以，如果我们只关注顶点或边本身，而不想研究它们之间的关系，那么使用顶点和边 RDDs 将会非常高效。

相反，我们所说的图形并行性是指相对于图形概念并行执行的操作*。例如，一个图形并行任务将是对每个顶点的所有入站边的权重求和。为了执行这个任务，我们需要处理顶点和边缘数据，这涉及到多个关系数据库。有效地做到这一点需要一个合适的内部代表。GraphX 试图在这两种范式之间取得平衡，这是很少有其他替代程序提供的。*

# 图形属性和操作

看到另一个人工示例后，接下来让我们转向一个更有趣的示例，我们将使用它来研究我们在上一节中研究的一些核心属性。我们将在本章中考虑的数据可以在[http://networkrepository.com/](http://networkrepository.com/)找到，这是一个开放的网络数据仓库，有大量有趣的数据。首先，我们将加载一个从推特上检索到的相对较小的数据集，可以从[http://networkrepository.com/rt-occupywallstnyc.php](http://networkrepository.com/rt-occupywallstnyc.php)下载。下载本页提供的 zip 文件，即 store rt_occupywallstnyc.zip 并解包访问文件 rt_occupywallstnyc.edges，文件为 CSV 格式，以逗号作为分隔符。每行代表一条关于纽约市“T4 占领华尔街”运动的推文转发。前两列显示推特用户标识，第三列代表转发的标识；也就是说，第二列中的用户转发了第一列中相应用户的推文。

前十项如下:

```
3212,221,13479297253212,3301,13479237143212,1801,13477143103212,1491,13479240003212,1483,13479236913212,1872,13479396901486,1783,13461813812382,3350,13466754172382,1783,13429253182159,349,1347911999
```

例如，我们可以看到来自用户 3，212 的推文至少被转发了六次，但是由于我们不知道该文件是否以任何方式排序，并且包含大约 3.6k 个顶点，我们应该利用 GraphX 来为我们回答这些问题。

为了构建一个图，我们将首先通过使用基本的 Spark 功能从这个文件创建一个边的 RDD，也就是`RDD[Edge[Long]]`:

```
val edges: RDD[Edge[Long]] =sc.textFile("./rt_occupywallstnyc.edges").map { line =>val fields = line.split(",")Edge(fields(0).toLong, fields(1).toLong, fields(2).toLong)}
```

回想一下，GraphX 中的 id 都是`Long`类型的，这就是为什么我们在加载文本文件并用逗号将每一行拆分后，将所有的值都强制转换为`Long`；也就是说，我们在这种情况下的边缘数据类型是`Long`。这里，我们假设所讨论的文件位于我们在其中启动`spark-shell`的同一文件夹中；如有必要，根据您的需求进行调整。有了这样的优势 RDD，我们现在可以使用`Graph`伴随对象的`fromEdges`方法如下:

```
val rtGraph: Graph[String, Long] = Graph.fromEdges(edges, defaultValue =  "")
```

我们需要为这个方法提供`edges`可能并不奇怪，但是`defaultValue`这个关键词值得一些解释。请注意，到目前为止，我们只知道边，虽然顶点标识作为边的源和目标是隐式可用的，但我们仍然没有确定任何 GraphX 图所需的顶点数据类型`VD`。`defaultValue`允许您创建一个默认的顶点数据值，该值带有一个类型。在我们的例子中，我们选择了一个空字符串，这解释了`rtGraph`的签名。

随着第一个真实数据图的加载，让我们检查一些基本属性。使用前面的符号，图的*阶*和*度*可以计算如下:

```
val order = rtGraph.numVerticesval degree = rtGraph.numEdges
```

前面的代码将分别产生 3，609 和 3，936。至于单个顶点的度数，GraphX 提供了 Graphs 上的`degrees`方法，返回一个整数顶点数据类型的图，用于存储度数。让我们计算转发图的平均度:

```
val avgDegree = rtGraph.degrees.map(_._2).reduce(_ + _) / order.toDouble
```

这个运算的结果应该大致是`2.18`，也就是说每个顶点平均约有两条边与之相连。在这个简洁的操作中使用的符号可能看起来有点密集，主要是因为使用了许多通配符，所以让我们稍微剖析一下。为了解释这一点，我们首先称之为学位，如前所述。之后，我们仅通过映射到该对的第二项来提取度数；也就是说，我们忘记了顶点标识。这就给我们留下了一个整数值的 RDD，我们可以通过加法来减少它。最后一步是铸造`order.toDouble`以确保我们得到浮动除法，然后除以这个总数。下一个代码清单更详细地显示了同样的四个步骤:

```
val vertexDegrees: VertexRDD[Int] = rtGraph.degreesval degrees: RDD[Int] = vertexDegrees.map(v => v._2)val sumDegrees: Int = degrees.reduce((v1, v2) => v1 + v2 )val avgDegreeAlt = sumDegrees / order.toDouble
```

接下来，我们通过简单地分别调用`inDegrees`和`outDegrees`来计算这个有向图的进度和出度。为了让事情更有趣，让我们计算图中所有顶点的最大进度和最小出度，并返回它的 ID。我们首先解决最大的学位问题:

```
val maxInDegree: (Long, Int) = rtGraph.inDegrees.reduce((v1,v2) => if (v1._2 > v2._2) v1 else v2)
```

进行这个计算，你应该看到 ID 为`1783`的顶点有 in 度 401，意思是这个 ID 的用户转发了 401 条不同的推文。所以，一个有趣的后续问题是，“这个用户转发了多少不同的用户？”同样，我们可以通过计算该目标在所有边缘的不同来源来快速回答这个问题:

```
rtGraph.edges.filter(e => e.dstId == 1783).map(_.srcId).distinct()
```

执行这个命令应该会提示 34，所以平均来说，用户`1783`在这个数据集中从任何给定用户转发了大约 12 条推文。这反过来意味着我们找到了一个有意义的多重图的例子——在这个图中有成对的顶点，它们之间有许多不同的联系。现在回答最低学位的问题很简单:

```
val minOutDegree: (Long, Int) = rtGraph.outDegrees.reduce((v1,v2) => if (v1._2 < v2._2) v1 else v2)
```

这种情况下的答案是`1`，也就是说在这个数据集中，每条推文至少被转发过一次。

回想一下，属性图的*三元组*由一条边及其数据，以及两个连接顶点及其各自的数据组成。在 Spark GraphX 中，这个概念是在一个名为`EdgeTriplet`的类中实现的，在这个类中我们可以通过`srcAttr`、`dstAttr`、`srcId`和`dstId`自然地将边缘数据检索为`attr`以及顶点数据和 IDs。要为我们的转发图获取三元组，我们可以简单地调用以下内容:

```
val triplets: RDD[EdgeTriplet[String, Long]] = rtGraph.triplets
```

三元组通常被证明是实用的，因为我们可以直接检索相应的边和顶点数据，否则这些数据将存在于图中单独的关系数据库中。例如，我们可以通过执行以下命令，快速转换生成的三元组，为每个转发提供一些可读的数据:

```
val tweetStrings = triplets.map(t => t.dstId + " retweeted " + t.attr + " from " + t.srcId)tweetStrings.take(5)
```

前面的代码产生以下输出:

![](../images/00163.jpeg)

当我们之前讨论`friendGraph`示例时，我们注意到`mapEdges`在某些方面优于先呼叫`edges`然后呼叫`map`他们。顶点和三元组也是如此。假设我们想将我们的图的顶点数据简单地更改为顶点标识，而不是之前选择的默认值。这可以通过如下映射顶点来最快速有效地实现:

```
val vertexIdData: Graph[Long, Long] = rtGraph.mapVertices( (id, _) => id)
```

类似地，我们可以从初始图开始，直接使用`mapTriplets`转换三元组，返回一个带有修改过的边缘数据的 graph 对象，而不是先检索三元组。为了达到与前面`tweetStrings`相同的效果，但保持图形结构不变，我们可以运行以下内容:

```
val mappedTripletsGraph = rtGraph.mapTriplets(t => t.dstId + " retweeted " + t.attr + " from " + t.srcId)
```

作为基本图形处理功能的最后一个示例，我们现在将查看给定图形的子图形以及如何将图形相互连接。考虑提取我们图表中所有被转发至少 10 次的推特用户的信息的任务。我们已经看到了如何从`rtGraph.outDegrees`获得外度数。为了使这些信息在我们的原始图中可以访问，我们需要将这些信息加入其中。为此，GraphX 已经具备了`outerJoinVertices`提供的功能。为此，我们需要提供一个顶点数据类型为`U`的`VertexRDD`，与一个确定如何聚合顶点数据的函数连接。如果我们叫 RDD 加入`other`，这在纸面上看起来如下:

```
def outerJoinVertices[U, VD2](other: RDD[(VertexId, U)])(mapFunc: (VertexId, VD, Option[U]) => VD2): Graph[VD2, ED]
```

请注意，因为我们执行外部连接，所以不是原始图中的所有标识都可能在`other`中有相应的值，这就是为什么我们在各自的映射函数中看到`Option`类型。为我们手头的具体例子这样做的工作如下:

```
val outDegreeGraph: Graph[Long, Long] =rtGraph.outerJoinVertices[Int, Long](rtGraph.outDegrees)(mapFunc = (id, origData, outDeg) => outDeg.getOrElse(0).toLong)
```

我们用出度`VertexRDD`加入我们的原始图，作为映射函数，我们简单地丢弃原始顶点数据并用出度替换它。如果没有可用的外学位，我们只需使用`getOrElse`将其设置为`0`即可解决`Option`。

接下来，我们要检索这个图的子图，其中每个顶点至少有 10 次转发。图的子图由原始顶点和边的子集组成。在形式上，我们将子图定义为边、顶点或两者上的*谓词*的结果。这里，我们指的是在顶点或边上求值的表达式，它返回真或假。图的子图方法的特征定义如下:

```
def subgraph(epred: EdgeTriplet[VD,ED] => Boolean = (x => true),vpred: (VertexId, VD) => Boolean = ((v, d) => true)): Graph[VD, ED]
```

注意，由于提供了默认功能，我们可以选择只提供`vpred`或`epred`中的一个。在我们的具体示例中，我们希望限制到至少具有`10`度的顶点，这可以如下进行:

```
val tenOrMoreRetweets = outDegreeGraph.subgraph(vpred = (id, deg) => deg >= 10)tenOrMoreRetweets.vertices.counttenOrMoreRetweets.edges.count
```

生成的图只有`10`个顶点和`5`条边，但有趣的是，这些影响者之间的联系似乎和平均值差不多。

为了结束这一部分，一个有趣的技巧是*掩蔽*。假设我们现在想知道转发次数少于 10 次的顶点的子图，这与前面的`tenOrMoreRetweets`有些相反。当然，这可以通过子图定义来完成，但是我们也可以通过`tenOrMoreRetweets`来屏蔽原始图，如下所示:

```
val lessThanTenRetweets = rtGraph.mask(tenOrMoreRetweets)
```

如果我们愿意，我们可以通过将`tenOrMoreRetweets`连接到`lessThanTenRetweets`来重建`rtGraph`。

# 构建和加载图表

在最后一节中，我们在图形分析方面留了很多余地，并讨论了一个有趣的转发图。在我们深入更复杂的操作之前，让我们后退一步，考虑用 GraphX 构造图的其他选项。完成这段插曲后，我们将快速了解可视化工具，然后转向更复杂的应用程序。

事实上，我们已经看到了两种创建 GraphX 图的方法，一种是显式地构造顶点和边 RDDs，我们自己，从它构造一个图；另一个是使用`Graph.fromEdges`。另一个非常方便的可能性是加载一个所谓的*边缘列表文件*。这种格式的一个例子如下:

```
1 35 34 23 21 5
```

因此，边列表文件是每行有多对标识的文本文件，用空格隔开。假设我们将前面的数据存储为当前工作目录中的`edge_list.txt`，我们可以使用`GraphLoader`界面从其中一行加载一个图形对象:

```
import org.apache.spark.graphx.GraphLoaderval edgeListGraph = GraphLoader.edgeListFile(sc, "./edge_list.txt")
```

鉴于我们以正确的格式提供了数据，这是一个非常方便的入口点。不过，在加载边列表文件后，必须将额外的顶点和边数据连接到结果图中。根据前面的数据构建图形的另一种类似方法是使用由`Graph`对象提供的`fromEdgeTuples`方法，该方法可以如下面的代码片段所示使用:

```
val rawEdges: RDD[(VertexId, VertexId)] = sc.textFile("./edge_list.txt").map { line =>val field = line.split(" ")(field(0).toLong, field(1).toLong)}val edgeTupleGraph = Graph.fromEdgeTuples(rawEdges=rawEdges, defaultValue="")
```

与前面的构造不同的是，我们创建了一个包含成对顶点标识的原始边 RDD，这些标识与顶点数据的默认值一起输入到图的构造中。

在最后这个例子中，我们基本上已经看到了 GraphX 中当前支持的从给定数据加载图形的每一种方式。然而，也有可能*生成*随机的确定性图，这对测试、快速健全性检查和演示非常有帮助。为此，我们导入以下类:

```
import org.apache.spark.graphx.util.GraphGenerators
```

这个类有很多功能可以提供。这两种确定性图形构建方法有助于构建*星形*和*网格*图形。星形图由一个中心顶点和几个仅通过一条边与中心顶点相连的顶点组成。下面是如何创建一个有十个顶点连接到中心顶点的星形图:

```
val starGraph = GraphGenerators.starGraph(sc, 11)
```

下图是星形图的图形表示:

![](../images/00164.jpeg)

Figure 10: A star graph with ten vertices surrounding a central one.

另一种确定性的图形创建方法是构建一个网格，这意味着顶点被组织成一个矩阵，每个顶点都垂直和水平地连接到它的直接邻居。在具有 *n* 行和 *m* 列的网格图中，精确地存在 *n(m-1) + m(n-1)* 条边-第一项用于所有垂直连接，第二项用于所有水平网格连接。这是如何在 GraphX 中建立一个有 40 条边的`5`乘以`5`的网格:

```
val gridGraph = GraphGenerators.gridGraph(sc, 5, 5)
```

![](../images/00165.jpeg)

Figure 11: A quadratic 3 by 3 grid graph with twelve vertices.

就随机图而言，我们将介绍一种在结构上近似反映许多真实世界图的创建方法，即*对数正态图*。现实生活中发现的许多结构遵循一个*幂律*，其中一个实体的度量是由另一个实体的力量给出的。一个具体的例子是帕累托原则，通常被称为 80/20 原则，这意味着 80%的财富被 20%的人拥有，也就是说，大多数财富归少数人所有。这个的一个变种，叫做*齐夫定律，*适用于我们的场景，即少数顶点具有非常高的度数，而大多数具有非常少的连接。在社交图的背景下，很少有人会有很多追随者，而大多数人的追随者很少。这导致顶点度数的分布遵循*对数正态分布。*图 10 中的星形图是这种行为的极端变体，其中所有边都以一个顶点为中心。

在 graphX 中创建一个有 20 个顶点的对数正态图，简单如下:

```
val logNormalGraph  = GraphGenerators.logNormalGraph(sc, numVertices = 20, mu=1, sigma = 3)
```

在前面的代码片段中，我们还规定了每个顶点一个外度数的平均值和三个标准差。让我们看看是否能确定顶点出度的对数正态分布:

```
logNormalGraph.outDegrees.map(_._2).collect().sorted
```

这将产生一个 Scala 数组，如下所示。

![](../images/00166.jpeg)

请注意，您可能会得到不同的结果，因为图形是随机生成的。接下来，让我们看看如何可视化我们到目前为止构建的一些图形。

# 用 Gephi 可视化图形

GraphX 没有内置的图形可视化工具，所以对于我们来说，为了解决可视化海量图形的问题，我们必须考虑其他选项。有许多通用的可视化库，以及一些专门的图形可视化工具。在本章中，我们选择 *Gephi* 本质上有两个原因:

*   这是一个免费的开源工具，适用于所有主要平台
*   我们可以利用一种简单的交换格式 GEXF 来保存 GraphX 图形，并且可以将它们加载到 Gephi 图形用户界面中，用它指定可视化

虽然第一点应该被普遍认为是一个优点，但并不是每个人都是图形用户界面的粉丝，大多数开发人员更倾向于通过编程来定义可视化。请注意，这在 Gephi 中实际上也是可能的，但稍后会对此进行更多说明。我们选择上述方法的原因是，通过仍然使用 Gephi 提供的强大可视化功能，保持该书自成一体，只包含关于 Spark 的编码部分。

# 杰吉

首先，从[https://gephi.org/](https://gephi.org/)下载 Gephi，并在你的机器上本地安装。在写这本书的时候，稳定版是 0.9.1，我们会通篇使用。打开 Gephi 应用程序后，会提示您一条欢迎消息，您可以从几个示例中进行选择。我们将使用`Les Miserables.gexf`来熟悉工具。我们将在后面更详细地讨论 GEXF 文件格式；现在，让我们只关注应用程序。该示例的基础图形数据由表示作品角色的顶点*悲惨世界*和表示角色关联的边*组成，这些边通过评估连接的重要性来加权*。

Gephi 是一个非常丰富的工具，我们在这里只能讨论几个基础。打开前面的文件后，您应该已经看到了示例图的预览。Gephi 有三个主要观点:

*   **概述**:这是我们可以操纵图形所有视觉属性并获得预览的视图。出于我们的目的，这是最重要的观点，我们将更详细地讨论它。
*   **数据实验室**:该视图以表格形式展示原始图形数据，拆分为*节点*和*边*，也可以根据需要进行扩展和修改。
*   **预览**:预览视图用于查看结果，即图形可视化，因为它也可以导出为各种格式，如 SVG、PDF 和 PNG。

如果尚未激活，请选择概述继续。在应用程序的主菜单中，在*窗口下，您可以选择各种选项卡。确保图形、预览设置、外观、布局和统计信息已打开，如下图所示:*

![](../images/00167.jpeg)

Figure 12: Gephi's three main views and the essential tabs used in the Overview view

图形选项卡，其中您应该已经看到了样本*悲惨世界*图形的可视化表示，可用于最终润色和视觉检查。例如，相应窗口左侧的*矩形选择*允许您通过选择顶点来选择子图，而通过*拖动*，您可以根据自己的审美需求在顶点周围移动。

在预览设置中，这可能是我们最感兴趣的选项卡，我们可以配置图形的大多数视觉方面。预设允许您更改图形的一般样式，例如曲线边与直边。我们将保持默认设置不变。您可能已经注意到，图形预览没有顶点或边标签，因此不可能看到每个顶点代表什么。我们可以通过在*节点标签*类别中选择*显示标签*然后取消选择*比例大小*复选框来改变这一点，以便所有标签具有相同的大小。如果现在转到预览视图，您看到的图形应该如下图所示:

![](../images/00168.jpeg)

Figure 13: Les miserables example graph, slightly modified with Gephi. Vertices are characters of the piece and edges represent importance of connection by means of edge thickness. Vertex size is determined by degree and vertices are additionally grouped by colour to indicate family membership, the latter of which can't be seen in print.

请注意，前面的图带有我们没有专门设置的视觉属性。顶点大小与顶点度成正比，边缘厚度由权重决定，图形用颜色编码显示各个字符属于哪个族。为了理解这是如何做到的，我们接下来讨论*外观*标签，它也区分了*节点*和*边缘*。在这个选项卡的右上角，有四个选项可供选择，我们选择*尺寸*，它由一个显示几个圆圈的图标来描述。完成后，我们可以首先选择左上角的节点，然后选择其正下方的*排名*。在下拉菜单中，我们可以选择一个属性来决定节点的大小，在前面的例子中是*度。*同样，可以配置前面讨论的另外两个属性。

继续，我们讨论的下一个选项卡是*布局*，在这里我们可以选择自动排列图形的方法。有趣的布局是两个可用的*力图谱*方案，它们通过可配置的顶点吸引和排斥属性来模拟顶点相互吸引。在*图 13* 中，没有选择布局，但是稍微探索一下会很有趣。无论你选择什么布局，点击运行按钮激活它们。

使用*统计*选项卡，我们可以从 Gephi 中探索图形属性，例如连接的组件和 PageRank。由于我们将讨论如何使用 GraphX 来实现这一点，而 GraphX 的性能也要高得多，所以我们就不讨论它了，尽管我们鼓励您尝试这个选项卡中的功能，因为它可以帮助快速建立直觉。

根据我们的需求配置好属性后，我们现在可以切换到预览视图，看看结果图是否是我们期望的那样。假设一切都解决了，预览设置标签的按钮可用于导出我们的最终信息图，以便在您的产品中使用，无论是报告、进一步分析还是其他使用案例。

# 从 GraphX 图形创建 GEXF 文件

为了将 Gephi 的图形可视化功能与 Spark GraphX 图形联系起来，我们需要解决两者之间的通信方式。这样做的典型候选是 Gephi 的**图形交换 XML 格式** ( **GEXF** ，其描述可以在[https://gephi.org/gexf/format/](https://gephi.org/gexf/format/)找到。下面的代码清单显示了如何以这种格式描述图形的一个非常简单的示例:

```
<?xml version="1.0" encoding="UTF-8"?><gexf  version="1.2"><meta lastmodifieddate="2009-03-20"><creator>Gexf.net</creator><description>A hello world! file</description></meta><graph mode="static" defaultedgetype="directed"><nodes><node id="0" label="Hello" /><node id="1" label="Word" /></nodes><edges><edge id="0" source="0" target="1" /></edges></graph></gexf>
```

除了 XML 的头和元数据，图形编码本身是不言自明的。知道前面的 XML 只是图形描述所需的最低限度是有用的，事实上，GEXF 可以用来编码其他属性，例如边缘权重，甚至是 Gephi 自动拾取的视觉属性。

为了与 GraphX 连接，让我们编写一个小助手函数，它采用`Graph`版本并返回前面的 XML 格式的`String`版本:

```
def toGexf[VD, ED](g: Graph[VD, ED]): String = {val header ="""<?xml version="1.0" encoding="UTF-8"?>|<gexf  version="1.2">|  <meta>|    <description>A gephi graph in GEXF format</description>|  </meta>|    <graph mode="static" defaultedgetype="directed">""".stripMarginval vertices = "<nodes>\n" + g.vertices.map(v => s"""<node id=\"${v._1}\" label=\"${v._2}\"/>\n""").collect.mkString + "</nodes>\n"val edges = "<edges>\n" + g.edges.map(e => s"""<edge source=\"${e.srcId}\" target=\"${e.dstId}\" label=\"${e.attr}\"/>\n""").collect.mkString + "</edges>\n"val footer = "</graph>\n</gexf>"header + vertices + edges + footer}
```

虽然乍一看代码可能有点神秘，但实际上发生的事情很少。我们为 XML 定义了页眉和页脚。我们需要将边和顶点属性映射到`<nodes>`和`<edges>` XML 标签。为此，我们使用 Scala 方便的`${}`符号将变量直接摄入字符串。作为改变，让我们在一个完整的 Scala 应用程序中使用这个`toGexf`函数，它使用了我们之前的简单朋友图。请注意，为了实现这一点，假设`toGexf`可用于`GephiApp`。因此，要么将它存储在同一个对象中，要么存储在另一个文件中，以便从那里导入它。如果你想继续使用 spark-shell，只需粘贴导入和主方法的主体，不包括创建`conf`和`sc`，应该可以正常工作:

```
import java.io.PrintWriterimport org.apache.spark._import org.apache.spark.graphx._import org.apache.spark.rdd.RDDobject GephiApp {def main(args: Array[String]) {val conf = new SparkConf().setAppName("Gephi Test Writer").setMaster("local[4]")val sc = new SparkContext(conf)val vertices: RDD[(VertexId, String)] = sc.parallelize(Array((1L, "Anne"),(2L, "Bernie"),(3L, "Chris"),(4L, "Don"),(5L, "Edgar")))val edges: RDD[Edge[String]] = sc.parallelize(Array(Edge(1L, 2L, "likes"),Edge(2L, 3L, "trusts"),Edge(3L, 4L, "believes"),Edge(4L, 5L, "worships"),Edge(1L, 3L, "loves"),Edge(4L, 1L, "dislikes")))val graph: Graph[String, String] = Graph(vertices, edges)val pw = new PrintWriter("./graph.gexf")pw.write(toGexf(graph))pw.close()}}
```

这个应用把我们的朋友图存储为`graph.gexf`，我们可以用它导入到 Gephi 中。为此，转到文件，然后点击*打开*选择该文件并导入图形。下图通过使用前面描述的选项卡和方法调整视觉属性，显示了此过程的结果:

![](../images/00169.jpeg)

Figure 14: Our example friend graph displayed using Gephi As noted earlier, it is indeed possible to define visual attributes programmatically, using *Gephi Toolkit*, a Java library you can import into your project. There are other language wrappers available, but this is the supported library, available as a single JAR. It's far beyond the scope of this book to discuss the toolkit, but if you are interested, you can refer to [https://gephi.org/toolkit/](https://gephi.org/toolkit/), which serves as a good entry point.

# 高级图形处理

在快速进入图形生成和可视化后，让我们转向更具挑战性的应用程序和更先进的图形分析技术。概括地说，我们到目前为止在图处理方面所做的只是使用 GraphX 图的底层边和顶点 RDDs 的基本属性，以及一些转换，包括`mapVertices`、`mapEdges`和`mapTriplets`。正如我们所看到的，这些技术已经非常有用了，但是它们本身的功能还不足以实现图形并行算法。为此，GraphX 图有两个强候选，我们接下来将讨论。大多数内置的 GraphX 算法，包括三角形计数、PageRank 等，都是使用其中一个或另一个来实现的。

# 聚合消息

首先，我们讨论 GraphX 图附带的`aggregateMessages`方法。基本思想是沿着边在整个图中并行传递消息，适当地聚合这些消息，并存储结果以供进一步处理。让我们仔细看看`aggregateMessages`是如何定义的:

```
def aggregateMessages[Msg: ClassTag](sendMsg: EdgeContext[VD, ED, Msg] => Unit,mergeMsg: (Msg, Msg) => Msg,tripletFields: TripletFields = TripletFields.All): VertexRDD[Msg]
```

如您所见，要实现一个`aggregateMessages`算法，我们需要指定一个消息类型`Msg`并提供三个函数，我们接下来将对此进行解释。您可能会注意到，还有两种我们以前没有遇到过的类型，即`EdgeContext`和`TripletFields`。简而言之，边上下文是我们已经看到的`EdgeTriplets`的扩展，即边加上所有关于相邻顶点的信息，唯一的区别是我们可以额外发送信息到定义如下的源和目标顶点:

```
def sendToSrc(msg: A): Unitdef sendToDst(msg: A): Unit
```

`TripletFields`允许限制计算中使用的`EdgeContext`字段，默认为所有可用字段。事实上，在接下来的内容中，我们将简单地对`tripletFields`使用这个默认值，并且只关注`sendMsg`和`mergeMsg`。如本主题介绍中所述，`sendMsg`用于沿边传递消息，`mergeMsg`聚合它们，我们将此操作的结果存储在`Msg`类型的顶点 RDD 中。为了更具体地说明这一点，考虑下面的例子，这是一种为我们之前的小朋友图计算所有顶点的入度的替代方法:

```
val inDegVertexRdd: VertexRDD[Int] = friendGraph.aggregateMessages[Int](sendMsg = ec => ec.sendToDst(1),mergeMsg = (msg1, msg2) => msg1+msg2)assert(inDegVertexRdd.collect.deep == friendGraph.inDegrees.collect.deep)
```

在本例中，发送消息是通过获取一个边缘上下文并使用其`sendToDst`方法向每个目标顶点(即数字 1)发送一个整数消息来定义的。这意味着，对于平行的每条边，我们向这条边所指向的每个顶点发送一个 1。这样，顶点可以发送我们需要合并的消息。这里的`mergeMsg`应该和一般 RDDs 的`reduce`一样理解，就是我们指定两个消息如何合并，这个食谱是用来把所有消息折叠成一个的。在前面的例子中，我们只是总结了所有的信息，根据定义，这些信息产生了每个顶点的入度。我们通过断言从收集主设备上的`inDegVertexRdd`和`friendGraph.inDegrees`获得的数组相等来证实这一点。

注意`aggregateMessages`的返回值是顶点 RDD，不是图。因此，迭代使用这种机制，我们需要在每次迭代中生成一个新的图形对象，这并不理想。由于 Spark 将分区数据保存在内存中，并且许多有趣的图形算法实际上是迭代的，因此它在迭代算法方面特别强大，接下来我们将讨论稍微复杂一点但极其强大的 Pregel API。

# 普雷格尔

Pregel 是谷歌内部开发的系统，其配套论文非常容易获取，可在[http://www . DCS . bbk . AC . uk/~ Dell/teaching/cc/paper/sigmo D10/p135-malewicz . pdf](http://www.dcs.bbk.ac.uk/~dell/teaching/cc/paper/sigmod10/p135-malewicz.pdf)下载。它代表了一种高效的迭代图形并行计算模型，允许人们实现一大类图形算法。GraphX 对 Pregel 的实现与前面的论文略有不同，但我们无法深入了解其中的任何细节。

在风味上，GraphX 的`Pregel`实现与`aggregateMessages`非常接近，但有几个关键的区别。这两种方法共有的特征是发送和合并消息机制。除此之外，使用 Pregel，我们可以定义一个所谓的*顶点程序* `vprog`，该程序在发送之前执行，以转换顶点数据。此外，我们从每个顶点上的共享初始消息开始，并可以指定我们想要执行多少次迭代 *vprog-send-merge* 循环，也就是说，迭代是规范的一部分。

简述了 Pregel 实现的`apply`方法。请注意，它需要两组输入，即由图形本身、初始消息、要执行的最大迭代和名为`activeDirection`的字段组成的四元组。最后一个论点值得更多关注。我们还没有谈到的 Pregel 规范的一个细节是*我们只从在之前的迭代*中已经接收到消息的顶点发送新消息。活动方向默认为`Either`，也可以同时为`In`或`Out`。在许多情况下，这种行为自然会让算法收敛，这也解释了为什么第三个参数被称为`maxIterations` -我们可能会比指定的时间更早停止:

```
object Pregel {def apply[VD: ClassTag, ED: ClassTag, A: ClassTag](graph: Graph[VD, ED],initialMsg: A,maxIterations: Int = Int.MaxValue,activeDirection: EdgeDirection = EdgeDirection.Either)(vprog: (VertexId, VD, A) => VD,sendMsg: EdgeTriplet[VD, ED] => Iterator[(VertexId, A)],mergeMsg: (A, A) => A): Graph[VD, ED]}
```

Pregel 的第二组参数是我们已经描述过的三重参数，即顶点程序，以及发送和合并消息函数。与之前唯一值得注意的区别是`sendMsg`的签名，它返回一个*迭代器，遍历顶点标识和消息对*。这对我们来说变化不大，但有趣的是，`aggregateMessage`中`sendMsg`的签名在 Spark 1.6 之前一直是这样的迭代器，并被更改为我们之前在 Spark 2.0 更新中讨论过的内容。很有可能，Pregel 的签名也将相应地改变，但是从 2.1.1 开始，它仍然保持如上所述。

为了说明 Pregel 应用编程接口的可能性，让我们绘制一个计算连接组件的算法的实现。这是对 GraphX 中当前可用的实现的轻微修改。我们用一个单一的跟随方法定义`ConnectedComponents`对象，即`run`，它采用任意图形和最大迭代次数。算法的核心思想很容易解释。对于每个边缘，只要其源的标识小于其目标，就将源标识发送到目标，反之亦然。要聚合这些消息，只需取所有广播值中的最小值，并重复此过程足够长的时间，以使其用完更新。此时，连接到另一个顶点的每个顶点都具有与顶点数据相同的标识，即原始图形中可用的最小标识:

```
import org.apache.spark.graphx._import scala.reflect.ClassTagobject ConnectedComponents extends Serializable {def run[VD: ClassTag, ED: ClassTag](graph: Graph[VD, ED],maxIterations: Int): Graph[VertexId, ED] = {val idGraph: Graph[VertexId, ED] = graph.mapVertices((id, _) => id)def vprog(id: VertexId, attr: VertexId, msg: VertexId): VertexId = {math.min(attr, msg)}def sendMsg(edge: EdgeTriplet[VertexId, ED]): Iterator[(VertexId, VertexId)] = {if (edge.srcAttr < edge.dstAttr) {Iterator((edge.dstId, edge.srcAttr))} else if (edge.srcAttr > edge.dstAttr) {Iterator((edge.srcId, edge.dstAttr))} else {Iterator.empty}}def mergeMsg(v1: VertexId, v2: VertexId): VertexId = math.min(v1, v2)Pregel(graph = idGraph,initialMsg = Long.MaxValue,maxIterations,EdgeDirection.Either)(vprog,sendMsg,mergeMsg)}}
```

一步一步来，算法如下。我们首先通过定义`idGraph`来忘记所有先前可用的顶点数据。接下来，我们定义顶点程序来发出当前顶点数据属性和当前消息的最小值。这样我们可以将最小顶点标识存储为顶点数据。如前所述，`sendMsg`方法将每条边的较小标识传播到源或目标，而`mergeMsg`再次仅取最小标识。定义好这三个关键方法后，我们就可以在指定的`maxIterations`下在`idGraph`上运行`Pregel`了。注意，我们不关心消息流向哪个方向，所以我们使用`EdgeDirection.Either`。此外，我们从最大可用长值开始作为我们的初始消息，这是可行的，因为我们在顶点标识上取最小值。

定义了这一点后，我们可以在转发图上找到之前的连接组件`rtGraph`，如下所示，最多选择五次迭代:

```
val ccGraph = ConnectedComponents.run(rtGraph, 5)cc.vertices.map(_._2).distinct.count
```

对结果图的不同顶点数据项进行计数，可以得到连通分量的数量(在这种情况下，它只是一个分量)，也就是说，如果我们忘记了方向性，那么数据集中的所有推文都是连通的。有趣的是，我们实际上需要五次迭代才能使算法收敛。用更少的迭代运行它，也就是 1、2、3 或 4，产生 1771、172、56 和 4 个连接的组件。因为必须至少有一个连接的组件，我们知道进一步增加迭代不会改变结果。然而，一般来说，我们宁愿不指定迭代的次数，除非时间或计算能力是一个问题。通过将前面的运行方法包装如下，我们可以只在图上运行该算法，而无需显式提供迭代:

```
def run[VD: ClassTag, ED: ClassTag](graph: Graph[VD, ED]): Graph[VertexId, ED] = {run(graph, Int.MaxValue)}
```

只需将此作为附加方法添加到`ConnectedComponents`对象中。对于转发图，我们现在可以简单地写。看过`aggregateMessages`和 Pregel 之后，读者现在应该有足够的能力开发自己的图形算法:

```
val ccGraph = ConnectedComponents.run(rtGraph)
```

# 图形框架

请注意，到目前为止，要计算给定图表上的任何有趣的指标，我们必须使用图表的计算模型，这是我们从关系数据库中所知的扩展。考虑到 Spark 的数据框架或数据集概念，读者可能会想，是否有可能使用类似于 SQL 的语言对图表进行查询以进行分析。查询语言通常提供一种快速获取结果的便捷方式。

这在 GraphFrames 中确实是可能的。该库由 Databricks 开发，是 GraphX 图形到 Spark 数据帧的自然扩展。不幸的是，GraphFrames 不是 Spark GraphX 的一部分，而是作为 Spark 包提供的。要在启动火花提交时加载图形框架，只需运行

`spark-shell --packages graphframes:graphframes:0.5.0-spark2.1-s_2.11`

并为您首选的 Spark 和 Scala 版本适当地修改前面的版本号。将 GraphX 图形转换为`GraphFrame`图形，反之亦然，这非常简单；在下文中，我们将朋友图从早期转换为`GraphFrame`，然后再转换回来:

```
import org.graphframes._val friendGraphFrame = GraphFrame.fromGraphX(friendGraph)val graph = friendGraphFrame.toGraphX
```

如前所述，GraphFrames 的一个额外好处是您可以将 Spark SQL 与它们一起使用，因为它们是构建在数据帧之上的。这也意味着 GraphFrames 比 Graphs 要快得多，因为 Spark 核心团队通过其 catalyst 和钨框架为 DataFrames 带来了大量的速度提升。希望我们能在下一个版本中看到 GraphFrames 被添加到 Spark GraphX 中。

我们不再看前面几章中已经足够熟悉的 Spark SQL 示例，而是考虑另一种可用于 GraphFrames 的查询语言，它具有非常直观的计算模型。GraphFrames 从图形数据库 *neo4j* 中借用了 *Cypher* SQL 方言，可以用于非常有表现力的查询。继续`friendGraphFrame`，我们可以非常容易地找到所有长度的两条路径，要么在顶点“克里斯”结束，要么首先通过边缘“信任”，使用一个简洁的命令:

```
friendGraphFrame.find("(v1)-[e1]->(v2); (v2)-[e2]->(v3)").filter("e1.attr = 'trusts' OR v3.attr = 'Chris'").collect.foreach(println)
```

请注意，我们如何以让您根据实际图形进行思考的方式指定图形结构，也就是说，我们有两条边 *e1* 和 *e2* ，它们通过一个公共顶点 *v2* 相互连接。这个操作的结果在下面的截图中列出，它确实给出了满足前面条件的三个路径:

![](../images/00170.jpeg)

不幸的是，我们不能在这里更详细地讨论 GraphFrames，但是感兴趣的读者可以参考在[https://graphframes.github.io/](https://graphframes.github.io/)获得的文档了解更多细节。相反，我们现在将转向 GraphX 中可用的算法，并将它们应用于演员数据的大量图表。

# 图形算法及应用

在本应用部分，我们将讨论三角计数、(强)连接组件、PageRank 和 GraphX 中可用的其他算法，我们将从[http://networkrepository.com/](http://networkrepository.com/)加载另一个有趣的图形数据集。这次请从[http://networkrepository.com/ca-hollywood-2009.php](http://networkrepository.com/ca-hollywood-2009.php)下载数据，它由一个无向图组成，无向图的顶点代表电影中出现的演员。文件的每一行都包含代表一条边的两个顶点标识，这意味着这些演员一起出现在电影中。

数据集由大约 110 万个顶点组成，有 5630 万条边。尽管文件大小，即使解压缩后，也不是特别大，但对于图形处理引擎来说，这种大小的图形是一个真正的挑战。由于我们假设您在本地使用 Spark 的独立模式，因此该图可能不适合您的计算机内存，并且会使 Spark 应用程序崩溃。为了防止这种情况，让我们稍微限制一下数据，这也给了我们清理文件头的机会。我们假设您已经打开`ca-hollywood-2009.mtx`并将其存储在您当前的工作目录中。我们使用 unix 工具*尾部*和*头部*删除前两行，然后限制到前一百万条边:

`tail -n+3 ca-hollywood-2009.mtx | head -1000000 > ca-hollywood-2009.txt`

如果这些工具对您不可用，任何其他工具都可以，包括手动修改文件。从前面描述的结构中，我们可以简单地使用`edgeListFile`功能将图形加载到 Spark 中，并确认它确实有一百万条边:

```
val actorGraph = GraphLoader.edgeListFile(sc, "./ca-hollywood-2009.txt")actorGraph.edges.count()
```

接下来，让我们看看我们可以用 GraphX 做什么来分析这个图。

# 使聚集

给定一个图，一个自然要问的问题是它是否有任何自然属于一起的子图，也就是说，以某种方式聚集该图。这个问题可以用很多方法来解决，其中一个我们已经自己实现了，即通过研究连接的组件。这次让我们使用 GraphX 的内置版本，而不是使用我们自己的实现。为此，我们可以简单地直接在图形本身上调用`connectedComponents`:

```
val actorComponents = actorGraph.connectedComponents().cache actorComponents.vertices.map(_._2).distinct().count
```

在我们自己的实现中，图的顶点数据包含簇标识，它对应于簇内的最小可用顶点标识。这允许我们通过收集不同的集群标识来直接计算连接的组件。我们的受限聚类图的答案是 173。计算组件，我们缓存该图，以便我们可以进一步将其用于其他计算。例如，我们可能会问连接的组件有多大，例如通过计算顶点的最大和最小集群大小。我们可以通过使用集群标识作为关键字，并通过计算其项目来减少每个组来实现这一点:

```
val clusterSizes =actorComponents.vertices.map(v => (v._2, 1)).reduceByKey(_ + _)clusterSizes.map(_._2).maxclusterSizes.map(_._2).min
```

事实证明，最大的演员群由 193，518 名演员组成，而最小的演员群只有三名演员。接下来，让我们忽略一个事实，即所讨论的图形实际上没有方向性，因为一起出现在电影中是对称的，并且表现得好像边缘对是有方向的。我们不必在这里强加任何东西，因为 Spark GraphX 中的一个边总是有一个源和一个目标。这让我们也可以研究*强*连接的组件。我们可以用类似于连接组件的算法来调用这个算法，但是在这种情况下，我们也必须指定迭代的次数。其原因是，以我们对连接组件的相同方式“跟踪”有向边在计算上要求更高，并且收敛更慢。

让我们只满足于一次迭代来执行计算，因为它非常昂贵:

```
val strongComponents = actorGraph.stronglyConnectedComponents(numIter = 1)strongComponents.vertices.map(_._2).distinct().count
```

这个计算可能需要几分钟才能完成。如果你在你的机器上运行这个例子有问题，考虑进一步限制`actorGraph`。

接下来，让我们计算演员图的三角形，这是另一种聚类方法。为此，我们需要稍微准备一下图，即我们必须*规范化*边并指定一个*图划分策略。*规范化图形意味着消除循环和重复边，并确保所有边的源标识始终小于目标标识:

```
val canonicalGraph = actorGraph.mapEdges(e => 1).removeSelfEdges().convertToCanonicalEdges()
```

像我们已经遇到的 RDD 分区一样，图分区策略关注的是如何在集群中有效地分布图的问题。当然，什么是有效的很大程度上取决于我们如何处理我们的图表。大致来说，有两种基本的划分策略，即*顶点切割*和*边切割*。顶点切割策略意味着通过切割顶点以不连续的方式强制分割边，也就是说，如果需要，顶点在分区之间重复。边缘切割策略则相反，因为顶点在整个集群中是唯一的，但是我们可能会复制边缘。GraphX 有四种分区策略，都是基于顶点切割的。我们在这里不详细讨论它们，而只是使用`RandomVertexCut`，它对顶点标识进行散列，使得顶点之间所有同向的边都位于同一个分区上。

Note that when creating a graph without specifying a partition strategy, the graph is distributed by simply adopting the structure of the underlying EdgeRDD that has been provided for construction. Depending on your use-case, this might not be ideal, for instance because edge partitions might be strongly imbalanced.

为了划分`canonicalGraph`并继续进行三角形计数，我们现在使用如下策略划分我们的图:

```
val partitionedGraph = canonicalGraph.partitionBy(PartitionStrategy.RandomVertexCut)
```

计算三角形在概念上很简单。我们首先收集每个顶点的所有相邻顶点，然后计算每个边的这些集合的交集。逻辑是，如果源顶点集和目标顶点集都包含相同的第三个顶点，则这三个顶点形成一个三角形。作为最后一步，我们将交集集的*计数发送给源和目标，从而对每个三角形计数两次，我们简单地除以 2，得到每个顶点的三角形计数。现在做三角计数可以归结为跑步:*

```
import org.apache.spark.graphx.lib.TriangleCountval triangles = TriangleCount.runPreCanonicalized(partitionedGraph)
```

事实上，我们不需要显式地将`actorGraph`规范化，只需要将`triangleCount`直接强加在初始图上就可以了，也就是通过计算以下内容:

```
actorGraph.triangleCount()
```

同样，我们也可以导入`TriangleCount`并在我们的演员图上调用它，如下所示:

```
import org.apache.spark.graphx.lib.TriangleCountTriangleCount.run(actorGraph)
```

但是，请注意，最后两个等价的操作实际上将像我们所做的那样规范化所讨论的图，规范化是一个计算量非常大的操作。因此，每当您看到有机会以规范形式加载您的图时，所示的第一种方法会更有效。

# 顶点重要性

在一张相互联系的朋友图中，一个有趣的问题是谁是小组中最有影响力的人。是不是人脉最多的人，也就是度最高的顶点？对于有向图，in-degree 可能是一个很好的第一个猜测。或者说是认识几个自己有很多关系的人的人？当然有很多方法来描述一个顶点有多重要或权威，具体的答案将在很大程度上取决于问题领域，以及我们通过该图获得的额外数据。此外，在我们给出的例子中，对于图中的一个特定的人，另一个人可能因为他们自己非常主观的原因而最有影响力。

然而，在给定的图中寻找顶点的重要性是一个具有挑战性的问题，这种算法的一个历史上重要的例子是 *PageRank* ，这在 1998 年的开创性论文《大规模超文本网络搜索引擎的剖析》中有所描述，该论文可在[http://ilpubs.stanford.edu:8090/361/1/1998-8.pdf](http://ilpubs.stanford.edu:8090/361/1/1998-8.pdf)获得。在这篇文章中，谢尔盖·布林和拉里·佩奇为他们的搜索引擎谷歌奠定了基础。虽然 PageRank 对在由链接连接的巨大网页图中找到相关搜索结果产生了重大影响，但多年来，该算法已被谷歌内部的其他方法所取代。然而，PageRank 仍然是一个很好的例子，展示了如何对网页或图表进行排名，以获得对它更深入的理解。GraphX 提供了 PageRank 的一个实现，我们将在描述算法本身后看一看。

PageRank 是有向图的迭代算法，通过为每个顶点设置相同的值来初始化，即 *1/N* ，其中 *N* 表示图的顺序，即顶点的数量。然后，它重复更新顶点值的相同过程，也就是它们的 PageRank，直到我们选择停止或满足某些收敛标准。更具体地说，在每次迭代中，一个顶点将它的*当前页面等级除以它的出度*发送给它有出站连接的所有顶点，也就是说，它将其当前页面等级均匀地分布在所有出站边上。然后，顶点将收到的所有值相加，以设置新的页面排名。如果整个页面在最后一次迭代中没有太大变化，请停止该过程。这是算法的基本公式，我们将在讨论 GraphX 实现时进一步指定停止标准。

然而，我们还需要通过引入一个*阻尼因子 d* 来稍微扩展基线算法。阻尼因子的发明是为了防止所谓的*级下沉*。想象一个强连接的组件，它只有来自图的其余部分的传入边，那么通过前面的说明，这个组件将在每次迭代中通过传入边积累越来越多的页面排名，但是永远不会通过传出连接“释放”任何页面排名。这个场景叫做等级下沉，为了摆脱它，我们需要通过阻尼*引入更多*等级源*。*PageRank 所做的是模拟一个完全随机的用户以链接目标的 page rank 给出的概率跟随链接的理想想法。阻尼的想法通过引入概率 d 的机会来改变这一点，用户跟随他们当前的路径，并以概率( *1-d* )变得无聊并继续阅读完全不同的页面。

在我们上面的排名接收器示例中，用户将离开强连接组件，并在图表中的其他地方结束，从而增加图表其他部分的相关性，即页面排名。总结这个解释，带有阻尼的 PageRank 更新规则可以写成如下:

![](../images/00171.jpeg)

也就是说，为了更新顶点 *v* 的页面排名 *PR* ，我们对所有入站顶点 *w* 的页面排名进行求和，除以它们各自的出度 *out(w)* 。

Spark GraphX 有两种 PageRank 实现，一种叫做静态实现，另一种叫做动态实现。在静态版本中，我们只需对预先指定的固定迭代次数`numIter`执行前面的更新规则。在动态版本中，我们为收敛指定了一个*容差* `tol`，即如果一个顶点的 PageRank 在最后一次迭代中至少没有变化`tol`，那么它将退出计算，这意味着它既不会发出新的 page rank，也不会更新自己的 page rank。让我们为微小的`friendGraph`计算静态和动态版本的 PageRank。包含 10 次迭代的静态版本如下所示:

```
friendGraph.staticPageRank(numIter = 10).vertices.collect.foreach(println)
```

运行算法后，我们只需收集 master 上的所有顶点并打印它们，结果如下:

```
 (1,0.42988729103845036) (2,0.3308390977362031) (3,0.6102873825386869) (4,0.6650182732476072) (5,0.42988729103845036)
```

有趣的是，页面如何随着迭代次数的变化而变化；有关详细信息，请参见下表:

| num ITER/vertex | **安妮** | **伯尼** | **克里斯** | **唐** | **埃德加** |
| one | Zero point two one three | Zero point two one three | Zero point three four one | Zero point two seven seven | Zero point two one three |
| Two | Zero point two six seven | Zero point two four | Zero point four two two | Zero point four four | Zero point two six seven |
| three | Zero point three three seven | Zero point two six three | Zero point four six eight | Zero point five zero nine | Zero point three three seven |
| four | Zero point three six six | Zero point two nine three | Zero point five one seven | Zero point five four eight | Zero point three six six |
| five | Zero point three eight three | Zero point three zero five | Zero point five five four | Zero point five eight nine | Zero point three eight three |
| Ten | Zero point four two nine | Zero point three three | Zero point six one | Zero point six six five | Zero point four two nine |
| Twenty | Zero point four three eight | Zero point three three six | Zero point six two two | Zero point six seven eight | Zero point four three eight |
| One hundred | Zero point four three eight | Zero point three three six | Zero point six two two | Zero point six seven eight | Zero point four eight three |

虽然哪个顶点比另一个更重要的一般趋势，即顶点的相对排名已经在仅两次迭代后建立，但是注意，即使对于这个微小的图，页面链也需要大约 20 次迭代来稳定。所以，如果你只对顶点的粗略排名感兴趣，或者运行动态版本太贵，静态算法可以派上用场。为了计算动态版本，我们指定公差`tol`为`0.0001`，所谓的`resetProb`为`0.15`。后者无非是 *1-d* ，即离开当前路径，在图中任意一个顶点弹出的概率。实际上，`0.15`是`resetProb`的默认值，反映了原论文的建议:

```
friendGraph.pageRank(tol = 0.0001, resetProb = 0.15)
```

运行该程序产生以下页面等级值，显示在*图 15* 中。这些数字看起来应该很熟悉，因为它们与 20 次或更多次迭代的静态版本相同:

![](../images/00172.jpeg)

Figure 15: PageRanks computed for our toy friend graph, using the dynamic GraphX implementation.

一个更有趣的例子，让我们再次转向演员图。使用与前面示例中相同的容差，我们可以快速找到页面等级最高的顶点标识:

```
val actorPrGraph: Graph[Double, Double] = actorGraph.pageRank(0.0001)actorPrGraph.vertices.reduce((v1, v2) => {if (v1._2 > v2._2) v1 else v2})
```

这将返回 ID 33024，页面等级为 7.82。为了强调 PageRank 与简单地将入度视为顶点重要性的幼稚想法有何不同，请考虑以下分析:

```
actorPrGraph.inDegrees.filter(v => v._1 == 33024L).collect.foreach(println)
```

限制所讨论的顶点标识并检查其度数，会产生 62 条引入边。让我们看看图表中最高的十个学位是什么:

```
actorPrGraph.inDegrees.map(_._2).collect().sorted.takeRight(10)
```

这导致了`Array(704, 733, 746, 756, 762, 793, 819, 842, 982, 1007)`，这意味着具有最高页面等级的顶点甚至不接近具有最高的入度。事实上，总共有 2167 个顶点至少有`62`条入站边，通过运行可以看出:

```
actorPrGraph.inDegrees.map(_._2).filter(_ >= 62).count
```

因此，虽然这仍然意味着顶点在所有顶点中的前 2%，但我们看到 PageRank 给出了与其他方法完全不同的答案。

# 上下文中的 GraphX

在这一章中，我们已经看到了许多图形分析的应用，接下来一个自然的问题是 GraphX 如何适合 Spark 生态圈的其他部分，以及我们如何将其用于机器学习应用程序，以及我们之前看到的类似 MLlib 的系统。

快速回答是，虽然图的概念仅限于 Spark GraphX，但由于图的底层顶点和边 RDDs，我们可以无缝地与 Spark 的任何其他模块进行对话。事实上，我们在整个章节中使用了许多核心的 RDD 操作，但并不止于此。MLlib 确实在一些选定的地方使用了 GraphX 功能，比如*潜在狄利克雷分析*或*幂迭代聚类*，不幸的是，这超出了本章要解释的范围。相反，我们专注于从第一性原理解释 GraphX 的基础。然而，我们鼓励读者将我们在本章中学到的知识与之前的知识结合起来，用前面的算法进行实验。为了完整起见，GraphX 中完全实现了一个机器学习算法，即 *SVD++* ，大家可以在[http://public . research . att . com/~ volinsky/网飞/kdd08koren.pdf](http://public.research.att.com/~volinsky/netflix/kdd08koren.pdf) 上了解更多，这是一个基于图的推荐算法。

# 摘要

在本章中，我们已经看到了如何使用 Spark GraphX 将大规模图形分析付诸实践。将实体关系建模为具有顶点和边的图是评估许多有趣问题的强大范例。

在 GraphX 中，图是有限的有向属性图，可能有多条边和多个环。GraphX 在顶点和边 RDDs 的高度优化版本上进行图形分析，这允许您利用数据和图形并行应用程序。我们已经看到了如何通过从`edgeListFile`加载这些图或者从其他关系数据库中单独构建它们来读取这些图。最重要的是，我们已经看到了为快速实验创建随机和确定性图形数据是多么容易。仅使用`Graph`模型丰富的内置功能，我们已经展示了如何研究核心属性的图表。为了可视化更复杂的图形，我们引入了 *Gephi* 和一个界面，它允许人们获得关于手头图形结构的直觉。

在 Spark GraphX 提供的许多其他可能性中，我们引入了两个强大的图形分析工具，即`aggregateMessages`和`Pregel`应用编程接口。GraphX 的大多数内置算法都是使用这些选项之一编写的。我们已经看到了如何使用这些 API 编写自己的算法。我们还简要介绍了 GraphFrames 包，它构建在 DataFrames 之上，配备了普通 GraphX 中没有的优雅查询语言，可以方便地用于分析目的。

在实际应用方面，我们看到了一个有趣的转发图，以及一个正在运行的好莱坞电影演员图。我们仔细解释和应用了谷歌的 PageRank 算法，研究了图的(强)连通分量，并计算了其中的三角形作为聚类的手段。最后，我们讨论了高级机器学习应用程序的 Spark MLlib 和 GraphX 之间的关系。