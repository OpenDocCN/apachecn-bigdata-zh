# 第 11-13 章 10.11-13 推荐系统

在本章中，我们将介绍以下食谱：

*   使用显式反馈的协作过滤
*   使用隐式反馈的协同过滤

# 简介

以下是维基百科对推荐系统的定义：

> *“推荐系统是信息过滤系统的一个子类，它试图预测用户对某项商品的‘评分’或‘偏好’。”*

推荐系统在最近几年获得了极大的普及。 亚马逊用它们来推荐书籍，Netflix 用来推荐电影，谷歌新闻用来推荐新闻故事。 因为证据就在布丁中，下面是一些建议可能产生的影响的例子(来源：Celma，Lamere，2008)：

*   在 Netflix 上观看的电影中有三分之二是推荐的
*   推荐使用谷歌新闻 38%的新闻点击量
*   亚马逊销售额的 35%是推荐的结果

正如我们在前几章中所看到的，特征和特征选择在机器学习算法的有效性中起着主要作用。 推荐引擎算法自动发现这些特征，称为**潜在特征**。 简而言之，用户喜欢一部电影而不喜欢另一部电影有潜在的原因。 如果另一个用户有相应的潜在特征，这个人很有可能也会有类似的电影品味。

为了更好地理解这一点，让我们来看看一些电影评分样本：

<colgroup><col style="text-align: left"> <col style="text-align: left"> <col style="text-align: left"> <col style="text-align: left"> <col style="text-align: left"></colgroup> 
| 

电影 / 影片 / 电影业 / 电影院

 | 

里奇 （人名）

 | 

再简单没有了 / 鲍勃

 | 

彼得

 | 

克里斯

 |
| --- | --- | --- | --- | --- |
| "泰坦尼克号" | 5. | 3. | 5. | ？ |
| *黄金眼* | 3. | 2 个 | 1. | 5. |
| *玩具总动员* | 1. | ？ | 2 个 | 2 个 |
| *披露* | 4. | 4. | ？ | 4. |
| ©ACE Ventura©T1* | 4. | ？ | 4. | ？ |

我们的目标是预测与？一起显示的缺失条目。 象征。 让我们看看是否能找到一些与电影相关的特征。 首先，您将查看流派，如下所示：

<colgroup><col style="text-align: left"> <col style="text-align: left"></colgroup> 
| 

电影 / 影片 / 电影业 / 电影院

 | 

（音乐或文学等艺术作品的）类型

 |
| --- | --- |
| "泰坦尼克号" | 动作、浪漫 |
| *黄金眼* | 动作、冒险、惊悚 |
| *玩具总动员* | 动画、儿童、喜剧 |
| *披露* | 戏剧。 |
| ©ACE Ventura©T1* | 喜剧 / 喜剧因素 / 喜剧性 / 有趣的事情 |

现在，每部电影的评级可以从 0 到 1。例如，*黄金眼*基本上不是一部浪漫电影，所以它的浪漫电影评分可能是 0.1 分，但动作片的评分是 0.98 分。 因此，每部电影都可以表示为特征向量。

### 备注

在本章中，我们将使用来自[grouplens.org/Datets/Movielens/](http://grouplens.org/datasets/movielens/)的 MovieLens 数据集。

InfoObjects 大数据沙箱自带 10 万电影评分。 如果你想分析更大的数据集以获得更好的预测，你还可以从 GroupLens 下载 100 万-甚至 1000 万-评级。

我们将使用此数据集中的两个文件：

*   `u.data`: This has a tab-separated list of movie ratings in the following format:

    ```scala
    user id | item id | rating | epoch time
    ```

    因为我们不需要时间戳，所以我们将从食谱中的数据中将其过滤掉

*   `u.item`：这有一个以制表符分隔的电影列表，格式如下：

    ```scala
    movie id | movie title | release date | video release date |               IMDb URL | unknown | Action | Adventure | Animation |               Children's | Comedy | Crime | Documentary | Drama | Fantasy |               Film-Noir | Horror | Musical | Mystery | Romance | Sci-Fi |               Thriller | War | Western |
    ```

本章将介绍如何使用 MLlib(Spark 的机器学习库)提出建议。

# 使用显式反馈的协同过滤

协同过滤是推荐系统最常用的技术。 它有一个有趣的特性--它自己学习功能。 因此，在电影评级的情况下，我们不需要提供关于电影是浪漫的还是动作的实际的人类反馈。

正如我们在*简介*部分看到的那样，电影有一些潜在的特征，比如类型，就像用户有一些潜在的特征，比如年龄、性别等等。 协作过滤不需要它们，它会自己找出潜在的特征。

在本例中，我们将使用名为**交替最小二乘**(**ALS**)的算法。 该算法基于少量的潜在特征来解释电影与用户之间的关联。 它使用三个训练参数：排名、迭代次数和 lambda(将在本章后面介绍)。 计算这三个参数的最佳值的最佳方法是尝试个不同的值，看看哪个值具有最小的**均方根误差**(**RMSE**)。 此误差类似于标准差，但它基于模型结果而不是实际数据。

## 做好准备

将从 GroupLens 下载的`moviedata`上传到`hdfs`中的`moviedata`文件夹：

```scala
$ hdfs dfs -put moviedata moviedata

```

我们将在这个数据库中添加一些个性化评分，这样我们就可以测试推荐的准确性。

您可以查看`u.item`来挑选一些电影并对它们进行评级。 以下是我选择的一些电影，以及我的收视率。 请随意选择您想要评级的电影，并提供您自己的评级。

<colgroup><col style="text-align: left"> <col style="text-align: left"> <col style="text-align: left"></colgroup> 
| 

电影 ID

 | 

电影名称

 | 

评级(1-5)

 |
| --- | --- | --- |
| 313 | "泰坦尼克号" | 5. |
| 2 个 | *黄金眼* | 3. |
| 1. | *玩具总动员* | 1. |
| 43 | *披露* | 4. |
| 67 | ©ACE Ventura©T1* | 4. |
| 八十二 | *侏罗纪公园* | 5. |
| 九十六 | 加入时间：清华大学 2007 年 01 月 25 日下午 3：33 | 5. |
| 一百二十一 | *独立日* | 4. |
| 148 | *幽灵与黑暗* | 4. |

最高用户 ID 为 943，因此我们将使用将新用户添加为 944。 让我们使用以下数据创建一个以逗号分隔的新文件`p.data`：

```scala
944,313,5
944,2,3
944,1,1
944,43,4
944,67,4
944,82,5
944,96,5
944,121,4
944,148,4
```

## How to Do It…

1.  上传个性化电影数据至`hdfs`：

    ```scala
    $ hdfs dfs -put p.data p.data

    ```

2.  导入 ALS 和额定值类别：

    ```scala
    scala> import org.apache.spark.mllib.recommendation.ALS
    scala> import org.apache.spark.mllib.recommendation.Rating

    ```

3.  将评级数据加载到 RDD：

    ```scala
    scala> val data = sc.textFile("moviedata/u.data")

    ```

4.  将`val data`转换为额定值的 RDD：

    ```scala
    scala> val ratings = data.map { line => 
     val Array(userId, itemId, rating, _) = line.split("\t") 
     Rating(userId.toInt, itemId.toInt, rating.toDouble) 
    }

    ```

5.  将个性化评级数据加载到 RDD：

    ```scala
    scala> val pdata = sc.textFile("p.data")

    ```

6.  将数据转换为个性化评分的 RDD：

    ```scala
    scala> val pratings = pdata.map { line => 
     val Array(userId, itemId, rating) = line.split(",")
     Rating(userId.toInt, itemId.toInt, rating.toDouble) 
    }

    ```

7.  将评级与个性化评级相结合：

    ```scala
    scala> val movieratings = ratings.union(pratings)

    ```

8.  使用等级为 5 和 10 的 ALS 构建模型，并将 0.01 作为 lambda：

    ```scala
    scala> val model = ALS.train(movieratings, 10, 10, 0.01)

    ```

9.  让我们根据此模型预测我对给定电影的评分。
10.  Let's start with original *Terminator* with movie ID 195:

    ```scala
    scala> model.predict(sc.parallelize(Array((944,195)))).collect.foreach(println)
    Rating(944,195,4.198642954004738)

    ```

    因为我给*Terminator**2*5 打了分，所以这是一个合理的预测。

11.  Let's try *Ghost* with movie ID 402:

    ```scala
    scala> model.predict(sc.parallelize(Array((944,402)))).collect.foreach(println)
    Rating(944,402,2.982213836456829)

    ```

    这是一个合理的猜测。

12.  Let's try *The Ghost and the Darkness*, the movie I already rated, with the ID 148:

    ```scala
    scala> model.predict(sc.parallelize(Array((944,402)))).collect.foreach(println)
    Rating(944,148,3.8629938805450035)

    ```

    非常接近的预测，知道我给这部电影打了 4 分。

您可以对`train`数据集使用更多影片。 还有 100 万和 1000 万个评级数据集可用，这些数据集将进一步完善算法。

# 使用隐式反馈的协同过滤

有时可用的反馈是，不是以评级的形式，而是以播放音轨、观看电影等形式。 乍一看，这些数据可能没有用户明确的评分那么好，但这要详尽得多。

## 做好准备

我们将使用来自[http://www.kaggle.com/c/msdchallenge/data](http://www.kaggle.com/c/msdchallenge/data)的百万首歌曲数据。 您需要下载三个文件：

*   `kaggle_visible_evaluation_triplets`
*   `kaggle_users.txt`
*   `kaggle_songs.txt`

现在执行以下步骤：

1.  在`hdfs`中创建`songdata`文件夹，并将所有三个文件放在此处：

    ```scala
    $ hdfs dfs -mkdir songdata

    ```

2.  上传歌曲数据至`hdfs`：

    ```scala
    $ hdfs dfs -put kaggle_visible_evaluation_triplets.txt songdata/
    $ hdfs dfs -put kaggle_users.txt songdata/
    $ hdfs dfs -put kaggle_songs.txt songdata/

    ```

我们还需要做更多的预处理。 MLlib 中的 ALS 将用户 ID 和产品 ID 都作为整数。 `Kaggle_songs.txt`文件旁边有歌曲 ID 和序列号，`Kaggle_users.txt`文件没有。 我们的目标是用相应的整数序列号替换`triplets`数据中的`userid`和`songid`。 为此，请执行以下步骤：

1.  将`kaggle_songs`数据加载为 RDD：

    ```scala
    scala> val songs = sc.textFile("songdata/kaggle_songs.txt")

    ```

2.  将用户数据作为 RDD 加载：

    ```scala
    scala> val users = sc.textFile("songdata/kaggle_users.txt")

    ```

3.  将三元组(用户、歌曲、播放)数据加载为 RDD：

    ```scala
    scala> val triplets = sc.textFile("songdata/kaggle_visible_evaluation_triplets.txt")

    ```

4.  将歌曲数据转换为`PairRDD`：

    ```scala
    scala> val songIndex = songs.map(_.split("\\W+")).map(v => (v(0),v(1).toInt))

    ```

5.  将`songIndex`收集为地图：

    ```scala
    scala> val songMap = songIndex.collectAsMap

    ```

6.  将用户数据转换为`PairRDD`：

    ```scala
    scala> val userIndex = users.zipWithIndex.map( t => (t._1,t._2.toInt))

    ```

7.  将`userIndex`收集为地图：

    ```scala
    scala> val userMap = userIndex.collectAsMap

    ```

我们需要`songMap`和`userMap`来替换三元组中的`userId`和`songId`。 Spark 将根据需要自动使这两个映射在群集上可用。 这可以很好地工作，但每次需要时通过群集发送会很昂贵。

更好的方法是使用称为`broadcast`变量的 Spark 功能。 `broadcast`变量允许 Spark 作业保留缓存在每台计算机上的变量的只读副本，而不是随每个任务一起提供一个副本。 Spark 使用高效的广播算法分发广播变量，因此网络上的通信成本可以忽略不计。

正如您可以猜到的，`songMap`和`userMap`都是很好的候选对象，可以围绕`broadcast`变量进行包装。 执行以下步骤：

1.  广播`userMap`：

    ```scala
    scala> val broadcastUserMap = sc.broadcast(userMap)

    ```

2.  广播`songMap`：

    ```scala
    scala> val broadcastSongMap = sc.broadcast(songMap)

    ```

3.  将`triplet`转换为数组：

    ```scala
    scala> val tripArray = triplets.map(_.split("\\W+"))

    ```

4.  导入评级：

    ```scala
    scala> import org.apache.spark.mllib.recommendation.Rating

    ```

5.  将`triplet`数组转换为评级对象的 RDD：

    ```scala
    scala> val ratings = tripArray.map { case Array(user, song, plays) =>
     val userId = broadcastUserMap.value.getOrElse(user, 0)
     val songId = broadcastUserMap.value.getOrElse(song, 0)
     Rating(userId, songId, plays.toDouble)
    }

    ```

现在，我们的数据已经准备好进行建模和预测。

## How to Do It…

1.  导入方式：

    ```scala
    scala> import org.apache.spark.mllib.recommendation.ALS

    ```

2.  使用等级为 10 和 10 的 ALS 构建模型：

    ```scala
    scala> val model = ALS.trainImplicit(ratings, 10, 10)

    ```

3.  从三元组中提取用户和歌曲元组：

    ```scala
    scala> val usersSongs = ratings.map( r => (r.user, r.product) )

    ```

4.  预测用户和歌曲元组：

    ```scala
    scala> val predictions = model.predict(usersSongs)

    ```

## …的工作原理

我们的模型需要四个参数才能工作，如下所示：

<colgroup><col style="text-align: left"> <col style="text-align: left"></colgroup> 
| 

参数

 | 

描述 / 描写 / 形容 / 类别

 |
| --- | --- |
| 兰克 （人名） | 模型中的潜在特征数 |
| 迭代 | 此因式分解要运行的迭代次数 |
| 希腊字母表中第十一个字母 / λ星 | 过拟合参数 |
| 希腊字母表中第一个字母 / 开端 | 观察到的相互作用的相对权重 |

正如您在渐变下降的情况下看到的，这些参数需要手动设置。 我们可以尝试不同的值，但效果最好的值是 RANK=50、Iterations=30、lambda=0.00001 和 Alpha=40。

## 还有更多的…

快速测试不同参数的一种方法是在 Amazon EC2 上生成一个 Spark 集群。 这使您可以灵活地使用功能强大的实例来快速测试这些参数。 我已经创建了一个公共 S3 存储桶`com.infoobjects.songdata`来将数据拉到 Spark。

以下是从 S3 加载数据并运行 ALS 需要遵循的步骤：

```scala
sc.hadoopConfiguration.set("fs.s3n.awsAccessKeyId", "<your access key>")
sc.hadoopConfiguration.set("fs.s3n.awsSecretAccessKey","<your secret key>")
val songs = sc.textFile("s3n://com.infoobjects.songdata/kaggle_songs.txt")
val users = sc.textFile("s3n://com.infoobjects.songdata/kaggle_users.txt")
val triplets = sc.textFile("s3n://com.infoobjects.songdata/kaggle_visible_evaluation_triplets.txt")
val songIndex = songs.map(_.split("\\W+")).map(v => (v(0),v(1).toInt))
val songMap = songIndex.collectAsMap
val userIndex = users.zipWithIndex.map( t => (t._1,t._2.toInt))
val userMap = userIndex.collectAsMap
val broadcastUserMap = sc.broadcast(userMap)
val broadcastSongMap = sc.broadcast(songMap)
val tripArray = triplets.map(_.split("\\W+"))
import org.apache.spark.mllib.recommendation.Rating
val ratings = tripArray.map{ v =>
 val userId: Int = broadcastUserMap.value.get(v(0)).fold(0)(num => num)
 val songId: Int = broadcastSongMap.value.get(v(1)).fold(0)(num => num)
 Rating(userId,songId,v(2).toDouble)
 }
import org.apache.spark.mllib.recommendation.ALS
val model = ALS.trainImplicit(ratings, 50, 30, 0.000001, 40)
val usersSongs = ratings.map( r => (r.user, r.product) )
val predictions =model.predict(usersSongs)

```

这些是在`usersSongs`矩阵上做出的预测。