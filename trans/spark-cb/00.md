# 前言

Hadoop 作为大数据平台的成功提高了用户的期望值，无论是在解决不同的分析挑战方面，还是在减少延迟方面。 随着时间的推移，各种工具不断发展，但是当 Apache Spark 出现时，它提供了一个运行时来解决所有这些挑战。 它消除了将多个工具与各自的挑战和学习曲线相结合的需要。 除了计算外，Apache Spark 还使用内存进行持久存储，消除了在磁盘中存储中间数据的需要，并将处理速度提高了 100 倍。 它还提供了单一的运行时，可以满足各种分析需求，例如机器学习和使用各种库的实时流。

本书介绍了 Apache Spark 的安装和配置，以及使用 Spark Core、Spark SQL、Spark Streaming、MLlib 和 GraphX 库构建解决方案。

### 备注

有关本书食谱的更多信息，请访问[infoobjects.com/spark-cookbook](http://infoobjects.com/spark-cookbook)。

# 这本书涵盖了哪些内容

[第 1 章](01.html "Chapter 1. Getting Started with Apache Spark")，*Apache Spark*入门，解释了如何在各种环境和集群管理器上安装 Spark。

[第 2 章](02.html "Chapter 2. Developing Applications with Spark")，*使用 Spark*开发应用程序，讨论如何在不同的 IDE 上开发 Spark 应用程序以及使用不同的构建工具。

[第 3 章](03.html "Chapter 3. External Data Sources")，*外部数据源*介绍了如何读取和写入各种数据源。

[第 4 章](04.html "Chapter 4. Spark SQL")，*Spark SQL*将带您了解 Spark SQL 模块，该模块可帮助您使用 SQL 界面访问 Spark 功能。

[第 5 章](05.html "Chapter 5. Spark Streaming")，*Spark Streaming*探讨了 Spark Streaming 库以分析来自实时数据源(如 Kafka)的数据。

[第 6 章](06.html "Chapter 6. Getting Started with Machine Learning Using MLlib")，*《使用 MLlib 的机器学习入门》*介绍了机器学习和基本工件(如向量和矩阵)。

[第 7 章](07.html "Chapter 7. Supervised Learning with MLlib – Regression")，*，*带 MLlib 回归的监督学习*，当结果变量连续时，逐步完成监督学习。*

[第 8 章](08.html "Chapter 8. Supervised Learning with MLlib – Classification")，*，*基于 MLlib 分类的监督学习*，讨论了结果变量为离散变量时的监督学习。*

[第 9 章](09.html "Chapter 9. Unsupervised Learning with MLlib")，*使用 MLlib 的无监督学习*，涵盖了 k-均值等无监督学习算法。

[第 10 章](10.html "Chapter 10. Recommender Systems")，*推荐系统*介绍了使用各种技术(如 ALS)构建推荐系统。

[第 11 章](11.html "Chapter 11. Graph Processing Using GraphX")，*使用 GraphX 的图形处理*讨论了使用 GraphX 的各种图形处理算法。

[第 12 章](12.html "Chapter 12. Optimizations and Performance Tuning")，*优化和性能调优*介绍了对 Apache Spark 和性能调优技术的各种优化。

# 这本书你需要什么

您需要 InfoObjects Big Data Sandbox 软件来继续本书中的示例。 该软件可从[http://www.infoobjects.com](http://www.infoobjects.com)下载。

# 这本书是给谁看的

如果您是一名数据工程师、应用程序开发人员或数据科学家，希望利用 Apache Spark 的力量从大数据中获得更好的见解，那么这本书就适合您。

# 节

在这本书中，你会发现几个经常出现的标题(准备好，如何做，它是如何工作的，还有更多，请参阅)。

为了给出如何完成食谱的明确说明，我们使用以下部分：

## 做好准备

本节告诉您食谱中的预期内容，并介绍如何设置食谱所需的任何软件或任何初步设置。

## How to Do It…

本节包含遵循食谱所需的步骤。

## …的工作原理

这一节通常包含对上一节中发生的事情的详细解释。

## 还有更多的…

本部分包含有关食谱的附加信息，以使读者对食谱有更多的了解。

## 另请参阅

本节提供了一些有用的链接，指向食谱中的其他有用信息。

# 公约

在本书中，您将发现许多区分不同类型信息的文本样式。 下面是这些风格的一些例子，并解释了它们的含义。

文本、数据库表名、文件夹名、文件名、文件扩展名、路径名、虚拟 URL、用户输入和 Twitter 句柄中的代码字如下所示：“Spark 期望安装 Java 并设置`JAVA_HOME`环境变量。”

代码块设置如下：

```
lazy val root = (project in file("."))
  settings(
    name := "wordcount"
  )
```

任何命令行输入或输出都如下所示：

```
$ wget http://d3kbcqa49mib13.cloudfront.net/spark-1.4.0-bin-hadoop2.4.tgz

```

**新术语**和**重要单词**以粗体显示。 您在屏幕上看到的单词(例如，在菜单或对话框中)会出现在文本中，如下所示：“单击右上角您的帐户名称下的**安全凭据**。”

### 备注

警告或重要说明会出现在这样的框中。

### 提示

提示和技巧如下所示。

# 读者反馈

欢迎读者的反馈。 让我们知道你对这本书的看法-你喜欢什么或不喜欢什么。 读者反馈对我们很重要，因为它可以帮助我们开发出真正能让您获得最大收益的图书。

要向我们发送一般反馈，只需发送电子邮件`<[feedback@packtpub.com](mailto:feedback@packtpub.com)>`，并在邮件主题中提及书名。

如果有一个您擅长的主题，并且您有兴趣撰写或投稿一本书，请参阅我们的作者指南，网址为[www.Packtpub.com/Authors](http://www.packtpub.com/authors)。

# 客户支持

现在您已经成为 Packt 图书的拥有者，我们有很多东西可以帮助您从购买中获得最大价值。

## 下载本书彩色图片

我们还为您提供了一个 PDF 文件，其中包含本书中使用的屏幕截图/图表的彩色图像。 彩色图像将帮助您更好地了解输出中的更改。 您可以从[https://www.packtpub.com/sites/default/files/downloads/7061OS_ColorImages.pdf](https://www.packtpub.com/sites/default/files/downloads/7061OS_ColorImages.pdf)下载此文件。

## 勘误表

虽然我们已经竭尽全力确保内容的准确性，但错误还是会发生。 如果您在我们的一本书中发现错误--可能是文本或代码中的错误--如果您能向我们报告，我们将不胜感激。 通过这样做，您可以将其他读者从挫折中解救出来，并帮助我们改进本书的后续版本。 如果您发现任何勘误表，请访问[http://www.packtpub.com/submit-errata](http://www.packtpub.com/submit-errata)，选择您的图书，单击**勘误表****提交****表**链接，然后输入勘误表的详细信息。 一旦您的勘误表被核实，您提交的勘误表将被接受，勘误表将被上传到我们的网站或添加到该书目勘误表部分下的任何现有勘误表列表中。

要查看之前提交的勘误表，请转到[https://www.packtpub.com/books/content/support](https://www.packtpub.com/books/content/support)，并在搜索字段中输入图书名称。 所需信息将显示在**勘误表**部分下。

## 盗版

在互联网上盗版版权材料是所有媒体持续存在的问题。 在 Packt，我们非常重视版权和许可证的保护。 如果您在互联网上发现任何形式的非法复制我们的作品，请立即提供我们的位置、地址或网站名称，以便我们采取补救措施。

请拨打`<[copyright@packtpub.com](mailto:copyright@packtpub.com)>`与我们联系，并提供疑似盗版材料的链接。

我们感谢您在保护我们的作者方面的帮助，以及我们为您提供有价值内容的能力。

## 问题

如果您对本书的任何方面有任何问题，您可以拨打`<[questions@packtpub.com](mailto:questions@packtpub.com)>`与我们联系，我们将尽最大努力解决问题。