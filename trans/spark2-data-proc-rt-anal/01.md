# 一、ApacheSpark V2 的首次尝试和新进展

**Apache Spark** 是一个分布式且高度可扩展的内存中数据分析系统，为您提供了用 Java、Scala 和 Python 以及 r 等语言开发应用的能力，在目前的 Apache 顶级项目中，它的贡献/参与率是最高的。Apache 系统，如 Mahout，现在使用它作为处理引擎，而不是 MapReduce。还可以使用 Hive 上下文让 Spark 应用直接处理进出 Apache Hive 的数据。

最初，Apache Spark 提供了四个主要的子模块——SQL、MLlib、GraphX 和 Streaming。它们都将在各自的章节中进行解释，但是简单的概述在这里会很有用。这...

# Spark机器学习

机器学习是 Apache Spark 的真正原因，因为说到底，你不希望只是将数据从 A 运送和转换到 B(一个称为 **ETL** ( **提取转换加载**)的过程)。您希望在数据之上运行高级数据分析算法，并且希望大规模运行这些算法。这就是ApacheSpark的切入点。

Apache Spark 在其核心中为海量并行数据处理提供了运行时，不同的并行机器学习库在其上运行。这是因为像 R 和 Python 这样的流行编程语言有大量的机器学习算法，但是它们是不可扩展的。一旦您将更多数据加载到系统的可用主内存中，它们就会崩溃。

相比之下，Apache Spark 可以利用多个计算机节点组成一个集群，甚至在单个节点上可以透明地将数据溢出到磁盘，因此，避免了主内存瓶颈。Apache Spark 附带了两个有趣的机器学习库，但在本作品中，我们还将介绍第三方机器学习库。

Spark MLlib 模块，经典 MLlib，提供了一个不断增长但不完整的机器学习算法列表。自从推出了名为 **SparkML** 的基于 **DataFrame** 的机器学习 API 之后，MLlib 的命运就明朗了。它只是为了向后兼容而保留。

在 SparkML 中，我们有一个机器学习库，可以利用这些开箱即用的改进，将其用作底层。

SparkML will eventually replace MLlib. Apache SystemML introduces the first library running on top of Apache Spark that is not shipped with the Apache Spark distribution. SystemML provides you with an execution environment of R-style syntax with a built-in cost-based optimizer. Massive parallel machine learning is an area of constant change at a high frequency. It is hard to say where that the journey goes, but it is the first time where advanced machine learning at scale is available to everyone using open source and cloud computing.

Apache Spark 上的深度学习使用 **H20** 、 **Deeplearning4j** 和 **Apache SystemML** ，这些都是 Apache Spark 发行版没有附带的非常有趣的第三方机器学习库的其他示例。

虽然 H20 在某种程度上是 MLlib 的补充，但是 Deeplearning4j 只关注深度学习算法。两者都使用 Apache Spark 作为数据处理并行化的手段。你可能想知道为什么我们想要处理不同的机器学习库。

The reality is that every library has advantages and disadvantages with the implementation of different algorithms. Therefore, it often depends on your data and Dataset size which implementation you choose for best performance.

然而，很高兴有这么多选择，并且在使用 Apache Spark 时，您没有被锁定在一个库中。开源意味着开放，与单一供应商、单一产品锁定相比，这只是我们都从这种方法中受益的一个例子。虽然最近 Apache Spark 将另一个 Apache Spark 库 GraphX 集成到其发行版中，但我们预计这不会太快发生。因此，作为中央数据处理平台的 Apache Spark 很有可能会和额外的第三方库共存，就像 Apache Spark 是大数据操作系统，而第三方库是你在其上安装和运行的软件。

# Spark流

**流处理**是 Apache Spark 的又一大热门话题。它将 Spark 中的数据处理为流，并涵盖了输入和输出操作、转换、持久性和检查点等主题。

Apache Spark Streaming 将涵盖处理领域，我们还将看到不同类型流处理的实际示例。本文讨论批处理和窗口流配置，并提供一个检查点的实际例子。它还涵盖了不同的溪流处理的例子，包括卡夫卡和水槽。

有许多方法可以使用流数据。可以使用其他 Spark 模块功能(例如，SQL、MLlib 和 GraphX)来处理该流。你们...

# Spark SQL

从 Spark 1.3 版本开始，Apache Spark 中引入了数据帧，这样 Spark 数据就可以以表格的形式进行处理，并且可以使用表格函数(如`select`、`filter`、`groupBy`)来处理数据。Spark SQL 模块与 Parquet 和 JSON 格式集成，允许数据以更好地表示数据的格式存储。这也提供了更多与外部系统集成的选项。

还可以引入将 Apache Spark 集成到 Hadoop Hive 大数据数据库中的想法。基于 Hive 上下文的 Spark 应用可用于操作基于 Hive 的表数据。这为 Hive 的大数据存储能力带来了 Spark 的快速内存分布式处理。它有效地让 Hive 使用 Spark 作为处理引擎。

此外，还有大量额外的连接器可以直接从 Apache Spark 访问 Hadoop 生态系统之外的 NoSQL 数据库。

# Spark图处理

当涉及到数据分析时，图形处理是另一个非常重要的话题。事实上，大多数问题都可以用图表来表示。

一张**图**基本上是一个物品及其相互关系的网络。项目称为**节点**，关系称为**边**。关系可以是有向的，也可以是无向的。关系和项目一样，可以有属性。例如，地图也可以表示为图形。每个城市都是一个节点，城市之间的街道是边缘。城市之间的距离可以指定为边缘的属性。

**Apache Spark GraphX** 模块允许 Apache Spark 提供快速的大数据内存图形处理。这允许您运行图形算法...

# 扩展生态系统

在检查大数据处理系统时，我们认为重要的是不仅要看系统本身，还要看它如何扩展以及如何与外部系统集成，以便提供更高级别的功能。在这种规模的书中，我们不可能涵盖所有选项，但通过引入一个主题，我们有望激发读者的兴趣，以便他们能够进一步调查。

# ApacheSpark V2 有什么新鲜事？

自从Apache·斯帕克·V2 以来，许多事情都发生了变化。这并不意味着 API 已经被破坏。相比之下，大多数 1.6 版本的 Apache Spark 应用将在 Apache Spark V2 上运行，无论是否有很小的变化，但在引擎盖下，已经有了很多变化。

虽然 **Java 虚拟机** ( **JVM** )本身就是一个杰作，但是它是一个通用的字节码执行引擎。因此有大量的 JVM 对象管理和**垃圾收集** ( **GC** )开销。例如，为了存储一个 4 字节的字符串，JVM 上需要 48 个字节。垃圾收集器在对象生存期估计上进行了优化，但是 Apache Spark 通常比 JVM 更了解这一点。因此，钨禁用了一个子集的 JVM 垃圾收集...

# 集群设计

正如我们已经提到的，Apache Spark 是一个分布式、内存中的并行处理系统，它需要一个相关的存储系统。因此，当您构建一个大数据集群时，您可能会使用分布式存储系统，如 Hadoop，以及移动数据的工具，如 Sqoop、Flume 和 Kafka。

我们想在大数据集群中引入边缘节点的概念。集群中的这些节点将面向客户端，其上驻留着面向客户端的组件，如 Hadoop 名称节点或Spark主节点。大数据集群的大部分可能位于防火墙之后。边缘节点将降低防火墙造成的复杂性，因为它们将是唯一可从外部访问的接触点。下图显示了一个简化的大数据集群:

![](img/c67b8c64-37f1-45fb-99f3-ee2d80a03065.png)

它显示了带有执行器 JVM 的五个简化集群节点，每个 CPU 内核一个，以及位于集群外部的 Spark Driver JVM。此外，您还可以看到直接连接到节点的磁盘。这叫 **JBOD** ( **只是一堆圆盘**)进场。非常大的文件在磁盘上分区，虚拟文件系统(如 HDFS)将这些块作为一个大的虚拟文件提供。这当然是程式化和简化的，但你明白了。

下面的简化组件模型显示了位于集群外部的驱动 JVM。它与集群管理器对话，以便获得在工作节点上调度任务的权限，因为集群管理器跟踪集群上运行的所有进程的资源分配。

正如我们稍后将看到的，有各种不同的集群管理器，其中一些还能够与 Spark Executors 并行管理其他 Hadoop 工作负载甚至非 Hadoop 应用。请注意，执行器和驱动程序一直都是双向通信的，因此在网络方面，它们也应该紧密地坐在一起:

![](img/6e9505fc-7541-41a5-94b3-1b823fe6c1b4.png)

Figure source: https://spark.apache.org/docs/2.0.2/cluster-overview.html

通常，防火墙在增加集群安全性的同时，也增加了复杂性。系统组件之间的端口需要打开，以便它们可以相互通信。例如，Zookeeper 被许多组件用于配置。发布/订阅消息系统 Apache Kafka 使用 Zookeeper 来配置它的主题、组、消费者和生产者。因此，到 Zookeeper 的客户端端口，可能会穿过防火墙，需要打开。

最后，需要考虑将系统分配给集群节点。例如，如果 Apache Spark 使用 Flume 或 Kafka，那么将使用内存通道。需要考虑数据流导致的这些通道的大小和使用的内存。Apache Spark 不应该在内存使用方面与其他 Apache 组件竞争。根据您的数据流和内存使用情况，可能有必要在不同的集群节点上使用 Spark、Hadoop、Zookeeper、Flume 和其他工具。或者，可以使用资源管理器(如纱、梅索斯或 Docker)来解决这个问题。在标准的 Hadoop 环境中，纱是最有可能的。

通常，充当集群名称节点服务器或 Spark 主服务器的边缘节点将需要比防火墙内的集群处理节点更多的资源。当许多 Hadoop 生态系统组件部署在集群上时，它们都需要主服务器上的额外内存。您应该监视边缘节点的资源使用情况，并根据需要调整资源和/或应用位置。例如，纱正在处理这个问题。

本节简要介绍了大数据集群在 Apache Spark、Hadoop 和其他工具方面的场景。但是，如何配置大数据集群中的 Apache Spark 集群本身？例如，可以有多种类型的 Spark 集群管理器。下一节将对此进行研究，并描述每种类型的 Apache Spark 集群管理器。

# 集群管理

您将在本书的许多示例中看到，Spark上下文可以通过Spark配置对象和Spark网址来定义。Spark 上下文连接到 Spark 集群管理器，然后该管理器在应用的工作节点之间分配资源。集群管理器在集群工作节点之间分配执行器。它将应用 JAR 文件复制给工作人员，最后分配任务。

以下小节描述了目前可用的可能的 Apache Spark 集群管理器选项。

# 当地的

通过指定 Spark 配置本地 URL，可以让应用在本地运行。通过指定`local[n]`，可以让 Spark 使用 *n* 线程在本地运行应用。这是一个有用的开发和测试选项，因为您还可以测试某种并行化场景，但将所有日志文件保留在一台机器上。

# 单独的

独立模式使用 Apache Spark 提供的基本集群管理器。Spark主网址如下:

`Spark://<hostname>:7077`

这里，`<hostname>`是运行 Spark 主机的主机的名称。我们指定了`7077`作为端口，这是默认值，但这是可配置的。这个简单的集群管理器目前只支持**先进先出** ( **先进先出**)调度。通过为每个应用设置资源配置选项，您可以设法允许并发应用调度；例如，使用`spark.core.max`在应用之间共享内核。

# Apache 纱

在更大的范围内，当与 Hadoop YARN 集成时，Apache Spark 集群管理器可以是 Spark，应用可以以两种模式之一运行。如果Spark主值设置为`yarn-cluster`，则应用可以提交到集群，然后终止。集群将负责分配资源和运行任务。但是，如果应用主文件作为`yarn-client`提交，则应用在处理的生命周期中保持活动状态，并向纱请求资源。

# Apache月

**Apache Mesos** 是一个开源系统，用于跨集群的资源共享。它允许多个框架通过管理和调度资源来共享一个集群。它是一个集群管理器，使用 Linux 容器提供隔离，并允许多个系统(如 Hadoop、Spark、Kafka、Storm 等)安全地共享一个集群。它可以高度扩展到数千个节点。它是一个基于主/从的系统，并且是容错的，使用 Zookeeper 进行配置管理。

对于单个主节点 Mesos 集群，Spark 主 URL 将采用以下形式:

`mesos://<hostname>:5050`。

这里，`<hostname>`是 Mesos 主服务器的主机名；该端口被定义为`5050,`，它是默认的 Mesos 主端口(这是...

# 基于云的部署

云系统有三个不同的抽象层次- **基础设施即服务**(**IaaS**)**平台即服务** ( **PaaS** )和**软件即服务** ( **SaaS** )。我们将看到如何在所有这些设备上使用和安装 Apache Spark。

实现 IaaS 的新方法是 Docker 和 Kubernetes，而不是虚拟机，基本上提供了一种在几分钟内自动设置 Apache Spark 集群的方法。Kubernetes 的优势在于，它可以在多个不同的云提供商之间使用，因为它是一个开放标准，也基于开源。

您甚至可以在本地数据中心使用 Kubernetes，并在本地、专用和公共云数据中心之间透明地动态移动工作负载。相比之下，PaaS 免去了您安装和操作 Apache Spark 集群的负担，因为这是作为服务提供的。

目前正在讨论 Docker 是 IaaS 还是 PaaS，但在我们看来，这只是一种轻量级预装虚拟机的形式。这一点特别有趣，因为该产品完全基于开源技术，这使您能够在任何其他数据中心复制该系统。

我们将介绍的开源组件之一是 Jupyter 笔记本；在基于云的协作环境中进行数据科学的现代方式。

# 表演

在继续下一章之前，涵盖 Apache Spark 和扩展的功能领域，我们将研究性能领域。需要考虑哪些问题和领域？从集群级别开始，到实际的 Scala 代码结束，什么可能会影响 Spark 应用的性能？我们不想只是重复，星火网站说的，所以看看这个网址:`http://spark.apache.org/docs/<version>/tuning.html`。

这里，`<version>`与你正在使用的 Spark 版本有关；也就是说，要么是最新的，要么是类似于特定版本的`1.6.1`。所以，看完这一页，我们将简要地提到一些主题领域。我们将在本节中列出一些要点，但不暗示...

# 集群结构

大数据集群的规模和结构将影响性能。如果您有一个基于云的集群，与非共享硬件集群相比，您的输入输出和延迟会受到影响。您将与多个客户共享底层硬件，并且群集硬件可能是远程的。这也有一些例外。例如，IBM cloud 提供了专用的裸机高性能集群节点，带有 InfiniBand 网络连接，可以每小时租用一次。

此外，服务器上群集组件的位置可能会导致资源争用。例如，仔细考虑在大型集群中定位 Hadoop 名称节点、Spark服务器、动物园管理员、水槽和卡夫卡服务器。对于高工作负载，您可以考虑将服务器隔离到单独的系统。您也可以考虑使用 Apache 系统，如 Mesos，它为单个进程提供了更好的分配和资源分配。

还要考虑潜在的并行性。对于大型数据集，Spark 集群中的工作人员数量越多，并行性的机会就越大。一个经验法则是每个超线程或虚拟内核分别有一个工作者。

# Hadoop 分布式文件系统

根据您的集群需求，您可以考虑使用 HDFS 的替代方案。例如，为了提高性能，IBM 推出了 GPFS 通用文件系统。

GPFS 可能是更好选择的原因是，从高性能计算背景来看，该文件系统具有完全的读写能力，而 HDFS 被设计为一次写入，读取多个文件系统。它比 HDFS 在性能上有所提高，因为它运行在内核级别，而 HDFS 运行在一个作为操作系统进程运行的 Java 虚拟机中。它还集成了 Hadoop 和 Spark 集群工具。IBM 使用 GPFS 运行数百千兆字节的设置。...

# 数据局部性

良好数据处理性能的关键是避免网络传输。这在几年前是非常正确的，但是对于高 CPU 需求和低 I/O 的任务来说不太相关，但是对于低 CPU 需求和高 I/O 需求的数据处理算法来说，这仍然成立。

We can conclude from this, that HDFS is one of the best ways to achieve data locality, as chunks of files are distributed on the cluster nodes, in most of the cases, using hard drives directly attached to the server systems. This means that those chunks can be processed in parallel using the CPUs on the machines where individual data chunks are located in order to avoid network transfer.

另一种实现数据局部性的方法是使用`ApacheSparkSQL`。根据连接器的实现，SparkSQL 可以利用源引擎的数据处理能力。因此，例如，当将 MongoDB 与 SparkSQL 结合使用时，在数据被上游发送到 Apache Spark 之前，部分 SQL 语句由 MongoDB 进行预处理。

# 记忆

为了避免您的 Apache Spark 集群上的任务出现 **OOM** ( **内存不足**)消息，请考虑一些调优问题:

*   考虑 Spark 工作节点上可用的物理内存级别。可以增加吗？检查高工作负载期间操作系统进程的内存消耗，以便了解空闲内存。确保工人有足够的记忆。
*   考虑数据分区。你能增加分区的数量吗？根据经验，您应该至少拥有与集群上可用 CPU 内核一样多的分区。使用 RDD 应用编程接口上的`repartition`功能。
*   你能修改 JVM 用来存储和缓存 rdd 的存储份额和内存吗？...

# 编码

尝试调整您的代码，以提高 Spark 应用的性能。例如，在 ETL 周期的早期过滤基于应用的数据。一个例子是，当使用原始的超文本标记语言文件时，在早期阶段将它们分离出来并裁剪掉不需要的部分。调整您的并行度，尝试找到代码中耗费资源的部分，并找到替代方案。

**ETL** is one of the first things you are doing in an analytics project. So you are grabbing data, from third-party systems, either by directly accessing relational or NoSQL databases or by reading exports in various file formats such as, CSV, TSV, JSON or even more exotic ones from local or remote filesystems or from a staging area in HDFS: after some inspections and sanity checks on the files an ETL process in Apache Spark basically reads in the files and creates RDDs or DataFrames/Datasets out of them.

它们被转换，以便适合下游分析应用，运行在 Apache Spark 或其他应用之上，然后作为 JSON、CSV 或 PARQUET 文件存储回文件系统，甚至存储回关系数据库或 NoSQL 数据库。

Finally, I can recommend the following resource for any performance-related problems with Apache Spark: [https://spark.apache.org/docs/latest/tuning.html](https://spark.apache.org/docs/latest/tuning.html).

# 云

尽管本书的部分内容将集中在安装在基于物理服务器的集群上的 Apache Spark 的示例上，但我们想指出的是，有多种基于云的选项意味着许多好处。有使用 Apache Spark 作为集成组件的基于云的系统，也有提供 Spark 即服务的基于云的系统。

# 错误和恢复

一般来说，您的申请需要问的问题是:接收和处理所有数据是否至关重要？如果没有，那么在失败时，您可能只能重新启动应用并丢弃丢失的数据。如果不是这样，那么您将需要使用检查点，这将在下一节中描述。

同样值得注意的是，您的应用的错误管理应该是健壮且自给自足的。我们这样说的意思是，如果一个异常不是关键的，那么管理这个异常，也许记录它，然后继续处理。例如，当任务达到最大失败次数(由`spark.task.maxFailures`指定)时，它将终止处理。

This property, among others, can be set during creation of the `SparkContext` object or as additional command line parameters when invoking `spark-shell` or `spark-submit`.

# 摘要

在本章的最后，我们邀请您通过以下章节中的每个基于 Scala 代码的示例来完成您的工作。Apache Spark 的发展速度令人印象深刻，值得注意的是发布的频率。因此，即使在撰写本文时，Spark 已经达到 2.2，我们也确信您将使用更高的版本。

遇到问题，到[www.stackoverflow.com](http://www.stackoverflow.com)举报，并做好相应的标记；你会在几分钟内收到反馈——用户社区非常活跃。获取信息和帮助的另一种方式是订阅 Apache Spark 邮件列表:`user@apachespark.org`。

到这一章结束时，你应该对这本书里等待你的东西有一个好的想法。我们致力于...