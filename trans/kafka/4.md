# 第四章。卡夫卡设计

在我们开始通过编写卡夫卡生产者和消费者的代码来弄脏我们的手之前，让我们快速讨论一下卡夫卡的内部设计。

在本章中，我们将重点讨论以下主题:

*   卡夫卡设计基础
*   卡夫卡中的信息压缩
*   卡夫卡的集群镜像
*   卡夫卡中的复制

由于与 JMS 及其各种实现相关的开销以及扩展架构的限制，LinkedIn([www.linkedin.com](http://www.linkedin.com))决定构建 Kafka 来满足他们对监控活动流数据和操作指标(如 CPU、I/O 使用和请求计时)的需求。

开发卡夫卡时，主要重点是提供以下内容:

*   生产者和消费者支持定制实现的应用编程接口
*   具有消息持久性的低网络和存储开销
*   支持数百万条消息的高吞吐量
*   分布式和高度可扩展的体系结构

# 卡夫卡设计基础

在一个非常基本的结构中，生产者向卡夫卡主题发布消息，这个主题是由卡夫卡经纪人作为卡夫卡服务器创建的。然后，消费者订阅卡夫卡主题来获取信息。下图对此进行了描述:

![Kafka design fundamentals](graphics/7938OS_04_01.jpg)

在前面的图中，显示了单节点-单代理架构。该架构考虑到所有三方——生产者、卡夫卡经纪人和消费者——都在不同的机器上运行。

这里，每个消费者被表示为一个过程，并且这些过程被组织在称为 **消费者组**的组中。

一条消息由消费者组中的单个进程(消费者)消费，如果要求一条消息由多个消费者消费，则所有这些消费者需要保存在不同的消费者组中。

通过卡夫卡设计，任何被消费的消息的消息状态都保持在消息消费者中，卡夫卡经纪人不保持谁消费了什么的记录，这也意味着定制消费者的糟糕设计最终导致多次阅读相同的消息。

重要卡夫卡设计事实如下:

*   Kafka 的基本支柱是消息缓存并将其存储在文件系统上。在 Kafka 中，数据会立即写入操作系统内核页面。将数据缓存和刷新到磁盘是可配置的。
*   Kafka 提供了消费后更长的信息保留时间，允许消费者在需要时再次消费。
*   Kafka 使用消息集对消息进行分组，以减少网络开销。
*   Unlike most of the messaging systems, where metadata of the consumed messages are kept at server level, in Kafka, the state of the consumed messages is maintained at consumer level. This also addresses issues such as:
    *   由于失败而丢失消息
    *   同一邮件的多次传递

    默认情况下，消费者将状态存储在 ZooKeeper 中，但 Kafka 也允许将其存储在用于**在线事务处理** ( **OLTP** ) 应用程序的其他存储系统中。

*   在卡夫卡，生产者和消费者在传统的推拉模式下工作，生产者把信息推给卡夫卡经纪人，消费者从经纪人那里拉信息。
*   卡夫卡没有任何大师的概念，把所有的经纪人都当作同行。这种方法便于在任何时候添加和删除卡夫卡式经纪人，因为经纪人的元数据在 ZooKeeper 中维护，并与生产者和消费者共享。
*   在 Kafka 0.7.x 中，基于 ZooKeeper 的负载平衡允许生产者动态发现代理。生产者维护一个代理连接池，并使用 ZooKeeper 观察器回调不断更新它。但是在 Kafka 0.8.x 中，负载均衡是通过 Kafka 元数据 API 实现的，ZooKeeper 只能用来识别可用代理的列表。
*   生产者还可以选择异步或同步模式向代理发送消息。

# 卡夫卡中的消息压缩

正如我们已经讨论过的，卡夫卡使用消息集特征对消息进行分组。它还提供了消息组压缩功能。在这里，数据由消息生产者使用**【GZIP】**或**爽快的** 压缩协议压缩，并由消息消费者解压缩。压缩消息集的网络开销较小，在消费端的解压缩开销也很小。

这一组压缩的消息可以作为单个消息呈现给消费者，消费者随后对其进行解压缩。因此，压缩的消息本身可能具有无限的消息深度。

为了区分压缩和未压缩的消息，在消息头中引入了压缩属性字节。在这个压缩字节中，最低的两位用于表示用于压缩的压缩编解码器，最后两位的值`0`表示未压缩的消息。

消息压缩技术对于使用 Kafka 跨数据中心镜像数据非常有用，在 Kafka 中，大量数据以压缩格式从主动数据中心传输到被动数据中心。

### 注

有关卡夫卡消息压缩的更多详细用法，请访问[。](https://cwiki.apache.org/confluence/display/KAFKA/Compression)

# 卡夫卡中的集群镜像

卡夫卡镜像功能用于创建现有集群的副本，例如，用于将主动数据中心复制到被动数据中心。Kafka 提供了一个镜像工具，用于将源集群镜像到目标集群。

下图描述了架构形式的镜像工具放置:

![Cluster mirroring in Kafka](graphics/7938OS_04_02.jpg)

在这种体系结构中，镜像工具的工作是使用来自源集群的消息，并在目标集群上重新发布它们。

卡夫卡迁移工具使用类似的方法从 0.7.x 卡夫卡集群迁移到 0.8.x 卡夫卡集群。

### 注

有关镜像制作工具设置和配置的详细说明，请访问[。](https://cwiki.apache.org/confluence/display/KAFKA/Kafka+mirroring+%28MirrorMaker%29)

# 卡夫卡中的复制

在我们讨论卡夫卡中的复制之前，我们先来讨论一下消息划分。在卡夫卡中，消息分割策略用于卡夫卡的经纪人端。消息如何划分由生产者决定，代理按照消息到达的顺序存储消息。可以在 Kafka 代理中为每个主题配置分区的数量。

卡夫卡复制是卡夫卡 0.8 中引入的非常重要的特性之一。虽然 Kafka 具有很高的可伸缩性，但是为了更好的消息持久性和 Kafka 集群的高可用性，复制保证了消息即使在代理失败的情况下也能被发布和消费，代理失败可能是由任何原因引起的。在这里，生产者和消费者都意识到卡夫卡的复制。下图解释了卡夫卡中的复制:

![Replication in Kafka](graphics/7938OS_04_03.jpg)

让我们详细讨论前面的图表。

在复制中，消息的每个分区都有 *n* 个副本，并且可以承受 *n-1* 个故障来保证消息传递。在 *n* 副本中，一个副本充当其余副本的主要副本。ZooKeeper 保存关于引导副本和当前同步跟随副本的信息(引导副本维护所有同步跟随副本的列表)。

每个副本都将其消息部分存储在本地日志和偏移量中，并定期同步到磁盘。该过程还确保消息要么写入所有副本，要么不写入任何副本。

如果主副本失败，无论是在将消息分区写入其本地日志时，还是在向消息生成器发送确认之前，生成器都会将消息分区重新发送给新的主代理。

选择新线索副本的过程是所有追随者的**同步副本**(**ISR**)向动物园管理员注册。第一个注册的副本成为新的主副本，其余的注册副本成为从副本。

卡夫卡支持以下复制模式:

*   **Synchronous replication**: In synchronous replication, a producer first identifies the lead replica from ZooKeeper and publishes the message. As soon as the message is published, it is written to the log of the lead replica and all the followers of the lead start pulling the message, and by using a single channel, the order of messages is ensured. Each follower replica sends an acknowledgement to the lead replica once the message is written to its respective logs. Once replications are complete and all expected acknowledgements are received, the lead replica sends an acknowledgement to the producer.

    在消费者端，所有消息的提取都是从主副本中完成的。

*   **异步复制**:在这种模式下的唯一区别是，只要一个主要副本将消息写入其本地日志，它就会将确认发送到消息客户端，而不会等待来自后续副本的确认。但是作为一个缺点，这种模式不能确保在代理失败时的消息传递。

### 注

关于卡夫卡复制及其用法的详细说明，请访问[。](https://cwiki.apache.org/confluence/display/KAFKA/Kafka+Replication)

# 总结

在这一章中，我们学习了为卡夫卡打下坚实基础的设计理念。

在下一章中，我们将重点关注如何使用提供的 API 编写卡夫卡制作人。