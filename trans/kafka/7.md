# 第七章。卡夫卡集成

考虑一个网站的使用案例，其中需要跟踪连续的安全事件，例如用户身份验证和访问安全资源的授权，并且需要针对任何安全漏洞实时做出决策。使用任何典型的面向批处理的数据处理系统，如 Hadoop，需要先收集所有数据，然后进行处理以找出模式，这将使判断网络应用程序是否存在任何安全威胁为时已晚。因此，这是实时数据处理的经典用例。

让我们考虑另一个使用案例，其中捕获并预处理了客户通过网站使用生成的原始点击流。处理这些点击流提供了对客户偏好的有价值的洞察，并且这些洞察可以在以后与营销活动和推荐引擎相结合，以提供对消费者的分析。因此，我们可以简单地说，存储在 Hadoop 上的大量点击流数据将由 Hadoop MapReduce 作业以批处理模式进行处理，而不是实时处理。

在本章中，我们将探讨如何将 Kafka 与以下技术集成，以解决不同的用例，例如使用 Storm 的实时处理和使用 Hadoop 的批处理:

*   卡夫卡与《风暴》的融合
*   Kafka 与 Hadoop 的集成

让我们开始吧。

# 卡夫卡与风暴的融合

使用技术实时处理少量数据从来不是一个挑战，例如 **Java 消息服务**(**JMS**)；然而，这些处理系统在处理大量流数据时表现出性能限制。此外，这些系统不是好的可扩展解决方案。

## 风暴介绍

**Storm** 是一个开源、分布式、可靠和容错的系统，用于实时处理大量数据流。它支持许多用例，如实时分析、在线机器学习、连续计算，以及 **提取转换加载** ( **ETL** )范式。

有各种组件协同工作进行流数据处理，如下所示:

*   **喷口**:这个是一个流的来源，是一个连续的日志数据流。
*   **螺栓**:喷嘴将数据传递给一个名为**螺栓**T5 的组件。一个 bolt 消耗任意数量的输入流，进行一些处理，并可能发出新的流。例如，通过处理推文流来发出趋势分析流。

下图显示了风暴架构中的喷口和螺栓:

![Introduction to Storm](graphics/7938OS_07_01.jpg)

我们可以假设一个风暴集群是一个螺栓组件链，其中每个螺栓对喷口流过的数据执行某种转换。

在风暴集群中，下一个作业通常被称为**拓扑**；唯一的区别是这些拓扑永远运行。为了在风暴上进行实时计算，创建了拓扑，它只不过是计算图。通常，拓扑定义数据如何从喷口通过螺栓流动。这些拓扑本质上可以是事务性的，也可以是非事务性的。

### 注

关于风暴的完整信息可以在[http://storm-project.net/](http://storm-project.net/)找到。

如果您使用过 Storm 或者对 Storm 有一定的了解，以下部分将会非常有用。

## 整合风暴

我们在前面的章节中已经了解到卡夫卡是一个基于发布者-订阅者的高性能消息传递系统，具有高度可伸缩性。卡夫卡喷口可用于整合风暴与卡夫卡集群。

卡夫卡风暴喷口的源代码可以在[上获得。](https://github.com/nathanmarz/storm-contrib/tree/master/storm-kafka)

卡夫卡喷口是一个常规喷口实现，它从卡夫卡集群中读取数据。连接到卡夫卡集群需要以下参数:

*   卡夫卡经纪人名单
*   每台主机的分区数
*   用于提取消息的主题名称
*   ZooKeeper 中的根路径，Spout 在这里存储消费者偏移量
*   在 ZooKeeper 中存储消费者偏移量所需的消费者的标识

下面的代码示例显示了使用前面的参数进行的`KafkaSpout`类实例初始化:

```scala
SpoutConfig spoutConfig = new SpoutConfig(
  ImmutableList.of("localhost:9092", "localhost:9093"), 
  2, 
  " othertopic", 
  "/kafkastorm", 
  "consumID"); 
KafkaSpout kafkaSpout = new KafkaSpout(spoutConfig);
```

卡夫卡壶嘴使用 ZooKeeper 来存储消息偏移的状态，并在消息被消耗时进行分段消耗跟踪。这些偏移量存储在为 ZooKeeper 指定的根路径上。默认情况下，Storm 使用它自己的 ZooKeeper 集群来存储消息偏移量，但是也可以通过在 Spout 配置中设置它来使用其他 ZooKeeper 集群。根据设计，Spout 在单线程模型中工作，因为所有的并行性都由 Storm 集群处理。它还可以倒回上一个偏移，而不是从上次保存的偏移开始。

Kafka Spout 还提供了一个选项，通过设置属性(如缓冲区大小和超时)来指定 Spout 如何从 Kafka 集群中获取消息。

### 注

要运行带有风暴的卡夫卡，风暴和卡夫卡的集群都需要设置并应该运行。风暴集群设置不在本书的讨论范围之内。

下面的图展示了卡夫卡风暴工作模型的高级集成视图:

![Integrating Storm](graphics/7938OS_07_02.jpg)

# 卡夫卡与 Hadoop 的融合

资源共享、稳定性、可用性和可扩展性是分布式计算面临的众多挑战中的几个。如今，另一个挑战是处理待定项或待决项中的大量数据。

## Hadoop 简介

Hadoop 是一个大规模分布式批处理框架，它跨多个节点并行处理数据，并解决分布式计算的挑战，包括大数据。

Hadoop 的工作原理是 MapReduce 框架(由 Google 引入)，它为大规模计算的并行化和分布提供了一个简单的接口。Hadoop 有自己的分布式数据文件系统，名为 **HDFS** ( **Hadoop 分布式文件系统** ) 。在任何典型的 Hadoop 集群中，HDFS 将数据分割成小块(称为**块** )并将其分发到所有节点。HDFS 还创建了这些小数据片段的复制，并将其存储起来，以确保如果任何节点出现故障，数据可以从另一个节点获得。

下图显示了多节点 Hadoop 集群的高级视图:

![Introduction to Hadoop](graphics/7938OS_07_03.jpg)

Hadoop 有以下主要组件:

*   **名称节点**:这个是 HDFS 的单点交互。名称节点存储关于分布在节点上的小块数据的信息。
*   **二级名称节点**:该节点存储编辑日志，有助于在名称节点发生故障时，恢复 HDFS 最新更新状态。
*   **数据节点**:这些节点以块的形式存储名称节点分发的实际数据，也存储来自其他节点的数据的复制副本。
*   **作业跟踪器**:这个是负责将 MapReduce 作业拆分成更小的任务。
*   **任务跟踪器**:任务跟踪器负责执行作业跟踪器拆分的任务。

数据节点和任务跟踪器共享同一台机器，MapReduce 作业被拆分，任务的执行基于名称节点提供的数据存储位置信息。

### 注

关于 Hadoop 的完整信息可以在[http://hadoop.apache.org/](http://hadoop.apache.org/)找到。

## 集成 Hadoop

这个部分如果你曾经使用过 Hadoop 或者有 Hadoop 的工作知识的话，是很有用的。

对于实时发布-订阅用例，Kafka 用于构建可用于实时处理或监控的管道，并将数据加载到 Hadoop、NoSQL 或数据仓库系统中进行离线处理和报告。

Kafka 在其`contrib`目录下提供了 Hadoop 生产者和消费者的源代码。

### 注

本节只讨论 Kafka 代码库为 Hadoop 提供的源代码；没有讨论针对 Kafka 和 Hadoop 集成的其他第三方解决方案。

## Hadoop 制作人

一个 Hadoop 生产者提供了一个将数据从 Hadoop 集群发布到 Kafka 的桥梁，如下图所示:

![Hadoop producer](graphics/7938OS_07_04.jpg)

对于一个卡夫卡式的制作人来说，卡夫卡式的主题被认为是 URIs，而要连接到一个特定的卡夫卡式经纪人，URIs 被指定如下:

```scala
kafka://<kafka-broker>/<kafka-topic>
```

Hadoop 生产者代码建议了两种从 Hadoop 获取数据的可能方法:

*   **使用 Pig 脚本并以 Avro 格式**编写消息:在这种方法中，卡夫卡制作者使用 **Pig** 脚本以二进制 **Avro** 格式编写数据，其中每行表示一条消息。为了将数据推入卡夫卡集群，`AvroKafkaStorage`类(扩展了 Pig 的`StoreFunc`类)将 Avro 模式作为其第一个参数，并连接到卡夫卡 URI。使用`AvroKafkaStorage`制作人，我们还可以在同一个基于 Pig 脚本的工作中轻松地写给多个主题和经纪人。
*   **对作业使用 Kafka OutputFormat 类**:在这种方法中，Kafka `OutputFormat`类(扩展了 Hadoop 的`OutputFormat`类)用于向 Kafka 集群发布数据。这种方法将消息发布为字节，并通过使用低级发布方法来提供对输出的控制。卡夫卡`OutputFormat`类使用`KafkaRecordWriter`类(扩展了 Hadoop 的`RecordWriter`类)向 Hadoop 集群写入记录(消息)。

对于卡夫卡制作人，我们还可以在一个作业的配置下配置卡夫卡制作人参数和卡夫卡经纪人信息。

### 注

有关卡夫卡制作人的更多详细用法，请参考`Kafka-0.8/contrib/hadoop-producer`目录下的`README`。

## Hadoop 消费者

一个 Hadoop 消费者是一个 Hadoop 作业，从卡夫卡经纪人那里获取数据，并将其推入 HDFS。下图显示了卡夫卡消费者在架构模式中的位置:

![Hadoop consumer](graphics/7938OS_07_05.jpg)

一个 Hadoop 作业执行从卡夫卡到 HDFS 的并行加载，加载数据的映射器数量取决于输入目录中的文件数量。输出目录包含来自卡夫卡的数据和更新的主题偏移。单个地图绘制者在地图任务结束时将最后一条消耗的消息的偏移量写入 HDFS。如果某个作业失败并且重新启动了作业，则每个映射器只需从存储在 HDFS 的偏移量重新启动。

`Kafka-0.8/contrib/hadoop-consumer`目录中提供的 ETL 示例演示了提取卡夫卡数据并将其加载到 HDFS。

### 注

有关卡夫卡消费者详细用法的更多信息，请参考`Kafka-0.8/contrib/hadoop-consumer`目录下的`README`。

# 总结

在这一章中，我们已经学习了 Kafka 集成如何同时适用于 Storm 和 Hadoop，以满足实时和批处理需求。

在下一章，也是本书的最后一章，我们将看看关于卡夫卡的一些其他重要事实。