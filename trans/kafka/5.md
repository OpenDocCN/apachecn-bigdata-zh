# 第五章。写作生产者

生产者是创建消息并将它们发布给卡夫卡经纪人以供进一步消费的应用程序。这些生产者在性质上可以不同；例如，前端应用程序、后端服务、代理应用程序、遗留系统的适配器以及 Hadoop 的生产者。这些生成器也可以用不同的语言实现，比如 Java 、 C 和 Python。

在本章中，我们将重点讨论以下主题:

*   面向消息生产者的卡夫卡应用编程接口
*   简单的基于 Java 的卡夫卡制作人
*   使用消息分区的基于 Java 的卡夫卡制作人

在这一章的最后，我们将探索卡夫卡制作人需要的一些重要属性。

我们开始吧。下图解释了消息生产者的卡夫卡应用编程接口:

![Writing Producers](graphics/7938OS_05_01.jpg)

在接下来的几节中，我们将讨论卡夫卡为编写基于 Java 的定制生产者提供的 API。

# Java 生产者 API

以下是为编写卡夫卡集群的基于 Java 的基本生产者而导入的类:

*   **Producer**: Kafka provides the `Producer` class (`class Producer<K,V>`) for creating messages for single or multiple topics with message partition as an optional feature. The following is the class diagram and its explanation:

    ![The Java producer API](graphics/7938OS_05_02.jpg)

    这里，`Producer`是一个用 Scala 编写的 Java 泛型([http://en.wikipedia.org/wiki/Generics_in_Java](http://en.wikipedia.org/wiki/Generics_in_Java))的类型，这里我们需要指定参数的类型；`K`和`V` 分别指定分区键和消息值的类型。

*   **KeyedMessage**: The `KeyedMessage` class takes the topic name, partition key, and the message value that needs to be passed from the producer as follows:

    ```scala
    class KeyedMessage[K, V](val topic: String, val key: K, val message: V) 
    ```

    这里，`KeyedMessage`是一种用 Scala 编写的 Java 泛型，我们需要在这里指定参数的类型；`K`和`V`分别指定分区键和消息值的类型，主题始终为`String`类型。

*   **producterconfig**:类`ProducerConfig`封装了与代理建立连接所需的值，如代理列表、消息分区类、消息的序列化程序类和分区密钥。

# 简单的 Java 生产者

现在我们将开始编写一个简单的基于 Java 的生产者来将消息传输给代理。这个`SimpleProducer`类用于为一个特定的主题创建一个消息并传输它。

## 导入类

作为第一步，我们需要导入以下类:

```scala
import kafka.javaapi.producer.Producer;
import kafka.producer.KeyedMessage;
import kafka.producer.ProducerConfig;
```

## 定义属性

作为编写生产者的下一步，我们需要定义与卡夫卡经纪人建立连接的属性，并将这些属性传递给卡夫卡生产者:

```scala
Properties props = new Properties();
props.put("metadata.broker.list","localhost:9092");
props.put("serializer.class","kafka.serializer.StringEncoder");
props.put("request.required.acks", "1");
ProducerConfig config = new ProducerConfig(props); 
Producer<Integer, String> producer = new Producer<Integer, String>(config);
```

现在让我们看看代码中提到的主要属性:

*   `metadata.broker.list`:这个属性指定了生产者需要连接的代理`<node:port>`(更多信息在下一个例子中提供)。
*   `serializer.class list`:这个属性指定了在准备消息从生产者传输到代理时需要使用的序列化程序类。在这个例子中，我们将使用卡夫卡提供的字符串编码器。默认情况下，键和消息的序列化程序类是相同的，但是我们可以通过使用`key.serializer.class`属性来更改键的序列化程序类。
*   `request.required.acks`:该属性指示卡夫卡经纪人在收到消息时向制作人发送确认。默认情况下，制作人在“火了就忘”模式下工作，消息丢失不通知。

## 构建消息并发送

作为最后一步，我们需要构建消息并将其发送给代理，如以下代码所示:

```scala
String messageStr = new String("Hello from Java Producer");
KeyedMessage<Integer, String> data = new KeyedMessage<Integer, String>(topic, messageStr);
producer.send(data); 
```

完整的程序如下所示:

```scala
package test.kafka;

import java.util.Properties;
import kafka.javaapi.producer.Producer;
import kafka.producer.KeyedMessage;
import kafka.producer.ProducerConfig;

public class SimpleProducer {
    private static Producer<Integer, String> producer;
    private final Properties props = new Properties();public    SimpleProducer()
    {
      props.put("broker.list", "localhost:9092");
      props.put("serializer.class", "kafka.serializer.StringEncoder");
      props.put("request.required.acks", "1");
      producer = new Producer<Integer, String>(new ProducerConfig(props));
    }
public static void main(String[] args) {
    SimpleProducer sp = new SimpleProducer();
    String topic = (String) args[0];
    String messageStr = (String) args[1];
    KeyedMessage<Integer, String> data = new KeyedMessage<Integer, String>(topic, messageStr);
    producer.send(data);
    producer.close();
  }
}
```

编译前面的程序，使用以下命令运行:

```scala
 [root@localhost kafka-0.8]# java SimpleProducer kafkatopic Hello_There
```

这里，`kafkatopic`是消息`Hello_There`发送给经纪人时会自动创建的话题。

# 用消息分区创建一个简单的 Java 生产者

前面的例子是`Producer`类的一个非常基本的例子，它只使用一个代理，没有显式的消息分区。让我们跳到下一个层次，编写另一个连接到多个代理并使用消息分区的程序。

## 导入类

对于本程序，该步骤保持不变。

## 定义属性

作为下一个步骤，我们需要定义与卡夫卡经纪人建立连接的属性，如下面的代码所示，并将这些属性传递给卡夫卡制作人:

```scala
Properties props = new Properties();
props.put("metadata.broker.list","localhost:9092, localhost:9093");
props.put("serializer.class","kafka.serializer.StringEncoder"); 
props.put("partitioner.class", "test.kafka.SimplePartitioner");
props.put("request.required.acks", "1");
ProducerConfig config = new ProducerConfig(props); 
Producer<Integer, String> producer = new Producer<Integer, String>(config);
```

之前的属性列表唯一的变化是在`metadata.broker.list`和`partitioner.class`中。

*   `metadata.broker.list`:这个属性指定了制作人需要连接的经纪人列表(采用`[<node:port>, <node:port>]`格式)。Kafka 生产者自动找到主题的主要代理，并在向代理发送任何消息之前，通过请求元数据对其进行划分。
*   `partitioner.class`:该属性定义了用于确定主题中需要发送消息的分区的类。如果密钥为空，Kafka 使用随机分区进行消息分配。

## 实现分区器类

接下来，我们需要实现`Partitioner`类，如下代码所示:

```scala
package test.kafka;
import kafka.producer.Partitioner;
public class SimplePartitioner implements Partitioner<Integer> {
    public int partition(Integer key, int numPartitions) {
        int partition = 0;
        int iKey = key;
        if (iKey > 0) {
           partition = iKey % numPartitions;
        }
       return partition;
  }
}
```

## 构建消息并发送

作为最后一步，我们需要构建消息并将其发送给经纪人。以下是该计划的完整列表:

```scala
package test.kafka;

import java.util.Properties;
import java.util.Random;
import kafka.javaapi.producer.Producer;
import kafka.producer.KeyedMessage;
import kafka.producer.ProducerConfig;

public class MultiBrokerProducer {
    private static Producer<Integer, String> producer;
    private final Properties props = new Properties();

      public MultiBrokerProducer()
    {
    props.put("metadata.broker.list","localhost:9092, localhost:9093");
      props.put("serializer.class","kafka.serializer.StringEncoder"); 

      props.put("partitioner.class", "test.kafka.SimplePartitioner");

      props.put("request.required.acks", "1");

      ProducerConfig config = new ProducerConfig(props); 
      producer = new Producer<Integer, String>(config);
    }
  public static void main(String[] args) {
    MultiBrokerProducer sp = new MultiBrokerProducer();
        Random rnd = new Random();

        String topic = (String) args[0];
        for (long messCount = 0; messCount < 10; messCount++) { 
               Integer key = rnd.nextInt(255); 
               String msg = "This message is for key - " + key; 
               KeyedMessage<Integer, String> data1 = new KeyedMessage<Integer, String>(topic, key, msg);
               producer.send(data1);
        }
    producer.close();
  }
}
```

编译之前的程序。运行之前，请阅读以下信息框。

### 注

在我们运行这个程序之前，我们需要确保我们的集群作为一个多浏览器集群(单个或多个节点)运行。有关如何设置单节点多浏览器集群的更多信息，请参考[第 3 章](3.html "Chapter 3. Setting up the Kafka Cluster")、*设置卡夫卡集群*。

一旦您的多浏览器集群启动，在运行该程序之前，使用以下命令创建一个包含五个分区的主题，并将复制因子设置为`2`:

```scala
[root@localhost kafka-0.8]# bin/kafka-topics.sh --zookeeper localhost:2181 --create --topic kafkatopic --partitions 5 --replication-factor 2
```

现在使用以下命令运行之前的程序:

```scala
[root@localhost kafka-0.8]# java MultiBrokerProducer kafkatopic 
```

为了验证发布给卡夫卡经纪人的数据，可以如下使用卡夫卡控制台消费者:

```scala
[root@localhost kafka-0.8]# bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic kafkatopic --from-beginning
```

# 卡夫卡制作人财产清单

下表列出了可以为卡夫卡制作人配置的几个重要属性。完整列表，请访问[http://kafka.apache.org/08/configuration.html](http://kafka.apache.org/08/configuration.html)。

<colgroup><col style="text-align: left"> <col style="text-align: left"> <col style="text-align: left"></colgroup> 
| 

属性名

 | 

描述

 | 

缺省值

 |
| --- | --- | --- |
| `metadata.broker.list` | 制作者使用这个属性获取元数据(主题、分区和副本)。用于发送实际数据的套接字连接将基于元数据中返回的代理信息来建立。格式为`host1:port1,host2:port2`。 |   |
| `serializer.class` | 这个为消息指定了序列化程序类。默认编码器接受一个字节并返回相同的字节。 | `DefaultEncoder` |
| `producer.type` | 该属性指定消息将如何发送:异步发送的`async`和同步发送的`sync`。 | `sync` |
| `request.required.acks` | 当生产者收到经纪人的确认时，这个值控制*。值`0`表示生产者不会收到经纪人的任何确认。值`1`表示一旦主代理收到数据，生产者就会收到确认。值`-1`表示一旦所有同步副本接收到数据，生产者将收到确认。* | `0` |
| `key.serializer.class` | 此指定键的序列化程序类(默认与消息序列化程序类相同)。 | `${serializer.class}` |
| `partitioner.class` | 这是在子主题之间划分消息的分割器类。默认分区器基于密钥的哈希值。 | `DefaultPartitioner` |

# 总结

在本章中，我们学习了如何编写使用消息分区的基本生产者和一些高级 Java 生产者。

在下一章中，我们将学习如何为消息消费编写基于 Java 的消费者。