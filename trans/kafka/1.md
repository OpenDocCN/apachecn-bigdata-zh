# 第一章。介绍卡夫卡

欢迎来到阿帕奇卡夫卡的世界。

在当今世界，实时信息不断由应用程序(商业、社交或任何其他类型)生成，这些信息需要简单的方法来可靠、快速地路由到多种类型的接收器。大多数情况下，产生信息的应用程序和使用这些信息的应用程序相距甚远，彼此无法访问。这有时会导致信息生产者或消费者的重新开发，从而在他们之间提供一个集成点。因此，需要一种机制来无缝集成生产者和消费者的信息，以避免在任何一端对应用程序进行任何形式的重写。

在当前的大数据时代，第一个挑战是收集大量数据，第二个挑战是分析数据。该分析通常包括以下类型的数据以及更多:

*   用户行为数据
*   应用程序性能跟踪
*   日志形式的活动数据
*   事件消息

消息发布是一种借助消息连接各种应用程序的机制，消息在应用程序之间路由，例如通过像卡夫卡这样的消息代理。Kafka 是任何软件解决方案的实时问题的解决方案，即处理实时量的信息并将其快速路由到多个消费者。卡夫卡提供了生产者和消费者之间信息的无缝集成，而没有阻断信息的生产者，也没有让生产者知道谁是最终的消费者。

Apache Kafka 是一个开源的分布式发布-订阅消息系统，主要设计有以下特点:

*   **持久消息传递**:要从大数据中获得真正的价值，任何形式的信息丢失都是无法承受的。Apache Kafka 采用 **O(1)** 磁盘结构设计，即使存储的消息量非常大(大约为 TB)，也能提供恒定的时间性能。
*   **高吞吐量**:牢记大数据，Kafka 设计用于商品硬件，支持每秒数百万条消息。
*   **分布式** : Apache Kafka 明确支持在 Kafka 服务器上对消息进行分区，并在消费者机器集群上分配消费，同时保持每个分区的排序语义。
*   **多客户端支持** : Apache Kafka 系统支持轻松集成来自不同平台的客户端，如 Java、。NET、PHP、Ruby 和 Python。
*   **实时**:生产者线程产生的消息应该对消费者线程立即可见；该特性对于基于事件的系统至关重要，例如 **复杂事件处理** ( **CEP** )系统。

Kafka 提供了一个实时发布-订阅解决方案，该解决方案克服了实时消费数据使用的挑战，因为数据量可能会以大于真实数据的数量级增长。Kafka 还支持 Hadoop 系统中的并行数据加载。

下图展示了 Apache Kafka 消息传递系统支持的典型大数据聚合和分析场景:

![Introducing Kafka](img/7938OS_01_01.jpg)

在生产端，有不同种类的生产者，例如:

*   生成应用程序日志的前端 web 应用程序
*   生产者代理生成网络分析日志
*   生成转换日志的生产者适配器
*   生成调用跟踪日志的生产者服务

在消费端，有不同的类消费者，比如:

*   消费消息并将消息存储在 Hadoop 或传统数据仓库中进行离线分析的离线消费者
*   消费消息并将消息存储在任何 NoSQL 数据存储区(如 HBase 或 Cassandra)中以进行近实时分析的近实时消费者
*   实时使用者，用于过滤内存数据库中的消息，并触发相关组的警报事件

# 对卡夫卡的需求

拥有任何形式的基于网络的存在和活动的公司都会产生大量数据。数据是这些基于互联网的系统中较新的组成部分之一，通常包括与登录、页面访问、点击、社交网络活动(如点赞、共享和评论)以及运营和系统指标相对应的用户活动事件。由于高吞吐量(每秒数百万条消息)，这些数据通常由日志记录和传统日志聚合解决方案处理。这些传统解决方案是为离线分析系统(如 Hadoop)提供日志数据的可行解决方案。然而，这些解决方案对于构建实时处理系统来说非常有限。

根据互联网应用的新趋势，活动数据已经成为生产数据的一部分，并用于实时运行分析。这些分析可以是:

*   基于相关性的搜索
*   基于受欢迎程度、共现或情感分析的建议
*   向大众投放广告
*   防止垃圾邮件或未经授权的数据抓取的互联网应用安全

由于收集和处理的数据量很大，实时使用从生产系统收集的多组数据已成为一项挑战。

Apache Kafka 旨在通过在 Hadoop 系统中提供并行加载机制以及在机器集群上划分实时消耗的能力来统一离线和在线处理。Kafka 可以与 Scribe 或 Flume 进行比较，因为它对处理活动流数据很有用；但从架构的角度来看，它更接近于传统的消息传递系统，如 ActiveMQ 或 RabitMQ。

# 很少有卡夫卡式的用法

在各自的用例中使用 Apache Kafka 的一些公司如下:

*   **LinkedIn**([www.linkedin.com](http://www.linkedin.com)):ApacheKafka 在 LinkedIn 用于活动数据和运营指标的流式传输。除了 Hadoop 等离线分析系统之外，这些数据还为 LinkedIn 新闻订阅源和 LinkedIn Today 等各种产品提供动力。
*   **DataSift**([www.datasift.com/](http://www.datasift.com/)):在 DataSift，Kafka 被用作监控事件的收集器和实时跟踪用户对数据流的消费。
*   **推特**([www.twitter.com/](http://www.twitter.com/)):推特将卡夫卡作为其风暴的一部分——一个流处理基础设施。
*   **Foursquare**([www.foursquare.com/](http://www.foursquare.com/)):卡夫卡在 four square 提供在线到在线和在线到离线的消息传递。它用于将 Foursquare 监控和生产系统与基于 Foursquare、Hadoop 的离线基础架构相集成。
*   **Square**([www.squareup.com/](http://www.squareup.com/)):Square 使用卡夫卡作为*总线*通过 Square 的各种数据中心移动所有系统事件。这包括度量、日志、自定义事件等。在消费者端，它输出到 Splunk、石墨或类似斯珀的实时警报。

### 注

以上信息来源为[https://cwiki . Apache . org/converge/display/KAFKA/power+By](https://cwiki.apache.org/confluence/display/KAFKA/Powered+By)。

# 总结

在这一章中，我们看到了公司如何发展收集和处理应用程序生成的数据的机制，以及如何通过对这些数据运行分析来利用这些数据的真正力量。

在下一章中，我们将了解安装卡夫卡所需的步骤。