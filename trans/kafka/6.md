# 第六章。给消费者写信

消费者是消费卡夫卡制作者发布的消息并处理从中提取的数据的应用程序。与生产者一样，消费者在本质上也可能不同，例如进行实时或接近实时分析的应用程序、具有 NoSQL 或数据仓库解决方案的应用程序、后端服务、Hadoop 的消费者或其他基于订户的解决方案。这些消费者也可以用不同的语言实现，如 Java、C 和 Python。

在本章中，我们将重点讨论以下主题:

*   面向消息消费者的卡夫卡应用编程接口
*   简单的基于 Java 的卡夫卡消费者
*   使用分区消息的基于 Java 的卡夫卡消费者

在这一章的最后，我们将探讨卡夫卡消费者需要的一些重要属性。那么，让我们开始吧。

![Writing Consumers](graphics/7938OS_06_01.jpg)

在接下来的几节中，我们将讨论卡夫卡为编写基于 Java 的定制消费者提供的 API。

### 注

本书中提到的所有卡夫卡类实际上都是用 Scala 编写的。

# Java 消费者 API

卡夫卡为 Java 消费者提供了两种类型的 API:

*   高级消费者应用编程接口
*   简单的消费者应用编程接口

### 注

高级消费者应用编程接口提供了对消费者应用编程接口的低级实现的抽象，而简单消费者应用编程接口通过允许消费者覆盖其默认的低级实现，为消费者提供了更多的控制。

## 高级消费者 API

当只需要数据而不需要处理消息偏移时，使用高级消费者应用编程接口。因此，大多数底层细节都是在消息消费过程中抽象出来的。高级使用者将从特定分区读取的最后一个偏移量存储在 ZooKeeper 中。该偏移量是根据流程开始时提供给卡夫卡的消费者组名称存储的。

### 注

消息偏移量是消息分区中的一个位置，用来知道消费者在哪里停止消费消息。

在整个 Kafka 集群中，消费者组名称是唯一的和全局的，任何具有正在使用的消费者组名称的新消费者都可能在系统中导致不明确的行为。当一个新的进程以现有的使用者组名称启动时，Kafka 会触发使用者组的新的和现有的进程线程之间的重新平衡。在重新平衡后，一些用于新进程的消息可能会转到旧进程，从而导致意外的结果。为了避免这种模棱两可的行为，在为现有的使用者组名称启动新的使用者之前，应该关闭任何现有的使用者。

以下是使用 Kafka 集群的高级消费者 API 为编写基于 Java 的基本消费者而导入的类:

*   **KafkaStream**: Objects of the `kafka.consumer.KafkaStream` class are returned by the `ConsumerConnector` implementation. This list of the `KafkaStream` objects is returned for each topic, which can further create an iterator shown as follows over messages in the stream:

    ```
    class KafkaStream[K,V]
    ```

    这里，参数`K`和`V`分别指定分区键和消息值的类型。

*   **consumer config**:`kafka.consumer.ConsumerConfig`类封装了与 ZooKeeper 建立连接所需的属性值，如 ZooKeeper URL、组 ID、ZooKeeper 会话超时和 ZooKeeper 接收器时间。
*   **ConsumerConnector**: Kafka provides the `ConsumerConnector` interface (`interface` `ConsumerConnector`) which is further implemented by ZookeeperConsumerConnector class(`kafka.javaapi.consumer.ZookeeperConsumerConnector`). This class is responsible for all the interaction of a consumer with ZooKeeper.

    以下是`ConsumerConnector`类的类图:

    ![High-level consumer API](graphics/7938OS_06_02.jpg)

## 简单消费者 API

高级消费者 API 不提供重启消费者时设置初始偏移量等功能。简单的消费者应用编程接口为卡夫卡消费者提供了对分区消费的低级控制，例如，对同一消息的多次读取或管理事务，等等。

相比于高级消费者 API，开发者需要付出额外的努力来获得消费者内部的这种低级控制，也就是说，消费者需要跟踪偏移量，还需要为主题和分区找出主导代理等等。

简单消费者 API 中使用的主要类是`SimpleConsumer` ( `kafka.javaapi.consumer.SimpleConsumer`)。以下是`SimpleConsumer`班的班图:

![Simple consumer API](graphics/7938OS_06_03.jpg)

一个简单的消费者类提供了一个到主要代理的连接，用于从主题获取消息，并提供了获取主题元数据和偏移量列表的方法。

构建不同请求对象的几个更重要的类是`FetchRequest` ( `kafka.api.FetchRequest`)、`OffsetRequest` ( `kafka.javaapi.OffsetRequest`)、`OffsetFetchRequest` ( `kafka.javaapi.OffsetFetchRequest`)、`OffsetCommitRequest` ( `kafka.javaapi.OffsetCommitRequest`)和`TopicMetadataRequest` ( `kafka.javaapi.TopicMetadataRequest`)。

### 注

本章中的以下示例基于高级消费者应用编程接口。基于简单消费者 API 的示例，参考[https://cwiki . Apache . org/converge/display/KAFKA/0 . 8 . 0+simple consumer+示例](https://cwiki.apache.org/confluence/display/KAFKA/0.8.0+SimpleConsumer+Example)。

# 简单的高级 Java 消费者

现在，我们将开始编写一个简单的单线程 Java 消费者，它是使用高级消费者 API 开发的，用于消费来自一个主题的消息。这个`SimpleHLConsumer`类用于从一个特定的主题中获取一个消息并使用它，假设在这个主题中有一个单独的分区。

## 导入类

作为的第一步，我们需要导入以下类:

```
import kafka.consumer.ConsumerConfig;
import kafka.consumer.KafkaStream;
import kafka.javaapi.consumer.ConsumerConnector;
```

## 定义属性

作为下一步，我们需要定义与 ZooKeeper 建立连接的属性，并使用以下代码将这些属性传递给 Kafka 消费者:

```
Properties props = new Properties();
props.put("zookeeper.connect", "localhost:2181");
props.put("group.id", "testgroup");
props.put("zookeeper.session.timeout.ms", "500");
props.put("zookeeper.sync.time.ms", "250");
props.put("auto.commit.interval.ms", "1000");
new ConsumerConfig(props);
```

现在，让我们看看代码中提到的主要属性:

*   `zookeeper.connect`:这个属性指定了动物园管理员`<node:port>`的连接细节
*   `group.id`:该属性指定了由组内所有消费者共享的消费者组的名称
*   `zookeeper.session.timeout.ms`:该属性以毫秒为单位指定 ZooKeeper 会话超时
*   `zookeeper.sync.time.ms`:该属性指定了 ZooKeeper 与 ZooKeeper leader 的同步时间，单位为毫秒
*   `auto.commit.interval.ms` :这个属性定义了提交给 ZooKeeper 的使用者偏移量的频率(以毫秒为单位)

## 阅读某个主题的信息并打印出来

作为最后一步，我们需要使用以下代码读取消息:

```
Map<String, Integer> topicCount = new HashMap<String, Integer>();
topicCount.put(topic, new Integer(1));

Map<String, List<KafkaStream<byte[], byte[]>>> consumerStreams = consumer.createMessageStreams(topicCount);

List<KafkaStream<byte[], byte[]>> streams = consumerStreams.get(topic);

for (final KafkaStream stream : streams) {
ConsumerIterator<byte[], byte[]> consumerIte = stream.iterator();
  while (consumerIte.hasNext())
    System.out.println("Message from Single Topic :: "
    + new String(consumerIte.next().message()));
} 
```

因此，完整的程序看起来像下面的代码:

```
package test.kafka.consumer;

import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.Properties;

import kafka.consumer.Consumer;
import kafka.consumer.ConsumerConfig;
import kafka.consumer.ConsumerIterator;
import kafka.consumer.KafkaStream;
import kafka.javaapi.consumer.ConsumerConnector;

public class SimpleHLConsumer {

  private final ConsumerConnector consumer;
  private final String topic;

public SimpleHLConsumer(String zookeeper, String groupId, String topic) {

    Properties props = new Properties();
    props.put("zookeeper.connect", zookeeper);
    props.put("group.id", groupId);
    props.put("zookeeper.session.timeout.ms", "500");
    props.put("zookeeper.sync.time.ms", "250");
    props.put("auto.commit.interval.ms", "1000");

    consumer = Consumer.createJavaConsumerConnector(
    new ConsumerConfig(props));
    this.topic = topic;
  }

  public void testConsumer() {

    Map<String, Integer> topicCount = new HashMap<String, Integer>();
        // Define single thread for topic
    topicCount.put(topic, new Integer(1));

Map<String, List<KafkaStream<byte[], byte[]>>> consumerStreams = consumer.createMessageStreams(topicCount);

List<KafkaStream<byte[], byte[]>> streams = consumerStreams.get(topic);

    for (final KafkaStream stream : streams) {
      ConsumerIterator<byte[], byte[]> consumerIte = stream.iterator();
      while (consumerIte.hasNext())
      System.out.println("Message from Single Topic :: " + 
      new String(consumerIte.next().message()));
    }
    if (consumer != null)
      consumer.shutdown();
  }

  public static void main(String[] args) {

    String topic = args[0];
SimpleHLConsumer simpleHLConsumer = new SimpleHLConsumer("localhost:2181", "testgroup", topic);
    simpleHLConsumer.testConsumer();
  }
}
```

编译之前的程序，使用以下命令运行:

```
[root@localhost kafka-0.8]# java SimpleHLConsumer kafkatopic 

```

在这里，`kafkatopic`是卡夫卡的生产者放置消费信息的主题。

# 多部分主题的多线程消费者

前面的示例是一个非常基本的示例，其中一个消费者使用来自单个代理的消息，而主题中没有显式的消息分区。让我们跳到下一个层次，编写另一个程序，它消耗来自连接到单个/多个主题的多个分区的消息。

基于多线程高级消费者 -API 的设计通常基于主题中的分区数量，并遵循主题中线程和分区之间的一对一映射方法。例如，如果为任何主题定义了四个分区，作为最佳实践，只有四个线程应该由消费者应用程序启动来读取数据；否则，可能会出现一些冲突行为，例如线程从不接收消息或线程从多个分区接收消息。此外，接收多条消息并不能保证消息会按顺序排列。例如，一个线程可能从第一分区接收两个消息，从第二分区接收三个消息，然后从第一分区再接收三个消息，接着从第一分区再接收一些消息，即使第二分区有数据可用。

让我们走得更远。

## 导入类

这一步保持与前一程序相同。

## 定义属性

该步骤对于该程序也保持不变。

## 从线程读取消息并打印

本节与上一节的唯一区别是，我们首先创建一个线程池，并获取线程池中与每个线程相关联的卡夫卡流，如以下代码所示:

```
Map<String, Integer> topicCount = new HashMap<String, Integer>();
    topicCount.put(topic, new Integer(threadCount));

Map<String, List<KafkaStream<byte[], byte[]>>> consumerStreams = consumer.createMessageStreams(topicCount);

List<KafkaStream<byte[], byte[]>> streams = consumerStreams.get(topic);

// Launching the thread pool
executor = Executors.newFixedThreadPool(threadCount);
```

基于卡夫卡高级消费程序接口的多线程卡夫卡消费程序完整的程序列表如下:

```
package test.kafka.consumer;

import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.Properties;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;

import kafka.consumer.Consumer;
import kafka.consumer.ConsumerConfig;
import kafka.consumer.ConsumerIterator;
import kafka.consumer.KafkaStream;
import kafka.javaapi.consumer.ConsumerConnector;

public class MultiThreadHLConsumer {

  private ExecutorService executor;
  private final ConsumerConnector consumer;
  private final String topic;

  public MultiThreadHLConsumer(String zookeeper, String groupId, String topic) {

    Properties props = new Properties();
    props.put("zookeeper.connect", zookeeper);
    props.put("group.id", groupId);
    props.put("zookeeper.session.timeout.ms", "500");
    props.put("zookeeper.sync.time.ms", "250");
    props.put("auto.commit.interval.ms", "1000");

    consumer = Consumer.createJavaConsumerConnector(newConsumerConfig(props));
    this.topic = topic;
  }

  public void testConsumer(int threadCount) {

    Map<String, Integer> topicCount = new HashMap<String, Integer>();

    // Define thread count for each topic
    topicCount.put(topic, new Integer(threadCount));

    // Here we have used a single topic but we can also add 
    // multiple topics to topicCount MAP 
    Map<String, List<KafkaStream<byte[], byte[]>>> consumerStreams = consumer.createMessageStreams(topicCount);

    List<KafkaStream<byte[], byte[]>> streams = consumerStreams.get(topic);

    // Launching the thread pool
    executor = Executors.newFixedThreadPool(threadCount);

    //Creating an object messages consumption
    int threadNumber = 0;
    for (final KafkaStream stream : streams) {
      ConsumerIterator<byte[], byte[]> consumerIte = stream.iterator();
      threadNumber++;

      while (consumerIte.hasNext())
    System.out.println("Message from thread :: " + threadNumber + " -- " + new String(consumerIte.next().message()));
    }
    if (consumer != null)
      consumer.shutdown();
    if (executor != null)
      executor.shutdown();
  }

  public static void main(String[] args) {

    String topic = args[0];
    int threadCount = Integer.parseInt(args[1]);
    MultiThreadHLConsumer simpleHLConsumer = new MultiThreadHLConsumer("localhost:2181", "testgroup", topic);
    simpleHLConsumer.testConsumer(threadCount);
  }
}
```

编译前一个程序，运行前阅读以下信息框。

### 注

在我们运行这个程序之前，我们需要确保我们的集群作为一个多浏览器集群运行(包括单个或多个节点)。有关如何设置单节点多代理集群的更多信息，请参考[第 3 章](3.html "Chapter 3. Setting up the Kafka Cluster")、*设置卡夫卡集群*。

一旦您的多浏览器集群启动，在运行该程序之前，使用以下命令创建一个包含四个分区的主题，并将复制因子设置为`2`:

```
[root@localhost kafka-0.8]# bin/kafka-topics.sh --zookeeper localhost:2181 --create --topic kafkatopic --partitions 4 --replication-factor 2

```

现在使用以下命令运行上一个程序:

```
[root@localhost kafka-0.8]# java MultiThreadHLConsumer kafkatopic 4

```

这个程序将打印与每个线程相关的所有消息分区。

# 卡夫卡消费财产清单

以下是可以为基于高级消费者 API 的 Kafka 消费者配置的几个重要属性的列表。完整列表请访问[http://kafka.apache.org/08/configuration.html](http://kafka.apache.org/08/configuration.html)。

<colgroup><col style="text-align: left"> <col style="text-align: left"> <col style="text-align: left"></colgroup> 
| 

属性名

 | 

描述

 | 

缺省值

 |
| --- | --- | --- |
| `group.id` | 该属性为同一消费群内的一组消费者定义了唯一的身份。 |   |
| `zookeeper.connect` | 该属性指定了 ZooKeeper 连接字符串`< hostname:port/chroot>`。Kafka 使用 ZooKeeper 来存储消费组为特定主题和分区消费的消息的偏移量。 |   |
| `client.id` | `Client.id`值由卡夫卡消费者客户端指定，用于区分不同的客户端。 | `${group.id}` |
| `zookeeper.session.timeout.ms` | 这个属性定义了 Kafka 在关闭会话之前等待 ZooKeeper 响应任何读/写请求的时间(以毫秒为单位)。 | `6000` |
| `zookeeper.connection.timeout.ms` | 该值定义了客户端与 ZooKeeper 建立连接的最大等待时间(毫秒)。 | `6000` |
| `zookeeper.sync.time.ms`  | 这个属性定义了 ZooKeeper 与 ZooKeeper leader 同步所需的时间(以毫秒为单位)。 | `2000` |
| `auto.commit.interval.ms` | 这个属性定义了被消耗的偏移量提交给 ZooKeeper 的频率(以毫秒为单位)。 | `60 * 1000` |

# 总结

在这一章中，我们学习了如何编写基本的使用者，并了解了使用来自分区的消息的一些高级 Java 使用者。

在下一章中，我们将学习如何将 Kafka 与 Storm 和 Hadoop 集成。