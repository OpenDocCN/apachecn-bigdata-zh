# 第八章。卡夫卡工具

在这最后一章中，我们将探索卡夫卡中可用的工具及其与第三方工具的集成。我们还将简要讨论在卡夫卡的表演测试领域所做的工作。

本章的主要重点领域是:

*   卡夫卡管理工具
*   与其他工具的集成
*   卡夫卡性能测试

# 卡夫卡管理工具

卡夫卡 0.8 提供了许多工具或实用程序来管理复制和主题创建等功能。让我们快速了解一下这些工具。

## 卡夫卡话题工具

默认情况下，卡夫卡用默认的分区数和复制因子(两者的默认值都是`1`)创建主题。但是在现实场景中，我们可能需要不止一次地定义分区数量和复制因子。

以下是使用特定参数创建主题的命令:

```
[root@localhost kafka-0.8]# bin/kafka-create-topic.sh --zookeeper localhost:2181 --replica 3 --partition 2 --topic kafkatopic

```

Kafka 还提供了在 Kafka 服务器中查找主题列表的实用程序。通过查询 ZooKeeper，列表主题工具提供了关于它们的分区、副本或领导者的主题和信息的列表。

以下是获取主题列表的命令:

```
[root@localhost kafka-0.8]#bin/kafka-list-topic.sh --zookeeper localhost:2181

```

在执行上述命令时，您应该会得到如下截图所示的输出:

![Kafka topic tools](graphics/7938OS_08_01.jpg)

上面的控制台输出显示，我们可以获得关于主题和已复制数据的分区的信息。上一张截图的输出可以解释如下:

*   `leader`是为分区的特定部分随机选择的节点，负责该分区的所有读和写
*   `replicas`表示保存指定分区日志的节点列表
*   `isr`表示当前活动且与领导者同步的同步副本列表的子集

注意`kafkatopic`有两个分区(分区`0`和`1`)三个副本，而`othertopic`只有一个分区两个副本。

## 卡夫卡复制工具

为了更好地管理复制功能，卡夫卡提供了选择复制线索和控制经纪人关闭的工具。

正如我们从 Kafka 设计中学到的，在复制中，多个分区可以有复制的数据，在这些多个副本中，一个副本充当主导副本，其余副本充当主导副本的同步追随者。在潜在客户副本不可用的情况下，可能由于代理关闭，需要选择新的潜在客户副本。

对于场景，例如为了维护活动而关闭 Kafka 代理，新领导者的选举是按顺序进行的，这导致了 ZooKeeper 的大量读/写操作。在任何具有许多主题/分区的大型集群中，潜在副本的顺序选择会导致可用性延迟。

为了确保高可用性，卡夫卡为卡夫卡经纪人的受控关闭提供了工具。如果代理关闭了引导分区，此工具会主动将引导转移到另一个代理上的其他同步副本。如果没有同步副本可用，该工具将无法关闭代理，以确保没有数据丢失。

以下是使用此工具的格式:

```
[root@localhost kafka-0.8]# bin/kafka-run-class.sh kafka.admin.ShutdownBroker --zookeeper <zookeeper_host:port/namespace> --broker <brokerID>

```

需要关闭的动物园管理员主机和经纪人 ID 是强制参数。我们还可以使用受控关机工具指定重试次数(`--num.retries`，默认值`0`)和重试间隔(以毫秒为单位)(`--retry.interval.ms`，默认值`1000`)。

接下来，在任何有许多代理和主题的大型 Kafka 集群中，Kafka 确保分区的主要副本在代理之间平均分布。但是，在关闭(也受控制)或代理失败的情况下，这种销售线索副本的平均分布可能会在集群内不平衡。

Kafka 提供了一个工具，用于维护 Kafka 集群内潜在客户副本在可用经纪人之间的平衡分布。

以下是使用此工具的格式:

```
[root@localhost kafka-0.8]# bin/kafka-preferred-replica-election.sh --zookeeper <zookeeper_host:port/namespace>

```

这个工具从 ZooKeeper 中检索集群的所有主题分区。我们还可以以 JSON 文件格式提供主题分区列表。它异步地更新 ZooKeeper 路径来移动分区的头，并创建一个平衡的分布。

### 注

关于 Kafka 工具及其用法的详细说明，请参考[https://cwiki . Apache . org/converge/display/Kafka/Replication+tools](https://cwiki.apache.org/confluence/display/KAFKA/Replication+tools)。

# 与其他工具的集成

本节讨论了许多贡献者的贡献，为各种需求(如日志记录、打包、云集成和 Hadoop 集成)提供了与 Apache Kafka 的集成。

加缪([https://github.com/linkedin/camus](https://github.com/linkedin/camus))是 LinkedIn 完成的另一件艺术品，它提供了一条从卡夫卡到 HDFS 的管道。在这个项目中，单个 MapReduce 作业执行以下步骤，以分布式方式将数据加载到 HDFS:

1.  作为第一步，它从 ZooKeeper 中发现了最新的主题和分区偏移量。
2.  MapReduce 作业中的每个任务从 Kafka 代理获取事件，并将提取的数据和审计计数一起提交到输出文件夹。
3.  作业完成后，最终偏移将被写入 HDFS，随后的 MapReduce 作业可以进一步使用这些偏移。
4.  在卡夫卡集群中也更新关于所消费的消息的信息。

其他一些有用的贡献包括:

*   在亚马逊上自动部署和配置卡夫卡和动物园管理员([https://github.com/nathanmarz/kafka-deploy](https://github.com/nathanmarz/kafka-deploy))
*   测井工具([https://github.com/leandrosilva/klogd2](https://github.com/leandrosilva/klogd2)
*   Mozilla matrix([https://github.com/mozilla-metrics/bagheera](https://github.com/mozilla-metrics/bagheera))的 REST 服务
*   阿帕奇骆驼-卡夫卡一体化([https://github.com/BreizhBeans/camel-kafka/wiki](https://github.com/BreizhBeans/camel-kafka/wiki))

### 注

有关卡夫卡生态系统工具的详细列表，请参考[https://cwiki.apache.org/confluence/display/KAFKA/Ecosystem](https://cwiki.apache.org/confluence/display/KAFKA/Ecosystem)。

# 卡夫卡性能测试

Kafka 的贡献者仍在进行性能测试，而他们的目标是产生一些脚本文件来帮助运行性能测试。其中一些在卡夫卡`bin`文件夹中提供:

*   `Kafka-producer-perf-test.sh`:该脚本将运行`kafka.perf.ProducerPerformance`类，为生产者将增加的统计数据生成 CSV 文件
*   `Kafka-consumer-perf-test.sh`:这个脚本将运行`kafka.perf.ConsumerPerformance`类，为消费者生成一个 CSV 文件

CSV 格式提供了更多的拉卡夫卡服务器和动物园管理员统计数据的脚本。生成 CSV 文件后，可以创建 R 脚本来生成图形图像。

### 注

关于如何进行 Kafka 性能测试的详细信息，请参考[https://cwiki . Apache . org/converge/display/Kafka/Performance+testing](https://cwiki.apache.org/confluence/display/KAFKA/Performance+testing)。

# 总结

在这一章中，我们添加了一些关于 Kafka 的更多信息，比如它的管理员工具、它的集成以及 Kafka 非 Java 客户端。

在这个穿越阿帕奇卡夫卡的完整旅程中，我们接触到了许多关于卡夫卡的重要事实。我们已经了解了开发 Kafka 的原因、它的安装以及它对不同类型集群的支持。我们也探索了卡夫卡的设计手法，写了很少的基本生产者和消费者。

最后，我们讨论了它与 Hadoop 和 Storm 等技术的集成。

进化的旅程永远不会结束。