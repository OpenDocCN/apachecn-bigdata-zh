# 第二章。开始使用您的第一个拓扑

本章专门指导您完成为执行 Storm 拓扑设置环境的步骤。其目的是准备用户沙箱，引导您执行一些示例代码并理解各种组件的工作。所有概念都将附带代码片段和“自己尝试”部分，以便您能够以实用的方式理解组件，并准备好探索和利用这一奇妙技术的力量。

本章将涉及的主题如下:

*   风暴拓扑和组件
*   执行示例风暴拓扑
*   以分布式模式执行拓扑

到本章结束时，您将能够理解拓扑中的组件和数据流，理解简单的字数统计拓扑，并在本地和分布式模式下执行它。您还将能够调整初始项目拓扑，以添加您自己的风格。

# 设置风暴的先决条件

这里列出了执行设置和执行步骤的先决条件:

*   对于本地模式设置，您需要 Maven、Git、Eclipse 和 Java
*   对于分布式设置，您需要以下内容:
    *   Linux 或 Ubuntu 安装程序或分布式安装程序可以在其 Windows 系统上利用 PowerShell 或 Cygwin
    *   让多个系统或虚拟机使用 VMware player 会有所帮助

您可以参考以下链接，并按照设定的流程来设置设置 Storm 所需的各种开源组件，并部署本书这一部分中解释的组件:

*   对于爪哇、[https://java.com/en/download/index.jsp](https://java.com/en/download/index.jsp)
*   对于日食，[https://www.eclipse.org/downloads/](https://www.eclipse.org/downloads/)
*   对于 Cygwin，[http://cygwin.com/install.html](http://cygwin.com/install.html)
*   对于 Git，[https://help.github.com/articles/set-up-git](https://help.github.com/articles/set-up-git)

# 风暴拓扑的组成部分

风暴拓扑由两个基本组件组成:喷口和一个或多个螺栓。这些构建块使用流绑定在一起；正是在这些流上，无穷无尽的元组数组流动。

让我们用一个简单的类比来讨论拓扑结构，如图所示，并在此后进行解释:

![Components of a Storm topology](../images/00010.jpeg)

在我们的示例拓扑中，我们有一个大的烤薯片处理单元，其中输入的*生马铃薯*被喷口消耗，还有各种螺栓，如去皮螺栓、切片螺栓和烤螺栓，它们执行顾名思义的任务。有各种装配线或工人将芯片从削皮器单元移动到粉碎机和更远的地方；在我们的例子中，我们有溪流来连接和连接喷口和螺栓。现在削皮器和粉碎机之间交换的基本单位是去皮的土豆，粉碎机和烘烤单元之间交换的基本单位是切片的土豆。这类似于元组，即喷口和螺栓之间的信息交换数据。

让我们仔细看看风暴拓扑的构建模块。

### 注

Storm 内数据交换的基本单位称为*元组*；这有时也被称为“T4”事件。

## 喷口

喷口是拓扑的收集漏斗；它将事件或元组馈送到拓扑中。它可以被视为风暴处理单元(拓扑)的输入源。

喷口从诸如队列、文件、端口等外部来源读取消息。此外，喷口将它们排放到溪流中，溪流又将它们传送到螺栓处。风暴喷口的任务是通过**有向无环图** ( **DAG** )在整个处理过程中跟踪每个事件或元组。然后，风暴框架根据拓扑中元组的执行结果发送并生成确认或失败通知。该机制为 Storm 提供了有保证的处理功能。根据所需的功能，喷口可以编程或配置为可靠或不可靠。可靠的喷口将失败的事件回放到拓扑中。

下图以图形方式描述了相同的流程:

![Spouts](../images/00011.jpeg)

所有风暴喷口都被实现为能够在一个或多个流螺栓上发出元组。如上图所示，喷口可以向螺栓 **A** 和 **C** 发射元组。

每个喷口应实现 **IRichSpout** 界面。以下是对了解壶嘴上下文的重要方法:

*   `nextTuple()`:这是持续轮询外部源新事件的方法；例如，前面例子中的队列。在每次轮询中，如果该方法找到一个事件，它就会通过流发送到拓扑，如果没有新的事件，该方法就会返回。
*   `ack()`:当喷口发出的元组已经被拓扑成功处理时，调用这个方法。
*   `fail()`:当发出的元组在指定的超时内没有成功处理喷口时，调用这个方法。在这种情况下，对于可靠的喷动，喷动使用`messageIds`事件跟踪和追踪每个元组，然后这些事件被重新发送到拓扑进行重新处理。例如，在上图中，再次发出失败的元组。

对于不可靠的喷动，不使用`messageIds`跟踪元组，并且`ack()`和`fail()`等方法不保存任何值，因为喷动不跟踪元组以成功处理。这些拓扑被认为是不可靠的。

### 注

IRichSpout 是 Storm 提供的一个接口，它提供了拓扑喷口要实现的契约或方法的细节。

## 螺栓

螺栓是拓扑的处理单元。它们是拓扑的组件，执行以下一项或多项任务:

*   从语法上分析
*   转换
*   聚合
*   连接
*   数据库交互

由拓扑执行的整个过程通常被分成较小的任务和子任务，每个任务和子任务最好由不同的螺栓执行，以利用 Storm 的并行分布式处理的能力。

让我们来看下图，该图捕获了一个实时用例，其中来自各种飞机的位置坐标被跟踪和处理，以确定它们是否在正确的轨迹上移动:

![Bolts](../images/00012.jpeg)

在这里，飞行位置坐标由飞机上的传感器发送，在日志服务器上进行整理，并输入风暴拓扑。风暴拓扑分解为以下螺栓，这些螺栓可以作用于喷口发出的元组:

*   **解析事件螺栓**:这个螺栓过滤并转换喷口发出的事件。它将信息转换成可解读的格式。
*   **位置螺栓**:这个是从解析螺栓接收的元组中提取位置坐标，然后将其发送到下一个螺栓的螺栓。
*   **验证螺栓**:这个是将定位螺栓发送的位置坐标与预先定义的平面轨迹进行验证的螺栓，如果检测到偏差，则向报警螺栓发送元组。
*   **警报螺栓**:这个螺栓是通知外部系统的行动者，比如我们这里的空气控制器，关于在飞行路径中检测到的异常或偏差。

由于实时用例的性质，例如上图中描述的，计算的速度和准确性是最重要的，这就是为什么 Storm 成为实现这种解决方案的强有力的技术选择。

整个处理逻辑被分解成更小的任务，以螺栓的形式执行；在螺栓中配置任务和平行度可以让工程师为解决方案获得合适的性能。

一个螺栓可以监听多个流，它可以向不同流上的多个其他螺栓发出信号。如图中*芽*部分所示:

*   螺栓-A 向螺栓-B 和螺栓-C 发射
*   螺栓-D 订阅来自螺栓-C 和螺栓-B 的流

Storm 提供的由自定义螺栓实现的常用接口如下:

*   IRichBolt
*   IBasicBolt

这两个接口的区别取决于是否需要可靠的消息传递和事务支持。

螺栓使用的主要方法如下:

*   `prepare()`:这个是螺栓初始化时调用的方法。从根本上说，风暴拓扑永远运行，螺栓一旦初始化，直到拓扑被杀死才会终止。这种方法通常用于初始化连接和读取其他静态信息，这在螺栓的整个生命周期中都是必需的。
*   `execute()`:这个是执行螺栓上定义的功能和处理逻辑的方法。它对每个元组执行。

## 溪流

流可以被定义为本质上无界的元组或事件序列。这些流通常以并行方式创建，并在整个拓扑中分布。流可以称为喷口和螺栓之间的连线或信息流通道。这些是未加工、半加工和加工信息的载体，这些信息往返于各种执行任务的部件，如螺栓和喷口。在对拓扑结构进行编码时，使用给流的元组中的字段命名的模式来配置流。

## 元组——风暴中的数据模型

元组是风暴中的基本和组成数据结构。这是一个命名的价值列表，从壶嘴开始它的旅程。然后，它从流中散发到螺栓，然后从螺栓散发到其他螺栓，在那里执行不同的处理阶段。根据拓扑定义，在成功完成所有预期的处理后，元组被打包回出口。

# 执行示例风暴拓扑–本地模式

在开始本节之前，假设您已经完成了先决条件并安装了预期的组件。

## 风暴启动器项目中的字数统计拓扑

为了理解上一节中描述的组件，让我们下载 Storm-starter 项目并执行一个示例拓扑:

1.  可以使用以下 Git 命令下载 Storm-starter 项目:

    ```scala
    Linux-command-Prompt $ sudo git clone git://github.com/apache/incubator-storm.git && cd incubator-storm/examples/storm-starter

    ```

2.  Next, you need to import the project into your Eclipse workspace:
    1.  启动 Eclipse。
    2.  点击**文件**菜单，选择**导入**向导。
    3.  From the **Import** wizard, select **Existing Maven Projects**.

        ![WordCount topology from the Storm-starter project](../images/00013.jpeg)

    4.  在风暴启动项目中选择 **pom.xml** ，并将其指定为`<download-folder>/starter/incubator-storm/examples/storm-starter`。
    5.  Once the project has been successfully imported, the Eclipse folder structure will look like the following screenshot:

        ![WordCount topology from the Storm-starter project](../images/00014.jpeg)

    6.  使用 run 命令执行拓扑，您应该能够看到如下截图所示的输出:

    ![WordCount topology from the Storm-starter project](../images/00015.jpeg)

为了理解拓扑的功能，让我们看一下代码，了解拓扑中每个组件的流程和功能:

```scala
// instantiates the new builder object
TopologyBuilder builder = new TopologyBuilder();
// Adds a new spout of type "RandomSentenceSpout" with a  parallelism hint of 5
builder.setSpout("spout", new RandomSentenceSpout(), 5);
```

从主函数开始，在`WordCountTopology.java`类中，我们找到了名为`builder`的`TopologyBuilder`对象；理解这一点很重要，因为这个类为我们提供了定义拓扑的模板。这个类公开了应用编程接口来配置和连接各种各样的管道和螺栓到一个拓扑中——这个拓扑本质上是一个简单的结构。

在前面的代码片段中，我们创建了一个`TopologyBuilder`对象，并使用模板执行以下操作:

*   `setSpout –RandomSentenceSpout`:这会生成随机的句子。请注意，我们使用的是一个名为 parallelism 提示的属性，这里设置为`5`。这是一个属性，用于标识在提交拓扑时将产生多少个此组件的实例。在我们的示例中，我们将有五个喷口实例。
*   `setBolt`:我们用这个方法给拓扑加两个螺栓:`SplitSentenceBolt`，把句子拆分成单词，`WordCountBolt`，统计单词。
*   前面代码片段中其他值得注意的项是`suffleGrouping`和`fieldsGrouping`；我们将在下一章详细讨论这些问题；现在，请理解这些是控制元组到拓扑中各种螺栓的路由的组件。

# 在分布式模式下执行拓扑

要在分布式模式下设置Storm，我们需要执行以下步骤。

## 为风暴设置动物园管理员(V 3.3.5)

风暴拓扑的协调由动物园管理员集群维护。动物园管理员的利用率不是很高，因为它只是维持风暴集群的可运行状态。在大多数情况下，单个 Zookeeper 节点就足够了，但是在生产场景中，建议至少使用三节点 Zookeeper 集群，这样单个节点就不会成为单点故障。

为了获得可靠的动物园管理员服务，将动物园管理员部署在一个名为“T2”的集群中。只要大部分合奏团都起来了，服务就可以了。系综中的一个节点被自动选择为领导者，其他节点被选择为追随者。如果领导者倒下，其中一个从动节点将成为领导者。

在将成为动物园管理员集合一部分的所有机器上执行以下步骤，以设置动物园管理员集群:

1.  从 Apache 动物园管理员网站下载最新的稳定版本(3.3.5 版)。
2.  在`/usr/local` :

    ```scala
    sudo mkdir /usr/local/zookeeper

    ```

    下创建`zookeeper`目录
3.  将下载的 TAR 文件解压到`/usr/local`位置。使用以下命令:

    ```scala
    sudo tar -xvf zookeeper-3.3.5.tar.gz -C /usr/local/zookeeper

    ```

4.  Zookeeper 需要一个目录来存储它的数据。创建`/usr/local/zookeeper/tmp`来存储该数据:

    ```scala
    sudo mkdir –p /usr/local/zookeeper/tmp

    ```

5.  在`/usr/local/zookeeper/zookeeper-3.3.5/conf`下创建一个配置文件`zoo.cfg`。将包含以下属性:
    *   `tickTime`:这个是每个刻度的毫秒数(例如 2000)。
    *   `initLimit`:这个是初始同步阶段可以取的刻度数(例如 5)。
    *   `syncLimit`:这是从发送请求到得到确认之间可以经过的节拍数(例如 2)。
    *   `dataDir`:这个就是存储快照的目录(例如`/usr/local/zookeeper/tmp`)。
    *   `clientPort`:这个是 Zookeeper 客户端将连接到端口的端口(例如，2182)。
    *   `server.id=host:port:port`:作为动物园管理员集合一部分的每一台机器都应该知道集合中的每一台机器。这是通过`server.id=host:port:port`形式的一系列线条完成的(例如`server.1:<IP_ADDRESS_OF_ZOOKEEPER_NODE_1>:2888:3888`)。
6.  重复上述步骤或将分发复制到将成为动物园管理员集群一部分的其他机器上。
7.  在`datadir`属性指定的目录中创建一个名为`myid`的文件。`myid`文件由一行组成，仅包含该机器的标识文本(1 在服务器中，1 在`zoo.cfg`)。因此，服务器 1 的`myid`将包含文本`1`而不包含其他内容。该标识在集合中必须是唯一的，并且应该具有 1 到 255 之间的值。本例中`myid`文件的路径是`vi /usr/local/zookeeper/tmp/myid`。
8.  Edit the `~/.bashrc` file and add an environment variable for the Zookeeper home and add its bin directory to the `PATH` environment variable:

    ![Set up Zookeeper (V 3.3.5) for Storm](../images/00016.jpeg)

9.  来源`~/`。`bashrc`文件修改后。需要此步骤来确保对`bashrc`所做的更改应用于当前终端会话:

    ```scala
    source ~/.bashrc

    ```

10.  通过从`$ZOOKEEPER_HOME` :

    ```scala
    sudo –E bin/zkServer.sh start

    ```

    执行以下命令，在每个节点上启动动物园管理员守护程序
11.  通过从`$ZOOKEEPER_HOME`执行以下命令来停止每个节点上的 Zookeeper 守护程序:

    ```scala
    sudo –E bin/zkServer.sh stop

    ```

12.  动物园管理员状态可以通过从`$ZOOKEEPER_HOME`运行以下命令来检查:

    ```scala
    sudo –E bin/zkServer.sh status

    ```

不同模式的输出如下:

*   If running in the standalone mode (only a single machine is part of the Zookeeper ensemble cluster), the following output will be seen on the console:

    ![Set up Zookeeper (V 3.3.5) for Storm](../images/00017.jpeg)

*   If running in the clustered mode, the following output is seen on the leader node:

    ![Set up Zookeeper (V 3.3.5) for Storm](../images/00018.jpeg)

*   If running in the clustered mode, the following output is seen on the follower node:

    ![Set up Zookeeper (V 3.3.5) for Storm](../images/00019.jpeg)

默认情况下，Zookeeper 日志(`zookeeper.out`)在其实例开始的相同位置创建。这就完成了动物园管理员集群设置。

## 在分布式模式下设置风暴

执行以下步骤以分布式模式设置 Storm:

1.  从 GitHub 风暴网站下载`Storm-0.9.2-incubating.zip`包。
2.  在`/usr/local` :

    ```scala
    sudo mkdir –p /usr/local/storm/tmp

    ```

    下创建目录`storm`和`storm/tmp`
3.  为日志创建以下目录:

    ```scala
    sudo mkdir –p /mnt/abc_logs/storm/storm_logs

    ```

4.  从`/usr/local` :

    ```scala
    sudo unzip -d /usr/local/storm/ storm-0.9.2 -incubating.zip

    ```

    的目录中提取光轮和工人机器上的 ZIP 文件
5.  在`/usr/local/storm/storm-0.9.2-incubating/conf/storm.yaml`进行以下更改:
    *   `storm.zookeeper.servers`:这是风暴集群的动物园管理员集群中的主机列表:

        ```scala
        storm.zookeeper.servers:
         "<IP_ADDRESS_OF_ZOOKEEPER_ENSEMBLE_NODE_1>"
         "<IP_ADDRESS_OF_ZOOKEEPER_ENSEMBLE_NODE_2>"
        ```

    *   `storm.zookeeper.port`:这是 Zookeeper 集群运行的端口:

        ```scala
        storm.zookeeper.port: 2182
        ```

    *   `storm.local.dir`:Nimbus 和 supervisor 需要在本地磁盘上有一个位置来存储少量与拓扑的配置和执行细节相关的数据。请确保在所有风暴节点上创建目录并分配读/写权限。对于我们的安装，我们将在`/usr/local/storm/tmp`位置创建这个目录:

        ```scala
        storm.local.dir: "/usr/local/storm/tmp"
        ```

    *   `nimbus.host`:节点需要知道哪台机器是主机，才能下载拓扑 jar 和 confs。该属性用于此目的:

        ```scala
        nimbus.host: "<IP_ADDRESS_OF_NIMBUS_HOST>"
        ```

    *   `java.library.path`:这是 Storm 使用的本机库(ZeroMQ 和 JZMQ)的加载路径。对于大多数安装来说`/usr/local/lib:/opt/local/lib:/usr/lib`的默认值应该没问题，所以在继续之前，请验证前面提到的位置中的库。
    *   `storm.messaging.netty` : Storm 基于 Netty 的传输已经进行了全面改造，通过更好地利用线程、CPU 和网络资源来显著提高性能，尤其是在消息大小较小的情况下。为了提供 Netty 支持，需要添加以下配置:

        ```scala
        storm.messaging.transport:"backtype.storm.messaging.netty.Context"
                   storm.messaging.netty.server_worker_threads:1
                   storm.messaging.netty.client_worker_threads:1
                   storm.messaging.netty.buffer_size:5242880
                   storm.messaging.netty.max_retries:100
                   storm.messaging.netty.max_wait_ms:1000
                   storm.messaging.netty.min_wait_ms:100
        ```

    *   风暴集群安装的`storm.yaml`片段如下:

        ```scala
        #To be filled in for a storm configuration
        storm.zookeeper.servers:
             - "nim-zkp-flm-3.abc.net"
        storm.zookeeper.port: 2182
        storm.local.dir: "/usr/local/storm/tmp"
        nimbus.host: "nim-zkp-flm-3.abc.net"
        topology.message.timeout.secs: 60
        topology.debug: false
        topology.optimize: true
        topology.ackers: 4

        storm.messaging.transport: "backtype.storm.messaging.netty.Context"
        storm.messaging.netty.server_worker_threads: 1
        storm.messaging.netty.client_worker_threads: 1
        storm.messaging.netty.buffer_size: 5242880
        storm.messaging.netty.max_retries: 100
        storm.messaging.netty.max_wait_ms: 1000
        storm.messaging.netty.min_wait_ms: 100
        ```

6.  在`~/.bashrc`文件中设置`STORM_HOME`环境，并在`PATH`环境变量中添加暴风的`bin`目录。这是为了从任何位置执行 Storm 二进制文件而添加的。
7.  使用以下命令将文件复制到雨云机器上风暴安装的`bin`文件夹:

    ```scala
    sudo cp /usr/local/storm/storm-0.9.2- incubating/conf/storm.yaml /usr/local/storm/storm-0.8.2/bin/

    ```

## 启动风暴守护程序

现在风暴集群已经设置好了，我们需要在各自的风暴节点上启动三个进程。它们如下:

*   **光轮:**通过从`$STORM_HOME` :

    ```scala
    sudo –bE bin/storm nimbus

    ```

    运行以下命令，在被识别为主节点的机器上启动光轮作为后台进程
*   **主管:**主管可以类似方式启动光轮启动。从`$STORM_HOME`运行以下命令:

    ```scala
    sudo –bE bin/storm supervisor

    ```

*   **用户界面:**风暴用户界面是一个检查风暴集群的网络应用程序，其中包含雨云/主管状态。它还列出了所有运行拓扑及其细节。从`$STORM_HOME`使用以下命令可以启用用户界面:

    ```scala
    sudo –bE bin/storm ui

    ```

用户界面可通过`http://<IP_ADDRESS_OF_NIMBUS>:8080`进入。

# 从命令提示符执行拓扑

一旦用户界面可见，所有守护进程启动，可以使用以下命令在 Nimbus 上提交拓扑:

```scala
storm jar storm-starter-0.0.1-SNAPSHOT-jar-with-dependencies.jar  storm.starter.WordCountTopology WordCount -c nimbus.host=localhost

```

这里显示了`WordCount`拓扑以分布式模式运行的风暴用户界面。它描述了拓扑状态、正常运行时间和其他细节(我们将在后面一章详细讨论用户界面的特性)。我们可以从用户界面中删除拓扑。

![Executing the topology from Command Prompt](../images/00020.jpeg)

## 调整字数统计拓扑进行定制

现在我们已经在分布式模式下部署了`WordCount`拓扑，让我们稍微调整一下螺栓中的代码，将`WordCount`写入到文件中。为此，我们将继续执行以下步骤:

1.  我们打算创造一个新的螺栓，`FileWriterBolt`，来实现这一点。打开`WordCountTopology.java`，将以下片段添加到`WordCountTopology.java` :

    ```scala
    public static class FileWriterBolt extends BaseBasicBolt {
        Map<String, Integer> counts = new HashMap<String,  Integer>();
        @Override
        public void execute(Tuple tuple, BasicOutputCollector  collector) {
            String word = tuple.getString(0);
            Integer count = counts.get(word);
            if(count==null) {count = 0;
            count = 0;
        }
            count++;
            counts.put(word, count);
            OutputStream ostream;
            try {
                ostream = new  FileOutputStream("~/wordCount.txt", true);
                ostream.write(word.getBytes());
                ostream.close();
            } catch (IOException e) {
                // TODO Auto-generated catch block
                e.printStackTrace();
            }
            collector.emit(new Values(word, count));
        }

        @Override
        public void declareOutputFields(OutputFieldsDeclarer  declarer) {
            declarer.declare(new Fields("word", "count"));
        }
    ```

2.  接下来我们要对`main()`方法进行修改，用这个新螺栓代替`WordCount Bolt()`；以下是片段:

    ```scala
    // instantiates the new builder object 
    TopologyBuilder builder = new TopologyBuilder();
    // Adds a new spout of type "RandomSentenceSpout" with a  parallelism hint of 5 
    builder.setSpout("spout", new RandomSentenceSpout(), 5);
    //Adds a new bolt to the  topology of type "SplitSentence"  with parallelism of 8
    builder.setBolt("split", new SplitSentence(),  8).shuffleGrouping("spout");
    //Adds a new bolt to the  topology of type "SplitSentence"  with parallelism of 8
    //builder.setBolt("count", new FileWriterBolt()(),  12).fieldsGrouping("split", new Fields("word"));
    ```

3.  接下来，您可以使用 Eclipse 执行拓扑，将其作为 Java 运行，输出将保存到主目录中名为`wordCount.txt`的文件中。
4.  要在分布式模式下运行，请执行以下步骤:
    1.  使用以下命令行编译拓扑更改以生成新的 Storm-starter 项目:

        ```scala
        mvn clean install

        ```

    2.  将`storm-starter-0.0.1-SNAPSHOT-jar-with-dependencies.jar`从起始项目下的目标文件夹复制到 Nimbus，比如说`/home/admin/topology/`。
    3.  使用以下命令提交拓扑:

        ```scala
        storm jar /home/admin/topology/storm-starter-0.0.1-SNAPSHOT- jar-with-dependencies.jar storm.starter.WordCountTopology  WordCount -c nimbus.host=localhost

        ```

5.  输出将与上一节图中执行的`WordCount`拓扑相同。

# 测验时间

问题 1 .陈述以下陈述是真是假:

1.  所有风暴拓扑都是可靠的。
2.  拓扑通常有多个喷口。
3.  拓扑通常有多个螺栓。
4.  一个螺栓只能在一条溪流上射出。

问题 2 .填空:

1.  _____ 是创建拓扑的模板。
2.  ___________ 指定特定螺栓或喷口产生多少个实例。
3.  Storm 的 __________ 守护进程类似于 Hadoop 的作业跟踪器。

问题 3 .执行以下任务:

1.  将 Storm-starter 项目的`WordCount`拓扑更改为`RandomSentenceSpout`，这样它就可以从指定位置的文件中读取句子。

# 总结

在这一章中，我们已经建立了风暴乐团。向您介绍了 Storm 拓扑的各种构造块，如螺栓、喷口和布线模板-拓扑生成器。我们执行并理解了`WordCount`拓扑，并对其进行了一些修改。

在下一章中，您将阅读并理解流分组、锚定和打包。这也将导致我们在风暴框架下的拓扑中出现可靠和不可靠的机制。