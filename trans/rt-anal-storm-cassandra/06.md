# 第六章。给风暴增添 NoSQL 的坚持

在这一章中，我们将进入理解 Storm 的下一步——我们将在拓扑中添加持久性。我们选择卡珊德拉的原因非常明显，这将在本章中详细说明。目的是让您了解卡珊德拉数据存储如何与 Storm 拓扑集成。

本章将涵盖以下主题:

*   卡珊德拉的优点
*   柱状数据库和柱状族设计基础介绍
*   建立卡珊德拉集群
*   介绍 CQLSH、命令行界面和连接器应用编程接口
*   连接到卡珊德拉商店的风暴拓扑
*   理解持久性的机制
*   风暴卡珊德拉应用的最佳实践

# 卡珊德拉的优点

这是任何人都会问的第一个也是最明显的问题，“我们为什么要用 NoSQL？”好吧，将目光投向 NoSQL 而非传统数据存储的快速答案，与世界转向大数据的原因是一样的——低成本、高度可扩展、可靠的解决方案可以存储无限量的数据。

现在，下一个问题是为什么是卡珊德拉，为什么不是 NoSQL 堆栈中的其他东西。这里的答案在于我们试图实现的问题和解决方法。嗯，我们正在处理实时分析，我们需要的一切都应该准确、无故障、快速。因此，卡珊德拉是最佳选择，因为:

*   它的写入速度是同类产品中最快的，如 HBase 等
*   它可以通过对等设计进行线性扩展
*   没有单点故障
*   可以在不影响彼此性能的情况下处理读写请求
*   处理包含数百万个事务和闪电般速度的搜索查询
*   具备复制因素的故障安全和高可用性
*   保证最终与 NoSQL 数据库的 CAP 定理保持一致
*   柱族设计可处理多种格式
*   无许可成本或许可成本低
*   减少开发运营或运营成本
*   它可以扩展以集成到各种其他大数据组件上

# 柱状数据库基础

开始使用 NoSQL 数据存储最重要的一个方面是了解柱状数据库的基础知识；或者更确切地说，让我们使用实际的术语——柱族。

这是一个在不同 NoSQL 数据库中有多种实现的概念，例如:

*   **卡珊德拉**:这是一个基于键值对的 NoSQL 数据库
*   **Mongo DB** :这个是基于文档的 NoSQL DB
*   **Neo4J** :这是一个图形 DB

它们与面向行的传统关系数据库管理系统在以下方面有所不同:

*   表演
*   存储扩展性
*   容错
*   低许可成本或无许可成本

但是，在重复了 NoSQL 数据库的所有差异和优势之后，您必须清楚地理解，向 NoSQL 的转变是数据存储、可用性和访问的整个范式的转变——它们不是关系数据库管理系统的替代品。

在 RDBMS 世界中，我们都习惯于创建表，但是在 Cassandra 中，我们创建列族，在列族中定义列的元数据，但是列实际上存储为行。每行可以有不同的列集，从而使整个列族相对非结构化和可扩展。

## 柱族类型

柱族有两种类型:

*   **静态列家族**:顾名思义有一组静态的列，是所有著名的关系数据库管理系统表的非常接近的替代，除了一些 NoSQL 传统的差异。下面是一个静态列族的例子:

    <colgroup class="calibre19"><col class="calibre20"><col class="calibre20"><col class="calibre20"><col class="calibre20"><col class="calibre20"></colgroup>
    | 

    罗基

     | 

    列

     |
    | --- | --- |
    | 拉曼 | 名字 | 电子邮件 | 手机号 | 年龄 |
    |  | 拉曼 subramanian | aa@yahoo.com | 99.99 亿 九十九万九千九百九十九 | 二十 |
    | 爱迪生 | 名字 | 电子邮件 | 手机号 | 年龄 |
    |  | 爱迪生韦斯利 | bb@yahoo.com | 八百八十八万八千八百八十八 | 三十 |
    | 亚历克斯 | 名字 | 电子邮件 | 手机号 | 年龄 |
    |  | 阿梅万豪酒店 | cc@yahoo.com | 七十七亿七千七百七十七万七千七百七十七 | 四十 |
    | 西蒙 | 名字 | 电子邮件 |  |  |
    |  | 斯里曼 米什拉 | dd@yahoo.com |  |  |

*   **动态列族**:这个一个得到了无结构无图式的真实本质。这里，我们不使用与列族相关联的预定义列，但是在将数据插入列族时，客户端应用程序可以动态生成和提供这些列。在动态列族的创建或定义过程中，我们通过定义比较器和验证器来定义关于列名和值的信息。下面是一个动态列族的示例:

    <colgroup class="calibre19"><col class="calibre20"><col class="calibre20"><col class="calibre20"><col class="calibre20"><col class="calibre20"></colgroup>
    | 

    罗基

     | 

    列

     |
    | --- | --- |
    | 拉曼 | 名字 | 电子邮件 | 手机号 | 年龄 |
    |  |  |  |  |
    | 爱迪生 | 地址 | 状态 | 领域 |  |
    |  |  |  |  |
    | 亚历克斯 | 国家 | 性 | 手机号 | 年龄 |
    |  |  |  |  |
    | 西蒙 | 国籍 |  |  |  |
    |  |  |  |  |

## 柱的类型

卡珊德拉支持多种栏目:

*   **Standard columns**: These columns contain a name; this is either static or dynamic and set by the writing application. A value (this is actually the attribute that stores the data) and timestamp are shown here:

    <colgroup class="calibre19"><col class="calibre20"></colgroup> 
    | 

    列名

     |
    | --- |
    | 价值 |
    | 时间戳 |

    Cassandra 利用与该列相关联的时间戳来找出该列的最后更新。当从 Cassandra 查询数据时，它按照这个时间戳排序，并且总是返回最新的值。

*   **Composite columns**: Cassandra makes use of this storage mechanism to handle clustered rows. This is a unique way of handling all the logical rows together that share the same partition key into a single physical wide row. This enables Cassandra to accomplish the legendary feat of storing 2 billion columns per row. For example, let's say I want to create a table where I capture live status updates from some social networking sites:

    ```
    CREATE TABLE statusUpdates(
      update_id uuid PRIMARY KEY,
      username varchar,
      mesage varchar
      );

    CREATE TABLE timeseriesTable (
      user_id varchar,
      udate_id uuid,
      username varchar,
      mesage varchar,
      PRIMARY KEY user_id , update_id )
    );
    ```

    实时更新记录在拥有`username`、`message`和`update_id`(实际上是 UUID)属性的`StatusUpdates`表下。

    在设计 Cassandra 列系列时，您应该广泛使用 UUIDs 提供的功能，这些功能可用于对数据进行排序。

    来自`timeseriesTable`的`user_id`和`update_id`属性的组合可以唯一地识别年表中的一行。

    Cassandra 使用主键中定义的第一列作为分区键；这也称为行键。

*   **过期栏目**:这些是特殊类型的卡珊德拉栏目，有时间生存( **TTL** ) 关联；存储在这些列中的值会在 TTL 过去后自动删除或擦除。这些列用于我们不想保留超过规定时间间隔的数据的用例；例如，如果我们不需要超过 24 小时的数据。在我们的列系列中，我会将 24 小时的 TTL 与插入的每一列相关联，并且这些数据将在插入 24 小时后被卡珊德拉自动删除。
*   **计数器列**:这些是又一个专门的功能列，增量存储号。对于我们使用计数器的情况，它们有特殊的实现和特殊的用法；例如，如果我需要计算一个事件发生的次数。

# 建立卡珊德拉集群

卡珊德拉是一个非常可扩展的键值存储。它保证了最终的一致性，其基于分布式环的体系结构消除了集群中的任何单点故障，从而使其高度可用。它的设计和开发是为了支持超大规模数据的快速读写。这种快速的写入和读取能力使其成为支持大型商业智能系统的**在线事务处理** ( **OLTP** ) 应用的有力竞争者。

Cassandra 提供了一个专栏-基于家族的数据模型，比典型的键值系统更灵活。

## 安装卡珊德拉

Cassandra 需要您可以部署的最稳定的 Java 1.6 版本，最好是 Oracle 或 Sun JVM。执行以下步骤安装卡珊德拉:

1.  从 Apache Cassandra 网站下载最新的稳定版本(撰写本文时的版本为 1.1.6)。
2.  在`/usr/local`下创建一个卡珊德拉目录，如下所示:

    ```
    sudo mkdir /usr/local/cassandra

    ```

3.  将下载的 TAR 文件解压到`/usr/local`位置。使用以下命令:

    ```
    sudo tar –xvf apache-cassandra-1.1.6-bin.tar.gz -C  /usr/local/cassandra

    ```

4.  Cassandra 需要一个目录来存储其数据、日志文件和缓存文件。创建`/usr/local/cassandra/tmp`来存储该数据:

    ```
    sudo mkdir –p /usr/local/cassandra/tmp

    ```

5.  Update the `Cassandra.yaml` configuration file under `/usr/local/Cassandra/apache-cassandra-1.1.6/conf`.

    将包含以下属性:

    ```
    cluster_name: 'MyClusterName'
    seeds: <IP of Node-1><IP of Node-2>(IP address of each node  go into it)
    listen_address: <IP of Current Node>
    ```

6.  使用以下脚本计算每个节点的令牌，并通过在`Cassandra.yaml` :

    ```
    #! /usr/bin/python
    import sys
    if (len(sys.argv) > 1):
      num=int(sys.argv[1])
    else:
      num=int(raw_input("How many nodes are in your cluster? "))
    for i in range(0, num):
      print 'node %d: %d' % (i, (i*(2**127)/num))
    ```

    中添加唯一的令牌值来更新每个节点的`initial_token`属性
7.  更新`conf/log4j-server.properties`文件中的以下属性。在`cassandra` :

    ```
    Log4j.appender.R.File=/usr/local/cassandra/temp/system.log

    ```

    下创建`temp`目录
8.  增加`Cassandra.yaml`中的`rpc_timeout`属性(如果这个超时非常小，并且网络延迟很高，卡珊德拉可能会认为节点已经死亡，而没有等待足够长的时间来传播响应)。
9.  在`/usr/local/Cassandra/apache-cassandra-1.1.6 using bin/Cassandra –f`运行卡珊德拉服务器。
10.  使用主机和端口在`/usr/local/Cassandra/apache-cassandra-1.1.6 using bin/Cassandra-cli`运行 Cassandra 客户端。
11.  使用`/usr/local/Cassandra/apache-cassandra-1.1.6`上的`bin/nodetool`振铃实用程序验证正确连接的集群:

    ```
    bin/nodetool –host <ip-adress> -p <port number> ring 
    192.168.1.30 datacenter1 rack1 Up    Normal 755.25 MB  25.00% 0
    192.168.1.31 datacenter1 rack1 Up    Normal 400.62 MB  25.00% 42535295865117307932921825928970
    192.168.1.51 datacenter1 rack1 Up    Normal 400.62 MB  25.00% 42535295865117307932921825928971
    192.168.1.32 datacenter1 rack1 Up    Normal 793.06 MB  25.00% 85070591730234615865843651857941
    ```

前面的输出显示了一个连接的集群。该配置表明它已正确配置和连接。

下面是输出的截图:

![Installing Cassandra](../images/00046.jpeg)

# 多个数据中心

在实际场景中，我们希望 Cassandra 集群分布在不同的数据中心，这样系统整体上对局部网络故障和物理灾难更加可靠和有弹性。

## 设置多个数据中心的前提条件

以下是设置多个数据中心应使用的一组先决条件:

*   在每个节点上安装 Cassandra
*   拥有群集中每个节点的 IP 地址
*   识别集群名称
*   识别种子节点
*   确定将要使用的告密者

## 安装卡珊德拉数据中心

以下是设置卡珊德拉数据中心的一组步骤:

1.  Let's start with an assumption that we have already installed Cassandra on the following nodes:

    10.188.66.41(种子 1)

    10.196.43.66

    10.188.247.41

    10.196.170.59(种子 2)

    10.189.61.170

    10.189.30.138

2.  使用上一节中定义的令牌生成 Python 脚本将令牌分配给前面的每个节点。
3.  假设我们按照以下数据中心的节点及其令牌分布进行排列:T118

    <colgroup class="calibre19"><col class="calibre20"><col class="calibre20"><col class="calibre20"><col class="calibre20"></colgroup>
    | 

    结节

     | 

    IP 地址；网络地址

     | 

    代币

     | 

    数据中心

     |
    | --- | --- | --- | --- |
    | 节点 0 | 10 . 188 . 66 . 41 | 零 | T42【Dc1】 |
    | 节点 1 | 10 . 196 . 43 . 66 | 56713727820156410577229101238628035245 | Dc1 |
    | 注 2 | 10 . 188 . 247 . 41 | 11342745564031282115445820247256070488 | Dc1 |
    | 附注 3 | 10 . 196 . 170 . 59 | 十 | Dc2 |
    | 节点 4 | 10 . 189 . 61 . 170 | 56713727820156410577229101238628035255 | T114】Dc2 |
    | 节点 5 | 10 . 189 . 30 . 138 | 11342745564031282115445820247256070498 | Dc2 |

4.  Stop Cassandra on the nodes and clear the data from `data_dir` of Cassandra:

    ```
    $ ps auwx | grep cassandra 

    ```

    该命令查找卡珊德拉 Java 进程标识:

    ```
    $ sudo kill <pid> 

    ```

    这是用指定的 PID 终止进程的命令:

    ```
    $ sudo rm -rf /var/lib/cassandra/*

    ```

    前面的命令从 Cassandra 的默认目录中清除数据。

5.  Modify the following property settings in the `cassandra.yaml` file for each node:

    ```
    endpoint_snitch <provide the name of snitch> 
      initial_token: <provide the value of token from previous  step>
      seeds: <provide internal IP_address of each seed node>
      listen_address: <provide localhost IP address>
    ```

    以下是更新后的配置:

    ```
    node0:
    end_point_snitch:  org.apache.cassandra.locator.PropertyFileSnitch
    initial_token: 0
    seed_provider:
      - class_name:  org.apache.cassandra.locator.SimpleSeedProvider
      parameters:
      - seeds: "10.188.66.41,10.196.170.59"
      listen_address: 10.196.43.66
      node1 to node5
    ```

    除了`initial_token`和`listen_address`属性之外，这些节点的所有属性与前面`node0`中定义的属性相同。

6.  接下来，我们必须为每个数据中心及其机架命名；例如`Dc1`、`Dc2`和`Rc1`、`Rc2`。
7.  转到`cassandra-topology.properties`文件，根据每个节点的 IP 地址为数据中心和机架名称添加一个分配。例如:

    ```
    # Cassandra Node IP=Data Center:Rack
    10.188.66.41=Dc1:Rc1
    10.196.43.66=Dc2:Rc1
    10.188.247.41=Dc1:Rc1
    10.196.170.59=Dc2:Rc1
    10.189.61.170=Dc1:Rc1
    10.199.30.138=Dc2:Rc1
    ```

8.  下一步是一个接一个地启动种子节点，然后是所有剩余的节点。
9.  检查您的环是否已打开，是否正在运行。

# CQLSH 简介

现在我们已经完成了卡珊德拉设置，让我们熟悉一下 shell 和一些基本命令:

1.  使用带有主机和端口的`bin/cqlsh`

    ```
    bin/cqlsh  –host <ip-adress> -p <port number>

    ```

    ，在`/usr/local/Cassandra/apache-cassandra-1.1.6`运行 CQL
2.  在卡珊德拉客户端或 CQL 创建密钥空间，如下所示:

    ```
    create keyspace <keyspace_name>; 

    ```

3.  Create a column family at the Cassandra client or at CQL as follows:

    ```
    use <keyspace_name>;
    create column family <columnfamily name>;

    ```

    例如，创建下表:

    ```
    CREATE TABLE appUSers (
     user_name varchar,
     Dept varchar,
     email varchar,
     PRIMARY KEY (user_name));

    ```

4.  从命令行向列族中插入几条记录:

    ```
    INSERT INTO appUSers (user_name, Dept, email)
     VALUES ('shilpi', 'bigdata, 'shilpisaxena@yahoo.com');

    ```

5.  从列族中检索数据:

    ```
    SELECT * FROM appUSers LIMIT 10;

    ```

# CLI 介绍

本节让您了解另一个用于与卡珊德拉进程交互的工具——命令行界面外壳。

以下步骤用于使用命令行界面外壳与卡珊德拉进行交互:

1.  以下是连接到卡珊德拉命令行界面的命令:

    ```
    Cd Cassandra-installation-dir/bin
    cassandra-cli -host localhost -port 9160

    ```

2.  创建键空间:

    ```
    [default@unknown] CREATE KEYSPACE myKeySpace
    with placement_strategy = 'SimpleStrategy'
    and strategy_options = {replication_factor:1};

    ```

3.  使用以下命令验证键空间的创建:

    ```
    [default@unknown] SHOW KEYSPACES;
     Durable Writes: true
     Options: [replication_factor:3]
     Column Families:
     ColumnFamily: MyEntries
     Key Validation Class:  org.apache.cassandra.db.marshal.UTF8Type
     Default column value validator:  org.apache.cassandra.db.marshal.UTF8Type
     Columns sorted by:  org.apache.cassandra.db.marshal.ReversedType (org.apache.cassandra.db.marshal.TimeUUIDType)
     GC grace seconds: 0
     Compaction min/max thresholds: 4/32
     Read repair chance: 0.1
     DC Local Read repair chance: 0.0
     Replicate on write: true
     Caching: KEYS_ONLY
     Bloom Filter FP chance: default
     Built indexes: []
     Compaction Strategy:  org.apache.cassandra.db.compaction. SizeTieredCompactionStrategy
     Compression Options:
     sstable_compression:  org.apache.cassandra.io.compress.SnappyCompressor
     ColumnFamily: MYDevicesEntries
     Key Validation Class:  org.apache.cassandra.db.marshal.UUIDType
     Default column value validator:  org.apache.cassandra.db.marshal.UTF8Type
     Columns sorted by:  org.apache.cassandra.db.marshal.UTF8Type
     GC grace seconds: 0
     Compaction min/max thresholds: 4/32
     Read repair chance: 0.1
     DC Local Read repair chance: 0.0
     Replicate on write: true
     Caching: KEYS_ONLY
     Bloom Filter FP chance: default
     Built indexes:  [sidelinedDevicesEntries. sidelinedDevicesEntries_date_created_idx,  sidelinedDevicesEntries. sidelinedDevicesEntries_event_type_idx]
     Column Metadata:
     Column Name: event_type
     Validation Class:  org.apache.cassandra.db.marshal.UTF8Type
     Index Name: sidelinedDevicesEntries_event_type_idx
     Index Type: KEYS
     Index Options: {}
     Column Name: date_created
     Validation Class:  org.apache.cassandra.db.marshal.DateType
     Index Name: sidelinedDevicesEntries_date_created_idx
     Index Type: KEYS
     Index Options: {}
     Column Name: event
     Validation Class:  org.apache.cassandra.db.marshal.UTF8Type
     Compaction Strategy:  org.apache.cassandra.db.compaction. SizeTieredCompactionStrategy
     Compression Options:
     sstable_compression:  org.apache.cassandra.io.compress.SnappyCompressor

    ```

4.  创建柱族:

    ```
    [default@unknown] USE myKeySpace;
     [default@demo] CREATE COLUMN FAMILY appUsers
     WITH comparator = UTF8Type
     AND key_validation_class=UTF8Type
     AND column_metadata = [
     {column_name:user_name, validation_class: UTF8Type}
     {column_name: Dept, validation_class: UTF8Type}
     {column_name: email, validation_class: UTF8Type}
    ];

    ```

5.  Insert data into the column family:

    ```
    [default@demo] SET appUsers['SS'][user_name']='shilpi';
     [default@demo] SET appUsers['ss'][Dept]='BigData';
     [default@demo] SET  appUsers['ss']['email']=shilpisaxena@yahoo.com';

    ```

    ### 注

    在这个例子中，代码`ss`是我的行键。

6.  从卡珊德拉列族中检索数据:

    ```
    GET appUsers[utf8('ss')][utf8('user_name')];
    List appUsers;

    ```

# 使用不同的客户端 API 访问 Cassandra

现在我们已经熟悉了 Cassandra，让我们进入下一步，我们将通过编程方式访问(插入或更新)集群中的数据。一般来说，我们讨论的 API 是在核心的节俭 API 上编写的包装器，它使用程序员友好的包在 Cassandra 集群上提供各种 CRUD 操作。

用于访问 Cassandra 的客户端应用编程接口如下:

*   **节俭协议**:访问 Cassandra 的所有 API 中最基本的是**远程过程调用** ( **RPC** ) 协议，它提供了一个语言中立的接口，从而暴露了使用 Python、Java 等进行通信的灵活性。请注意，我们将讨论的几乎所有其他 API 都在引擎盖下使用**节俭**。它使用简单，并且提供了基本的功能，如环发现和本地访问。不支持诸如重试、连接池等复杂功能。然而，有各种各样的库扩展了节俭并且增加了这些非常需要的特性，我们将在本章中涉及一些广泛使用的特性。
*   **赫克托**:这拥有的特权，成为基于 Java 的客户端应用程序访问 Cassandra 最稳定和最广泛使用的API 之一。如前所述，它在引擎盖下使用节俭，因此它本质上不能提供节俭协议不支持的任何功能。它被广泛使用的原因是它有许多现成可用的基本功能:
    *   它有连接池的实现
    *   它有一个环发现功能，附加了自动故障转移支持
    *   它对卡珊德拉环中被击倒的主机有重试选项
*   **数据税 Java 驱动程序**:这也是卡珊德拉的客户端访问选项堆栈中的最近添加的，因此与新版卡珊德拉配合良好。以下是它的显著特点:
    *   连接池
    *   重新连接策略
    *   负载平衡
    *   光标支持
*   **Astyanax** :这是卡珊德拉客户端API 的花束中非常的最新加入，由网飞开发，这无疑让它比其他的更具寓言性。让我们看一下它的凭据，看看它符合什么条件:
    *   它支持 Hector 的所有功能，并且更容易使用
    *   它承诺比赫克托更好的连接池
    *   它比赫克托更擅长处理故障转移
    *   It provides some out-of-the-box, database-like features (now that's big news). At the API level, it provides functionality called Recipes in its terms, which provides:

        并行行查询执行

        消息队列功能

        对象存储

        页码

    *   它有许多经常需要的“T2”工具，如 JSON Writer 和 CSV“T3”Importer

# 连接到卡珊德拉商店的风暴拓扑

现在你已经被教育和告知为什么你应该使用卡珊德拉。您已经完成了卡珊德拉和列族创建的设置，甚至已经介绍了可用于以编程方式访问卡珊德拉数据存储的各种客户端/协议选项。如前所述，赫克托是迄今为止最广泛使用的访问卡珊德拉的应用编程接口，尽管`Datastax`和`Astyanax`驱动程序正在快速赶上。在我们的练习中，我们将使用赫克托应用编程接口。

我们要在这里实现的用例是使用 Cassandra 来支持电信数据的实时、即席报告，这些数据正在使用 Storm 拓扑进行整理、解析和丰富。

![Storm topology wired to the Cassandra store](../images/00047.jpeg)

如上图所示，该用例需要使用数据收集组件进行实时电信**呼叫详细记录** ( **CDR** ) 捕获(实际上，我们可以使用样本记录和模拟器外壳脚本来模拟实时 CDR 提要)。整理后的实时提要被推入 RabbitMQ 代理，然后被风暴拓扑使用。

对于拓扑，我们有一个 AMQP 喷口作为消费者，它读取队列的数据，并将其向下推至拓扑螺栓；这里，我们已经连接了螺栓来解析消息，并将其转换为 **【普通旧 Java 对象】** ( **POJO** )。然后，我们的拓扑中有了一个新条目，即 Cassandra bolt，它实际上将数据存储在 Cassandra 集群中。

从卡珊德拉集群中，基于用户界面的消费者根据用户定义的搜索查询检索数据，从而提供实时数据的即席实时报告。

为了便于实现，我们将从 CLI/CQLSH 中查询数据，如下所示:

1.  创建键空间:

    ```
    create keyspace my_keyspace with placement_strategy = 'SimpleStrategy' and strategy_options = {replication_factor : 3} and durable_writes = true;
     use my_keyspace;

    ```

2.  创建柱族:

    ```
    create column family my_columnfamily
      with column_type = 'Standard'
      and comparator = 'UTF8Type'
      and default_validation_class = 'BytesType'
      and key_validation_class = 'TimeUUIDType'
      and read_repair_chance = 0.1
      and dclocal_read_repair_chance = 0.0
      and gc_grace = 0
      and min_compaction_threshold = 4
      and max_compaction_threshold = 32
      and replicate_on_write = true
      and compaction_strategy =  'org.apache.cassandra.db.compaction. SizeTieredCompactionStrategy'
      and caching = 'KEYS_ONLY'
      and bloom_filter_fp_chance = 0.5
      and column_metadata = [
    {column_name : 'cellnumber',
      validation_class : Int32Type },
      {column_name : 'tollchrg',
      validation_class : UTF8Type},
    {column_name : 'msgres',
      validation_class : UTF8Type},

    {column_name : 'servicetype',
      validation_class : UTF8Type}]
      and compression_options = {'sstable_compression' :  'org.apache.cassandra.io.compress.SnappyCompressor'
    };
    ```

3.  The following changes need to be made to `pom.xml` in the project. The Hector dependency should be added to the `pom.xml` file so that it is fetched at the time of build and added to the `m2` repository, as shown:

    ```
      <dependency>
        <groupId>me.prettyprint</groupId>
        <artifactId>hector-core</artifactId>
        <version>0.8.0-2</version>
      </dependency>
    ```

    如果您使用的是非 Maven 项目，请遵循通常的协议——下载 Hector core JAR 文件，并将其添加到项目构建路径中，以便满足所有必需的依赖关系。

4.  接下来，我们需要在我们的 Storm 拓扑中放置组件。我们将从创建一个`CassandraController` Java 组件开始，该组件将保存所有与 Cassandra 相关的功能，并将从拓扑中的`CassandraBolt`类调用该组件，以将数据保存到 Cassandra 中:

    ```
    public class CassandraController {

      private static final Logger logger =  LogUtils.getLogger(CassandraManager.class);
      //various serializers are declared in here
      UUIDSerializer timeUUIDSerializer = UUIDSerializer.get();
      StringSerializer stringSerializer =  StringSerializer.get();
      DateSerializer dateSerializer = DateSerializer.get();
      LongSerializer longSerializer = LongSerializer.get();

      public CassandraController() {
          //list of IPs of Cassandra node in ring
          String nodes =  "10.3.1.41,10.3.1.42,10.3.1.44,10.3.1.45";
          String clusterName = "mycluster";
          //creating a new configurator
          CassandraHostConfigurator hostConfigurator = new  CassandraHostConfigurator(nodes);
          hostConfigurator.setCassandraThriftSocketTimeout(0);
          cluster = HFactory.getOrCreateCluster(clusterName,  hostConfigurator);

          String[] nodeList = nodes.split(",");
          if (nodeList != null && nodeList.length ==  cluster.getConnectionManager(). getDownedHosts().size()) {
            logger.error("All cassandra nodes are down. " +  nodes);
          }

          //setting up read and write consistencies
          ConfigurableConsistencyLevel consistency = new  ConfigurableConsistencyLevel();
          consistency.setDefaultWriteConsistencyLevel (HConsistencyLevel.ONE);
          consistency.setDefaultReadConsistencyLevel (HConsistencyLevel.ONE);
          keySpaceObj = HFactory.createKeyspace ("my_keyspace", cluster, consistency);
          stringMutator = HFactory.createMutator(keySpaceObj, stringSerializer);
          uuidMutator = HFactory.createMutator (keySpaceObj, timeUUIDSerializer);

          logger.info("Cassandra data store initialized,  Nodes=" + nodes + ", " + "cluster name=" +  clusterName + ", " + "keyspace=" + keyspace + ", " +  "consistency=" + writeConsistency);
        }
        //defining the mutator 
      public Mutator < Composite > getCompositeMutator() {
        return compositeMutator;
      }

      public void setCompositeMutator(Mutator < Composite >  compositeMutator) {
          this.compositeMutator = compositeMutator;
        }
        //getter and setters for all mutators and serializers

      public StringSerializer getStringSerializer() {
        return stringSerializer;
      }

      public Keyspace getKeyspace() {
        return keySpaceObj;
      }
    }
    ```

5.  最后但不是最不重要的在我们的拓扑中，实际上是将写入卡珊德拉的组件，风暴螺栓将利用前面创建的`CassandraController`将实时数据写入卡珊德拉:

    ```
    public class CassandraBolt extends BaseBasicBolt {
      private static final Logger logger =  LogUtils.getLogger(CassandraBolt.class);

      public void prepare(Map stormConf, TopologyContext  context) {

        logger.debug("Cassandra bolt, prepare()");
        try {
          cassandraMngr = new CassandraController();
          myCf = "my_columnfamily";
          );

        } catch (Exception e) {
          logger.error("Error while instantiating  CassandraBolt", e);
          throw new RuntimeException(e);
        }
      }

      @Override
      public void execute(Tuple input, BasicOutputCollector  collector) {
        logger.debug("execute method :: Start ");
          Calendar tCalendar = null;
          long eventts = eventObj.getEventTimestampMillis();
          com.eaio.uuid.UUID uuid = new  com.eaio.uuid.UUID(getTimeForUUID(eventts),  clockSeqAndNode);

      java.util.UUID keyUUID =  java.util.UUID.fromString(uuid.toString());

      /*
      * Persisting to my CF
      */

      try {
        if (keyUUID != null) {
            cassandraMngrTDR.getUUIDMutator().addInsertion(
                keyUUID,
                myCf,
                HFactory.createColumn("eventts",
                    new Timestamp(tCalendar.getTimeInMillis()),  -1, cassandraMngr.getStringSerializer(),
                    cassandraMngr.getDateSerializer()));
         }

      cassandraMngrTDR.getUUIDMutator().addInsertion(
        keyUUID,
        myCf,
        HFactory.createColumn("cellnumber",  eventObj.getCellnumber(), -1,  cassandraMngr.getStringSerializer(),
          cassandraMngr.getLongSerializer()));
          cassandraMngr.getUUIDMutator().execute();
      logger.debug("CDR event with key = " + keyUUID + "  inserted into Cassandra cf " + myCf);

      } else {
      logger.error("Record not saved. Error while parsing date  to generate KEY for cassandra data store, column family -  " + myCf);
        }
      }

      catch (Exception excep) {
      logger.error("Record not saved. Error while saving data  to cassandra data store, column family - " + myCf,  excep);
      }

       logger.debug("execute method :: End ");
      }
    }
    ```

所以在这里我们完成最后一块拼图；我们现在可以使用 Storm 实时将数据流式传输到 Cassandra 中。端到端执行拓扑后，可以使用 CLI/CQLSH 上的 select 或 list 命令来验证 Cassandra 中的数据。

# 风暴/卡珊德拉应用的最佳实践

当使用具有 24/7 全天候运行的服务级别协议的分布式应用程序时，速度非常快，平均处理时间很短，某些方面变得极其重要，需要注意:

*   网络延迟在实时应用程序中起着重要作用，它可以决定产品的成败，因此在数据中心或跨数据中心放置各种节点时要做出非常明智和有意识的决定。在这种情况下，通常建议将 ping 延迟保持在最小。
*   卡珊德拉的复制因子应该在 3 左右。
*   压实应该是卡珊德拉日常维护的一部分。

# 测验时间

问题 1 .陈述以下陈述是真是假:

1.  卡珊德拉是一个基于文档的 NoSQL。
2.  卡珊德拉只有一个失败点。
3.  Cassandra 对密钥分发使用一致哈希。
4.  卡珊德拉从事主从建筑。

问题 2 .填空:

1.  _____ 卡珊德拉坚持 CAP 定理的属性。
2.  _____ 是使卡珊德拉成为与 Storm 结合使用的竞争者的显著特征。
3.  _____ 是一个使用 Java 客户端访问卡珊德拉的应用编程接口，是一个希腊神话人物——卡珊德拉的兄弟。

问题 3 .完成本章中提到的用例，并演示端到端执行，将数据填充到 Cassandra 中。

# 总结

在这一章中，你已经介绍了 NoSQL 的基本知识，特别是卡珊德拉。您获得了设置 Cassandra 集群的实践经验，并了解了提供对 Cassandra 编程访问的各种 API、驱动程序和协议。我们还将 Cassandra 作为数据存储集成到我们的 Storm 拓扑中，用于数据插入。

在下一章中，我们将谈到卡珊德拉的一些不可或缺的方面，特别是一致性和可用性。