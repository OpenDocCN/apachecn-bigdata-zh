# 第十一章。分布式缓存和风暴中心平台

在本章中，我们将了解分布式缓存与 Storm 结合使用的必要性，以及广泛使用的选项与 Storm 的集成。我们还将与 Storm 合作接触**复杂事件处理** ( **CEP** )引擎。

在本章中，我们将涵盖以下主题:

*   风暴框架中对分布式缓存的需求
*   memcache 简介
*   使用缓存构建拓扑
*   CEP 与斯珀简介

在本章的最后，您应该能够结合 Storm 应用 CEP 和缓存来解决实时用例。

# 风暴中分布式缓存的需求

现在我们已经对 Storm 进行了充分的探索，了解了它的所有优势，让我们来接触一下它的一个最大的弱点:缺少共享缓存，这是内存中的一个公共存储，运行在 Storm 集群中不同节点上的工作人员可以访问和写入的所有任务。

下图说明了一个三节点 Storm 集群，其中我们有两个工作人员在每个主管节点上运行:

![The need for distributed caching in Storm](../images/00074.jpeg)

如上图所示，每个工作人员都有自己的 JVM，数据可以在其中存储和缓存。然而，我们在这里缺少的是一个缓存层，它在一个主管上的工作人员之间以及主管之间共享组件。下图描述了我们所指的需求:

![The need for distributed caching in Storm](../images/00075.jpeg)

前面的图描述了共享缓存层的需求，公共数据可以放置在共享缓存层，可以从所有节点引用。这些都是非常有效的用例，因为在生产中，我们会遇到如下场景:

*   我们有许多只读的参考维度数据，我们希望将它们放在一个地方，而不是在每个主管级别进行复制和更新
*   有时，我们在某些用例中有事务性数据，所有的工作人员都要读取和更新这些数据；例如，在对某些事件进行计数时，计数必须保存在一个公共位置

这就是所有管理节点都可以访问的公共共享缓存层。

# memcached 简介

Memcached 是一个非常简单的内存键值存储；我们可以假设它是哈希映射的内存存储。这可以与 Storm 管理器一起用作公共内存存储，Storm 集群中各个节点上的所有 Storm 工作人员都可以访问该内存进行读/写操作。

Memcached 具有以下组件:

*   memcached 服务器
*   memcache 客户端
*   哈希算法(基于客户端的实现)
*   数据保留的服务器算法

Memcached 使用**最近最少使用的** ( **LRU** )从缓存中丢弃元素。这意味着从最长时间以来没有被引用的项目是第一个从缓存中移除的项目。这些项目被称为从缓存中过期，如果它们在过期后被引用，它们将从稳定的存储中重新加载。

以下是如何从缓存中加载和检索条目的流程:

![Introduction to memcached](../images/00076.jpeg)

上图描述了缓存命中和缓存未命中的情况，其中某些项目根据 LRU 算法过期。上图中的场景如下:

*   当缓存应用程序位置启动时，它会加载来自稳定存储的数据，在我们的例子中，是来自数据库的数据
*   当我们从缓存中请求数据时，可能会出现两种情况:
    *   **缓存命中**:这里是我们请求的数据在缓存服务器上的位置，在这种情况下，请求是从缓存中发出的
    *   **缓存未命中**:这里是缓存服务器中不存在请求的数据的地方，在这种情况下，数据从数据库中提取到缓存中，然后从缓存中为请求提供服务

现在，我们了解了缓存是如何工作的，以及在 Storm 解决方案的背景下对它的需求。

## 设置 memcache

以下是安装 memcache 需要执行的步骤:

```
wget http://memcached.org/latest
tar -zxvfmemcached-1.x.x.tar.gz
cdmemcached-1.x.x
./configure && make && make test &&sudo make install

```

下面是连接到 memcache 客户端和函数的代码片段。它从缓存中检索数据:

```
public class MemCacheClient {
  private static MemcachedClient client = null;
  private static final Logger logger =  LogUtils.getLogger(MemCacheClient.class);

  /**
  * Constructor that accepts the cache properties as parameter  and initialises the client object accordingly.
   * @param properties
   * @throws Exception
   */

  publicMemCacheClient(Properties properties) throws Exception {
    super();
    try {
      if (null == client) {
        client = new MemcachedClient(new InetSocketAddress(
          102.23.34.22,
          5454)));
    }
  } catch (IOException e) {
    if (null != client)
      shutdown();
    throw new Exception("Error while initiating MemCacheClient",  e);
  }
}

/**
 * Shutdown the client and nullify it
 */

public void shutdown() {
    logger.info("Shutting down memcache client ");
    client.shutdown();
    client = null;
  }

  /**
    * This method sets a value in cache with a specific key and  timeout 
    * @param key the unique key to identify the value 
    * @paramtimeOut the time interval in ms after which the value  would be refreshed
    * @paramval
    * @return
    */

  public Future < Boolean > addToMemCache(String key, inttimeOut,  Object val) {
    if (null != client) {
      Future < Boolean > future = client.set(key, timeOut, val);
      return future;
    } else {
      return null;
    }
  }

  /**
    * retrives and returns the value object against the key passed  in as parameter
    * @param key
    * @return
    */

public Object getMemcachedValue(String key) {
  if (null != client) {
    try {
      returnclient.get(key);
    } catch (OperationTimeoutException e) {
      logger.error(
        "Error while fetching value from memcache server for key "  + key, e);
      return null;
    }
  } else
    return null;
  }
}
```

一旦您编码了前面的代码片段，您将已经构建了创建缓存客户端、将数据加载到缓存中并从中检索值的机制。因此，任何需要访问缓存的 Storm bolt 都可以通过与客户端的交互来使用 memcache 创建的公共层。

## 用缓存构建拓扑

一旦我们有了基本的缓存框架，很容易将它插入螺栓并从缓存中引用数据，或者在缓存中更新它。以下是缓存的片段:

```
public class MyCacheReaderBolt extends BaseBasicBolt {
  MyCacheReadercacheReader;
  @Override
  public void prepare(Map stormConf, TopologyContext context) {
      super.prepare(stormConf, context);
      try {
        cacheReader = new MyCacheReader();
      } catch (Exception e) {
        logger.error("Error while initializing Cache", e);
      }
    }

  /**
     * Called whenever a new tuple is received by this bolt.  Responsible for 
     * emitting cache enriched event onto output stream 
  */

  public void execute(Tuple tuple, BasicOutputCollector collector)  {
    logger.info("execute method :: Start ");
    event = tuple.getString(0);
    populateEventFromCache(event);
    collector.emit(outputStream, new Values(event));
  } else {
    logger.warn("Event not parsed :: " + tuple.getString(0));
  }
} catch (Exception e) {
  logger.error("Error in execute() ", e);
  }
}
logger.info("execute method :: End ");
}

private void populateEventFromCache(Event event) {
  HashMapfetchMap = (HashMap)  cacheReader.get(searchObj.hashCode());
  if (null != fetchMap) {
    event.setAccountID(Integer.parseInt((String)  fetchMap.get("account_id")));
    logger.debug("Populating event" + event + " using cache " +  fetchMap);
  } else {
    logger.debug("No matching event found in cache.");
  }
  logger.info("Time to fetch from cache=" +  (System.currentTimeMillis() - t1) + "msec");
  }
}

/**
 * Declares output streams and tuple fields emitted from this bolt
 */
  @Override
    public void declareOutputFields(OutputFieldsDeclarer declarer)  {
    String stormStreamName = logStream.getName() + "_" +  eventType;
    declarer.declareStream(stormStreamName, new  Fields(stormStreamName));
  logger.debug("Topology : " + topology.getTopologyName() + ",  Declared output stream : " + stormStreamName + ", Output field :  " + stormStreamName);
}
```

前面的代码片段演示了一个螺栓，它从流中读取一个事件，从 memcache 中获取一些维度数据，将丰富的螺栓发送到流中，到达 DAG 拓扑中的后续螺栓。

# 复杂事件处理引擎简介

有两个术语通常是连用的；分别是**复杂事件处理** ( **CEP** )和**事件流处理** ( **ESP** )。

嗯，理论上，这些是技术范例的一部分，允许我们通过对流数据进行戏剧性的实时分析来构建应用程序。它们让我们以非常快的速度处理传入的事件，并在事件流之上执行类似于 SQL 的查询，以生成实时直方图。我们可以假设 CEP 是传统数据库的反转。在传统的数据库管理系统和关系数据库管理系统的情况下，我们存储数据，然后对它们运行 SQL 查询以获得结果，而在中心平台的情况下，我们预定义或存储查询，并通过它们运行数据。我们可以用一个例子来设想这一点；假设我在经营一家百货商店，我想知道最近一个小时内销售额最高的商品。因此，如果您看这里，我们将要执行的查询本质上是非常固定的，但是输入数据不是恒定的——它在每次销售交易时都会改变。同样，假设我经营一家股票控股公司，希望每 5 秒钟就能知道过去 2 分钟内表现最好的 10 家公司。

![Introduction to the complex event processing engine](../images/00077.jpeg)

上图描述了股票代码用例，其中我们有一个 2 分钟的滑动窗口，股票代码每 5 秒钟滑动一次。我们现在有很多这方面的实际用例，比如:

*   针对**销售点** ( **销售点**交易的欺诈检测模式
*   任意线段的顶部 *N*
*   深度学习模式应用于任何来源的数据流

现在，在高层次上理解了 CEP 及其需求之后，让我们来谈谈它的高层次组成部分:

*   每个 CEP 中的操作数是`Event`的`Data`；它本质上是一个事件驱动的系统
*   **事件处理语言**:这是一个工具，可以帮助构建要对数据执行的查询
*   **监听器**:这些是实际执行查询并在事件到达系统时执行操作的组件

## Esper

斯珀是开放源代码——GPL 和企业许可证——下领先的 CEP 引擎之一。这个包可以从[http://www.espertech.com/download/](http://www.espertech.com/download/)下载，如果你试图执行一个基于 Maven 的斯珀项目，依赖关系可以如下构建:

```
<dependency>
<groupId>com.espertech</groupId>
<artifactId>esper</artifactId>
<version> ... </version>
</dependency>
Ref :Espertech.com
```

下一个显而易见的问题可能是，为什么我们要结合风暴使用斯珀-CEP。嗯，斯珀有一些独特的能力，可以很好地与风暴合作，让 EQL 工厂利用风暴得出的结果。以下是导致这一选择的补充特性:

*   **吞吐量**:补充风暴的能力，斯珀也有非常高的吞吐量，每秒可以处理 1K 到 10 万条消息。
*   **延迟**:斯珀能够以非常低的延迟率基于斯珀在的结果执行 eql 和动作；大多数情况下，这是的毫秒量级。
*   **计算**:这些指的是执行功能的能力，例如模式检测、基于聚合的复杂查询以及随时间的相关性。这些流数据的切片窗口。

## 从斯珀开始

在我们开始结合斯珀和斯托姆之前，让我们单独在斯珀尝试一个自己动手的小练习，以了解斯珀的结构组件及其布线。

让我们建立一个案例，在这个案例中，我们试图在轮盘赌中获得 10，000 以上的分数列表。

我们希望您在开始编码之前，将斯珀包从 EsperTech([http://www.espertech.com/community/](http://www.espertech.com/community/))下载到您的 POM 上。或者，您可以使用上一节中提到的 Maven 依赖项。

以下是斯珀事件的代码片段——在我们的示例中，这是`CasinoWinEvent`，一个值对象，我们在其中存储游戏名称、奖金金额和时间戳:

```
public static class CasinoWinEvent {
  String game;
  Double prizeAmount;
  Date timeStamp;

  publicCasinoWinEvent(String s, double p, long t) {
    game = s;
    prizeAmount = p;
    timeStamp = new Date(t);
  }
  public double getPrizeAmount() {
    return prizeAmount;
  }
  public String getGame() {
    return game;
  }
  public Date getTimeStamp() {
    return timeStamp;
  }

  @
  Override
  public String toString() {
    return "Price: " + price.toString() + " time: " +  timeStamp.toString();
  }
}
```

一旦我们有了值对象，下一步就是实例化斯珀引擎和监听器，并将所有部分连接在一起:

```
public class myEsperMain {
  private static Random generator = new Random();
  public static void GenerateRandomCasinoWinEvent(EPRuntimecepRT)  {
    doubleprizeAmount = (double) generator.nextInt(10);
    longtimeStamp = System.currentTimeMillis();
    String game = "Roulette";
    CasinoWinEventcasinoEvent = new CasinoWinEvent(game,  prizeAmount, timeStamp);
    System.out.println("Sending Event:" + casinoEvent);
    cepRT.sendEvent(casinoEvent);
  }
  public static class CEPListener implements UpdateListener {
    public void update(EventBean[] newData, EventBean[] oldData) {
      System.out.println("Event received: " +  newData[0].getUnderlying());
    }
  }
  public static void main(String[] args) {
    //The Configuration is meant only as an initialization-time  object.
    Configuration cepConfig = new Configuration();
    cepConfig.addEventType("CasinoEvent",  CasinoWinEvent.class.getName());
    EPServiceProvidercep =  EPServiceProviderManager.getProvider("myCEPEngine",  cepConfig);
    EPRuntimecepRT = cep.getEPRuntime();
    EPAdministratorcepAdm = cep.getEPAdministrator();
    EPStatementcepStatement = cepAdm.createEPL("select * from " +   "CasinoEvent(symbol='Roulette').win:length(2) " + "having  avg(prizeAmount) > 10000.0");

    cepStatement.addListener(new CEPListener());
    // We generate a few ticks...
    for (inti = 0; i < 5; i++) {
      GenerateRandomCasinoWinEvent(cepRT);
    }
  }
}
```

以下是输出的片段:

![Getting started with Esper](../images/00078.jpeg)

在前面的片段中，`CEPListener`是`updateListener`的实现(监听事件的到达)`newData`有一个或多个新到达事件的流，`oldData`有该流的前一个状态，即监听者当前触发到达之前。

在主方法中，我们可以加载斯珀配置，或者如前面的例子所示，创建一个默认配置。然后，我们创建一个斯珀运行时引擎实例，并将 EQL 查询绑定到它。

如果您查看前面代码中的`cepStatement.addListener(new CEPListener())`语句，您会看到我们也将侦听器绑定到语句，从而将所有部分连接在一起。

## 整合斯珀与风暴

下图描述了我们计划如何在中使用斯珀，并结合我们之前在[第 6 章](06.html#page "Chapter 6\. Adding NoSQL Persistence to Storm")、*中创建的拓扑之一，将 NoSQL 持久性添加到风暴*中。Storm 与斯珀的集成使开发人员能够在 Storm 正在处理的事件流之上执行类似 SQL 的查询。

![Integrating Esper with Storm](../images/00079.jpeg)

在这里，我们对我们创建的一个早期的拓扑进行了一些修改，并在同一拓扑中添加了一个斯珀螺栓。这个螺栓读取正被倾倒到卡珊德拉的同一条流，并通过`Esperlistener`执行 EQL 处决。它执行以过滤呼叫持续时间为 0 秒的记录集。

以下是`ZeroDuration`过滤螺栓的一个片段，用于过滤持续时间为 0 秒的`CALL_END`事件，这些事件将被发射到为斯珀螺栓提供能量的流中:

```
  /*
  * Bolt responsible for forwarding events which satisfy following  criteria:
  * <ul>
  * <li>event should belong to 'End'  type</li>
  * <li>duration should be zero</li>
  * </ul>
  */

public class ZeroSecondsCDRBolt extends BaseRichBolt {

  /**
  * Called when {@link ZeroSecondsCDRBolt} is initialized
  */
  @Override
  public void prepare(Map conf, TopologyContext context,
    OutputCollector collector) {
    logger.info("prepare method :: Start ");
    this.collector = collector;
    logger.info("prepare() conf {},Collector {}", conf.toString(),  collector.toString());
    logger.info("prepare method :: End ");
  }

  /**
  * Called whenever a new tuple is received by this bolt. This  method 
   * filters zero duration End records 
   */

  @
  Override
  public void execute(Tuple tuple) {
    logger.info("execute method :: Start ");

    if (tuple != null && tuple.getString(0) != null) {
      eventCounter++;
      String event = tuple.getString(0);
      logger.info("execute :event recd :: {}", event);
      if (event != null && event.contains("CALL_END")) {
        emitCallEndRecords(tuple);
      }
      collector.ack(tuple);
    }
    logger.info("execute method :: End ");
  }

  private void emitCallEndRecords(Tuple tuple) {
    String event = tuple.getString(0);

      try {
        //splitting the event based on semicolon
        String[] eventTokens = event.split(",");
        duration = Long.parseLong(eventTokens[4]);
        callId = Long.parseLong(eventTokens[0]);
        logger.debug(" Event (callId = {}) is a Zero duration  Qualifier ", callId);
        collector.emit(....);

      } catch (Exception e) {
        logger.error("Corrupt Stopped record. Error occurred while  parsing the event : {}", event);
      }
    }

  /**
  * Declares output fields in tuple emitted from this bolt
  */

  @Override
  public void declareOutputFields(OutputFieldsDeclarer declarer) {
    declarer.declareStream(CALL_END, new Fields());
  }

  @
  Override
  public Map < String, Object > getComponentConfiguration() {
    return null;
  }
}
```

下一步是将斯珀螺栓共轭到拓扑中。这个可以很容易地从[https://github.com/tomdz/storm-esper](https://github.com/tomdz/storm-esper)上捆绑下载，并且可以使用以下代码快速捆绑到拓扑中:

```
EsperBoltesperBolt = newEsperBolt.Builder()
  .inputs()
  .aliasComponent("ZeroSecondCallBolt")
  .withFields("a", "b")
  .ofType(Integer.class)
  .toEventType("CALL_END")
  .outputs()
  .outputs().onDefaultStream().emit("count")
  .statements()
  .add("select callID as CALL_ID,callType as CALL_TYPE, count(*)  as OCCURRENCE_CNT from CDR.win:time_batch(5 minutes)  where  (eventType = 'CALL_END') and (duration = 0) group by  callID,eventType having count(*) > 0 order by  OCCURRENCE_CNTdesc")
  .build();
```

以下是输出结果:

![Integrating Esper with Storm](../images/00080.jpeg)

上图中的斯珀查询在输入数据流上执行；下面是它的分解和解释:

```
selectcallID as CALL_ID,callType as CALL_TYPE, count(*) as  OCCURRENCE_CNT
```

我们从传入的元组中选择以下字段，如`Call_Id`、`Call_type`和`count`:

```
fromCDR.win:time_batch(5 minutes)  where (eventType = 'CALL_END')  and (duration = 0) group by callID,eventTypehaving count(*) > 0
order by OCCURRENCE_CNTdesc
```

我们正在操作的指定窗口是`CDR.WIN`。批处理大小为 5 分钟，这意味着随着每个事件或元组的到达，我们将回溯 5 分钟的时间，并对过去 5 分钟内到达的数据执行查询。结果按事件类型分组，并按相反的顺序排序。

# 测验时间

问题 1 .陈述以下陈述是真是假:

1.  缓存是一个只读内存空间。
2.  数据一旦添加到缓存中，就会永远保留在那里。
3.  CEP 允许在流数据上实现类似 SQL 的查询。
4.  斯珀基于事件驱动架构。

问题 2 .填空:

1.  _____ 是 memcache 的算法。
2.  当数据不在缓存中时，称为 ______________。
3.  _____ 是触发 **Endeca 查询语言** ( **EQL** )执行的斯珀组件。
4.  _____ 一般用于时间序列加窗函数数据。

问题 3 .使用斯珀创建一个端到端拓扑，使用 Storm 和斯珀联合显示上述高速公路上的前 10 个超速设备。

# 总结

在本章中，我们结合 Storm 讨论了缓存的概念，以及解决方案开发人员使用缓存的工具和应用。我们了解了 memcache 作为一个缓存系统。

在本章的后半部分，我们探讨了斯珀作为一个复杂的事件处理系统，并了解了它与风暴拓扑的集成。