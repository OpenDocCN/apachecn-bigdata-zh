# 零、前言

Apache Spark 是一个内存中的、基于集群的数据处理系统，提供大数据处理、分析、机器学习等多种功能。通过这条学习之路，您可以通过学习如何扩展 Spark 的功能，并在此平台上构建自己的数据流和机器学习程序，将您对 Apache Spark 的了解提升到一个新的水平。您将使用 Apache Spark 中的不同模块，例如使用 Spark SQL 进行交互式查询、使用数据框架和数据集、使用 Spark Streaming 实现流分析，以及使用 MLlib 和各种外部工具在 Spark 上应用机器学习和深度学习技术。在这个精心设计的学习结束时...

# 这本书是给谁的

如果您是一名中级 Spark 开发人员，希望掌握 Apache Spark 2.x 的高级功能和用例，那么这条学习之路非常适合您。想要学习如何集成和使用 Apache Spark 的功能并构建强大的大数据管道的大数据专业人员也将发现此 Learning Path 非常有用。要掌握本学习路径中解释的概念，您必须了解 Apache Spark 和 Scala 的基础知识。

# 这本书涵盖了什么

[*第 1 章*](00.html)*ApacheSpark V2 的第一次尝试和新动态*概述了 ApacheSpark、其模块内可用的功能以及如何扩展。它涵盖了标准 Apache Spark 模块之外的 Apache Spark 生态系统中可用于处理和存储的工具。它还提供了关于性能调整的提示。

[*第二章*](00.html)*Apache Spark Streaming*，讲述使用 Apache Spark Streaming 的连续应用。您将学习如何增量处理数据并创建可操作的见解。

[*第三章*](00.html)*结构化流*讲述了结构化流——一种使用数据框架和数据集 API 定义连续应用的新方法。

[*第四章*](00.html)*Apache 星火 MLlib* ，介绍...

# 充分利用这本书

**操作系统:** Linux 发行版更好(包括 Debian、Ubuntu、Fedora、RHEL 和 CentOS)，更具体来说，对于 Ubuntu，建议拥有完整的 14.04 (LTS) 64 位(或更高版本)安装、VMWare player 12 或 Virtual box。您可以在 Windows (XP/7/8/10)或 Mac OS X (10.4.7+)上运行 Spark 作业。

**硬件配置:**处理器酷睿 i3、酷睿 i5(推荐)或酷睿 i7(以获得最佳效果)。然而，多核处理将提供更快的数据处理和可扩展性。对于独立模式，您至少需要 8-16 GB 内存(推荐)，对于单个虚拟机，至少需要 32 GB 内存，对于集群，则需要更高的内存。您还需要足够的存储空间来运行繁重的作业(取决于您要处理的数据集大小)，并且最好至少有 50 GB 的可用磁盘存储空间(对于缺少的独立单词和 SQL 仓库)。

除此之外，您还需要以下内容:

*   VirtualBox 5.1.22 或更高版本
*   Hortonworks HDP 沙盒 V2.6 或更高版本
*   日蚀霓虹或以上
*   Eclipse 插件缩放
*   Eclipse Git 插件
*   Spark 2.0.0(或更高版本)
*   Hadoop 2.7(或更高版本)
*   Java (JDK 和 JRE) 1.7+/1.8+
*   Scala 2.11.x(或更高版本)
*   Python 2.7+/3.4+
*   R 3.1+和 RStudio 1.0.143(或更高)
*   Maven Eclipse 插件(2.9 或更高版本)
*   Eclipse 的 Maven 编译器插件(2.3.2 或更高版本)
*   Eclipse 的 Maven 汇编插件(2.4.1 或更高版本)
*   Oracle JDK SE 1.8.x
*   捷脑智能社区版 2016.2.X 或更高版本
*   面向 IntelliJ 2016.2.x 的 Scala 插件
*   Jfreechart 1.0.19 版
*   微风-核心 0.12
*   Cloud9 1.5.0 JAR
*   19/19200
*   Hadoop-流媒体 2.2.0
*   Jcommon 1.0.23
*   Lucene-分析仪-通用 6.0.0
*   Lucene-核心-6.0.0
*   Spark 流水槽组件 2.0.0
*   Spark 流-卡夫卡-组件 2.0.0

# 下载示例代码文件

你可以从你在[www.packt.com](http://www.packt.com)的账户下载这本书的示例代码文件。如果您在其他地方购买了这本书，您可以访问[www.packt.com/support](http://www.packt.com/support)并注册将文件直接通过电子邮件发送给您。

您可以按照以下步骤下载代码文件:

1.  登录或注册[www.packt.com](http://www.packt.com)。
2.  选择“支持”选项卡。
3.  点击代码下载和勘误表。
4.  在搜索框中输入图书的名称，并按照屏幕指示进行操作。

下载文件后，请确保使用最新版本的解压缩文件夹:

*   视窗系统的 WinRAR/7-Zip
*   zipeg/izp/un ARX for MAC
*   适用于 Linux 的 7-Zip/PeaZip

这本书的代码包也托管在 GitHub 上...

# 使用的约定

在这本书里，你会发现许多区分不同种类信息的文本样式。以下是这些风格的一些例子和对它们的意义的解释。

文本中的码字、数据库表名、文件夹名、文件名、文件扩展名、路径名、伪 URL、用户输入和 Twitter 句柄如下所示:“下一行代码读取链接，并将其分配给 to`BeautifulSoup`函数。”

代码块设置如下:

```scala
import org.apache.spark.SparkContext
import org.apache.spark.SparkContext._
import org.apache.spark.SparkConf
```

任何命令行输入或输出都编写如下:

```scala
$./bin/spark-submit --class com.chapter11.RandomForestDemo \
--master spark://ip-172-31-21-153.us-west-2.compute:7077 \
--executor-memory 2G \
--total-executor-cores 2 \
file:///home/KMeans-0.0.1-SNAPSHOT.jar \
file:///home/mnist.bz2
```

**粗体**:新词、重要词以粗体显示。您在屏幕上看到的单词，例如在菜单或对话框中看到的单词，会出现在如下文本中:“配置全局库。选择 Scala SDK 作为您的全局库。”

Warnings or important notes appear like this. Tips and tricks appear like this.

# 取得联系

我们随时欢迎读者的反馈。

**一般反馈**:如果你对这本书的任何方面有疑问，在你的信息主题中提到书名，发邮件给我们`customercare@packtpub.com`。

**勘误表**:虽然我们已经尽了最大的努力来保证内容的准确性，但是错误还是会发生。如果你在这本书里发现了一个错误，如果你能向我们报告，我们将不胜感激。请访问[www.packt.com/submit-errata](http://www.packt.com/submit-errata)，选择您的图书，点击勘误表提交链接，并输入详细信息。

**盗版**:如果您在互联网上遇到任何形式的我们作品的非法拷贝，如果您能提供我们的位置地址或网站名称，我们将不胜感激。请联系我们...

# 复习

请留下评论。一旦你阅读并使用了这本书，为什么不在你购买它的网站上留下评论呢？然后，潜在的读者可以看到并使用您不带偏见的意见来做出购买决定，我们在 Packt 可以了解您对我们产品的看法，我们的作者可以看到您对他们的书的反馈。谢谢大家！

更多关于 Packt 的信息，请访问[packt.com](http://www.packt.com/)。