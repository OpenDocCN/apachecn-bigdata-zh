# 零、前言

在这个智能时代，数据分析是维持和促进业务增长的关键。每个企业都在尝试利用各种数据科学工具和技术尽可能多地利用他们的数据，以沿着分析成熟度曲线前进。数据科学需求的突然上升是数据科学家稀缺的明显原因。独角兽数据科学家是统计学、机器学习、数学建模以及编程方面的专家，很难满足市场需求。

独角兽数据科学家的可用性只会随着市场需求的增加而下降，而且还会继续下降。因此，我们需要一种解决方案，它不仅能让独角兽数据科学家做得更多，还能创造出 Gartner 所说的“公民数据科学家”。公民数据科学家不是别人，正是开发人员、分析师、商业智能专业人员或其他技术人员，他们的主要工作职能不在统计或分析领域，但对学习数据科学充满热情。它们正在成为整个组织和行业数据分析民主化的关键推动者。

有太多的工具和技术被设计来促进大规模的大数据分析。这本书试图创造公民数据科学家，他们可以利用 Apache Spark 的分布式计算平台进行数据分析。

这本书是学习统计分析和机器学习以构建可扩展数据产品的实用指南。它有助于掌握数据科学的核心概念，也有助于 Apache Spark 帮助您启动任何现实生活中的数据分析项目。整本书中，所有章节都有足够的例子支持，可以在家用电脑上执行，这样读者就可以很容易地理解和吸收概念。每一章都试图自成一体，这样读者就可以从任何一章开始，并指向相关的章节了解详情。虽然这些章节从基础开始让初学者学习和理解，但同时对资深架构师来说也足够全面。

# 这本书涵盖了什么

[第 1 章](01.html "Chapter 1.  Big Data and Data Science – An Introduction")、*大数据和数据科学–简介*，本章简要讨论大数据分析中的各种挑战，以及 Apache Spark 如何在单一平台上解决这些问题。本章还解释了数据分析是如何演变成现在这样的，并给出了 Spark 堆栈的基本概念。

[第二章](02.html "Chapter 2. The Spark Programming Model")、*Spark 编程模型*，本章讲述 Apache Spark 的设计考虑和支持的编程语言。它还解释了 Spark 核心组件，并详细介绍了 RDD API，这是 Spark 的基本构造块。

[第三章](03.html "Chapter 3.  Introduction to DataFrames")、*数据框介绍*，本章讲解数据框，这是数据科学家安心工作最方便、最有用的组件。它解释了 Spark SQL 和支持数据帧的 Catalyst 优化器。此外，还通过代码示例演示了各种数据框操作。

[第四章](04.html "Chapter 4.  Unified Data Access")、*统一数据访问*，这一章讲的是我们从不同的来源获取数据，进行整合，统一工作的各种方式。它涵盖了实时数据收集和操作的流方面。它还谈到了这些 API 的幕后基础。

[第 5 章](05.html "Chapter 5. Data Analysis on Spark")、*星火上的数据分析*，本章讨论完整的数据分析生命周期。通过大量的代码示例，它解释了如何从不同的来源获取数据，如何使用数据清理和转换技术准备数据，以及如何执行描述性和推理性统计以从数据中生成隐藏的见解。

[第 6 章](06.html "Chapter 6.  Machine Learning")、*机器学习*，本章解释了各种机器学习算法，它们是如何在 MLlib 库中实现的，以及它们如何与流水线 API 一起使用以实现简化的执行。本章涵盖了所有算法的基本原理，因此可以作为一站式参考。

[第 7 章](07.html "Chapter 7.  Extending Spark with SparkR")、*用 Spark*扩展 Spark，这一章主要面向希望利用 Spark 进行数据分析的 R 程序员。它解释了如何用 SparkR 编程以及如何使用 R 库的机器学习算法。

[第 8 章](08.html "Chapter 8.  Analyzing Unstructured Data")、*分析非结构化数据*，本章只讨论非结构化数据分析。它解释了如何获取非结构化数据，对其进行处理并对其进行机器学习。它还涵盖了“机器学习”一章中没有涉及的一些降维技术。

[第九章](09.html "Chapter 9. Visualizing Big Data")、*可视化大数据*，在这一章中，读者将学习 Spark 上支持的各种可视化技术。它解释了数据工程师、数据科学家和业务用户的不同类型的可视化需求；并建议正确的工具和技术。它还谈到了利用 IPython/Jupyter 笔记本和齐柏林飞艇，一个用于数据可视化的 Apache 项目。

[第 10 章](10.html "Chapter 10.  Putting It All Together")、*综合*，到目前为止，本书已经在不同章节分别讨论了大部分数据分析组件。这一章致力于在一个典型的数据科学项目上缝合各种步骤，并展示一个完整的分析项目执行的逐步方法。

[第 11 章](11.html "Chapter 11.  Building Data Science Applications")、*构建数据科学应用*，到目前为止，本书主要讨论了数据科学组件以及一个完整的执行示例。本章提供了如何构建可在生产中部署的数据产品的提示。它还介绍了 Apache Spark 项目的当前发展状况，以及该项目的未来发展。

# 这本书你需要什么

在执行书中提到的代码之前，您的系统必须有以下软件。但是，并非所有章节都需要所有软件组件:

*   Ubuntu 14.4 或更高版本，Windows 7 或更高版本
*   Apache Spark 2.0.0
*   Scala: 2.10.4
*   Python 2.7.6
*   R 3.3.0
*   Java 1.7.0
*   齐柏林飞艇 0.6.1
*   Jupyter 4.2.0
*   IPython 核心 5.1

# 这本书是给谁的

这本书是为任何想利用 Apache Spark 进行数据科学和机器学习的人准备的。如果你是一个想扩展知识在 Spark 中执行数据科学操作的技术专家，或者是一个想了解算法如何在 Spark 中实现的数据科学家，或者是一个开发经验最少的新手，想了解大数据分析，这本书就是为你准备的！

# 惯例

在这本书里，你会发现许多区分不同种类信息的文本样式。以下是这些风格的一些例子和对它们的意义的解释。

文本中的码字、数据库表名、文件夹名、文件名、文件扩展名、路径名、伪 URL、用户输入和 Twitter 句柄如下所示:“当一个程序在 Spark shell 上运行时，它被称为驱动程序，其中有用户的`main`方法。”

代码块设置如下:

```scala
Scala> sc.parallelize(List(2, 3, 4)).count()
res0: Long = 3
Scala> sc.parallelize(List(2, 3, 4)).collect()
res1: Array[Int] = Array(2, 3, 4)
Scala> sc.parallelize(List(2, 3, 4)).first()
res2: Int = 2
Scala> sc.parallelize(List(2, 3, 4)).take(2)
res3: Array[Int] = Array(2, 3)
```

**新名词**和**重要词语**以粗体显示。您在屏幕上看到的单词，例如菜单或对话框中的单词，出现在文本中，如下所示:“它还允许用户使用**数据源应用编程接口**从开箱即用不支持的数据源(例如，CSV、Avro HBase、Cassandra 等)中获取数据。)"

### 注

警告或重要提示会出现在这样的框中。

### 类型

提示和技巧是这样出现的。

# 读者反馈

我们随时欢迎读者的反馈。让我们知道你对这本书的看法——你喜欢或不喜欢什么。读者反馈对我们来说很重要，因为它有助于我们开发出你真正能从中获益的标题。要向我们发送一般反馈，只需给 feedback@packtpub.com 发电子邮件，并在邮件主题中提及书名。如果你对某个主题有专业知识，并且对写作或投稿感兴趣，请参见我们位于[www.packtpub.com/authors](http://www.packtpub.com/authors)的作者指南。

# 客户支持

现在，您已经自豪地拥有了一本书，我们有许多东西可以帮助您从购买中获得最大收益。

## 下载示例代码

你可以从你在[http://www.packtpub.com](http://www.packtpub.com)的账户下载这本书的示例代码文件。如果您在其他地方购买了这本书，您可以访问[http://www.packtpub.com/support](http://www.packtpub.com/support)并注册，以便将文件直接通过电子邮件发送给您。

您可以按照以下步骤下载代码文件:

1.  使用您的电子邮件地址和密码登录或注册我们的网站。
2.  将鼠标指针悬停在顶部的 **SUPPORT** 选项卡上。
3.  点击**代码下载&勘误表**。
4.  在**搜索**框中输入图书名称。
5.  选择要下载代码文件的书籍。
6.  从您购买这本书的下拉菜单中选择。
7.  点击**代码下载**。

下载文件后，请确保使用最新版本的解压缩文件夹:

*   视窗系统的 WinRAR / 7-Zip
*   zipeg/izp/un ARX for MAC
*   适用于 Linux 的 7-Zip / PeaZip

这本书的代码包也托管在 https://github.com/PacktPublishing/Spark-for-Data-Science 的 GitHub 上。我们还有来自丰富的图书和视频目录的其他代码包，可在[https://github.com/PacktPublishing/](https://github.com/PacktPublishing/)获得。看看他们！

## 下载本书的彩色图片

我们还为您提供了一个 PDF 文件，其中包含本书中使用的截图/图表的彩色图像。彩色图像将帮助您更好地理解输出中的变化。您可以从[http://www . packtpub . com/sites/default/files/downloads/SparkforDataScience _ color images . pdf](http://www.packtpub.com/sites/default/files/downloads/Bookname_ColorImages.pdf)下载此文件。

## 勘误表

尽管我们尽了最大努力来确保我们内容的准确性，但错误还是会发生。如果你在我们的某本书里发现一个错误，也许是文本或代码中的错误，如果你能向我们报告，我们将不胜感激。通过这样做，你可以让其他读者免受挫折，并帮助我们改进这本书的后续版本。如果您发现任何勘误表，请访问[http://www.packtpub.com/submit-errata](http://www.packtpub.com/submit-errata)，选择您的书籍，点击**勘误表提交表**链接，并输入您的勘误表的详细信息。一旦您的勘误表得到验证，您的提交将被接受，勘误表将上传到我们的网站或添加到该标题勘误表部分下的任何现有勘误表列表中。

要查看之前提交的勘误表，请前往[https://www.packtpub.com/books/content/support](https://www.packtpub.com/books/content/support)并在搜索栏中输入图书名称。所需信息将出现在**勘误表**部分。

## 盗版

互联网上版权材料的盗版是所有媒体的一个持续问题。在 Packt，我们非常重视版权和许可证的保护。如果您在互联网上遇到任何形式的我们作品的非法拷贝，请立即向我们提供位置地址或网站名称，以便我们寻求补救。

请联系我们在 copyright@packtpub.com 的链接到可疑的盗版材料。

我们感谢您在保护我们的作者方面的帮助，以及我们为您带来有价值内容的能力。

## 问题

如果你对这本书的任何方面有问题，你可以联系我们在 questions@packtpub.com，我们将尽最大努力解决这个问题。