# 十、Storm 中的高级概念

在本章中，我们将涵盖以下主题:

*   构建三叉戟拓扑
*   了解三叉戟原料药
*   示例和插图

在本章中，我们将学习事务拓扑和三叉戟应用编程接口。我们还将探讨微批处理及其在 Storm 拓扑中的实现。

# 构建三叉戟拓扑

三叉戟为 Storm 计算提供了批处理优势。它允许开发人员在 Storm 框架上使用抽象的层进行计算，为分布式查询提供了高吞吐量的状态处理优势。

嗯三叉戟的架构和暴风一样；它建立在 Storm 之上，抽象出一个层，在 Storm 之上增加了微批处理和执行类 SQL 函数的功能。

为了类比，可以说三叉戟在概念上很像批量加工的 Pig。它支持连接、聚合、分组、过滤器、函数等等。

Trident 具有基本的批处理功能，例如一致性处理和对元组执行一次处理逻辑。

现在来了解三叉戟及其工作原理；让我们看一个简单的例子。

我们选择的示例将实现以下内容:

*   句子流中的字数(标准 Storm 字数拓扑)
*   获取一组列出的单词的计数总和的查询实现

这是解剖的代码:

```scala
FixedBatchSpout myFixedspout = new FixedBatchSpout(new  Fields("sentence"), 3,
new Values("the basic storm topology do a great job"),
new Values("they get tremendous speed and guaranteed processing"),
new Values("that too in a reliable manner "),
new Values("the new trident api over storm gets user more features  "),
new Values("it gets micro batching over storm "));
myFixedspout.setCycle(true);
```

这个前面的代码片段确保了喷流`myFixedspout`在作为值添加的句子集合中循环。这个片段确保了我们有源源不断的数据流进入拓扑，并有足够的点来执行我们想要的所有微批处理功能。

现在我们已经确定了连续输入流，让我们看下面的片段:

```scala
//creating a new trident topology
TridentTopology myTridentTopology = new TridentTopology();
//Adding a spout and configuring the fields and query 
TridentState myWordCounts = topology.newStream("myFixedspout",  spout)
  .each(new Fields("sentence"), new Split(), new Fields("word"))
  .groupBy(new Fields("word"))
  .persistentAggregate(new MemoryMapState.Factory(), new Count(),  new Fields("count"))
  .parallelismHint(6);
```

现在让我们一行行地看代码来解释它是如何工作的。

在这里，我们首先创建一个三叉戟拓扑对象，这反过来让开发人员访问三叉戟接口。

这种拓扑结构`myTridentTopology`可以访问一个名为`newStream`的方法，该方法可以创建一个新的流来从源中读取数据。

这里我们使用前面片段中的`myFixedSpout`来循环一组预定义的句子。在生产场景或现实场景中，我们将使用一个喷口来读取队列中的流(如 RabbitMQ、Kafka 等)。

现在的微配料；谁做，怎么做？Trident 框架存储了每个源的状态(它还记得到目前为止它消耗了哪些输入数据)。这种状态保存是在动物园管理员集群中完成的。前面代码中的标记*喷口*实际上是一个 znode，它是在 Zookeeper 集群中创建的，用于保存状态元数据信息。

该元数据信息是为小批量存储的，其中批量大小是基于输入元组速度的变量；基于每秒的事件**事务** ( **tps** )可能有几百到几百万个元组。

现在我的喷口读着，把溪流喷向标有`sentence`的田野。在下一行，我们将把句子拆分成单词；这与我们在前面提到的`wordCount`拓扑中部署的功能完全相同。

以下是捕获`split`功能工作的代码上下文:

```scala
public class Split extends BaseFunction {
  public void execute(TridentTuple tuple, TridentCollector  collector) {
      String sentence = tuple.getString(0);
      for(String word: sentence.split(" ")) {
          collector.emit(new Values(word));
      }
  }
}
```

一个非常简单的上下文在*空格*上分割句子，以元组的形式发出每个单词。

现在，超过这个点的拓扑计算计数，并以持久的方式存储结果。可以通过以下步骤计算拓扑:

1.  我们按*字*字段将流分组。
2.  我们使用计数聚合器聚合并持久化每个组。

持久化函数应该以一种方式编写，将聚合结果存储在一个实际保持状态的存储中。前面代码中的插图将所有聚合保存在内存中，这个片段可以非常方便地重写，以便将值保存到内存数据库系统(如 memcached 或 Hazelcast)或稳定存储(如 Cassandra)中的 IMDB。

带 Storm 的三叉戟之所以如此受欢迎，是因为它保证了在一个语义中以故障安全的方式处理所有元组。在由于失败而需要重试的情况下，它只做一次，所以作为开发人员，我不会在发生失败时多次更新表存储。

Trident 通过对输入流创建非常小的批次来进行微批处理，如下图所示:

![Building a Trident topology](img/00072.jpeg)

在上图中，我们已经为微批处理给出了一个清晰的演示，即在 Storm 中，Trident 框架是如何在流数据上创建小批处理的。请记住，上图只是微量配料的说明；批处理中元组的实际数量取决于源上传入数据的 tps，并由框架决定。

现在已经完成了问题的微批处理部分，让我们进入问题的下一部分，在这些微批处理上执行分布式查询。三叉戟 Storm 保证了这些查询的低延迟和闪电般的速度。在处理和语义上，这些查询很像**远程过程调用** ( **RPC** )，但 Storm 的区别在于它给你带来了高度的并行性，从而使它们具有高性能，并且执行速度极快。

让我们来看看这种基于 DRPC 的查询与我们的三叉戟组件的集成。

以下是 DRPC 的代码片段，后面是解释:

```scala
myTridentTopology.newDRPCStream("words")
  .each(new Fields("args"), new Split(), new Fields("word"))
  .groupBy(new Fields("word"))
  .stateQuery(wordCounts, new Fields("word"), new MapGet(), new  Fields("count"))
  .each(new Fields("count"), new FilterNull())
  .aggregate(new Fields("count"), new Sum(), new Fields("sum"));
```

在前面的代码片段中，我们使用`myTridentTopology`创建了一个 DRPC 流，除此之外，我们还有一个名为`word`的函数。

每个 DRPC 查询请求都被视为它自己的迷你批处理作业，执行这个迷你作业的两个参数是代表该请求的一个元组。例如，在我们的例子中，参数是用空格分隔的单词列表。

以下是在前面的代码片段中执行的步骤:

*   我们把论点流分成它的组成词；例如，我的论点`storm trident topology`被拆分成单独的词，如`storm`、`trident`和`topology`
*   然后输入流按`word`分组
*   接下来，状态查询操作符用于查询拓扑第一部分生成的三叉戟状态对象:
    *   状态查询接受由拓扑的前一部分计算的字数。
    *   然后，它执行作为查询数据的 DRPC 请求的一部分指定的函数。
    *   在这种情况下，我的拓扑是对查询执行`MapGet`函数，得到每个单词的计数；在我们的例子中，DRPC 流的分组方式与前面拓扑部分中的`TridentState`完全相同。这种安排保证了我对每个单词的所有字数查询都指向管理单词更新的`TridentState`对象的同一个三叉戟状态分区。
*   `FilterNull`确保没有计数的单词被过滤掉
*   然后 sum 聚合器将所有计数相加，得到结果，这些结果会自动返回给等待的客户端

理解了开发人员编写的代码的执行后，让我们看看 Trident 的样板是什么，以及当这个框架执行时，幕后会自动发生什么。

*   在我们的三叉戟字数统计拓扑中，有两种操作可以读取或写入状态— `persistentAggregate`和`stateQuery`。Trident 利用自动将这些操作批处理到该状态的能力。例如，当前的处理需要对数据库进行 10 次读写；Trident 会自动将它们作为一次读取和一次写入一起批处理。这为您提供了由框架处理优化时的性能和计算便利性。
*   三叉戟聚合器是框架的其他高效和优化的组件。它们不按照规则将所有元组转移到一台机器上，然后进行聚合，而是尽可能通过执行部分聚合来优化计算，然后通过网络传输结果，从而节省网络延迟。这里采用的方法类似于 MapReduce 世界中的组合器。

# 了解三叉戟原料药

三叉戟 API 支持五大类操作:

*   不通过网络传输对本地数据进行分区的操作
*   与流的重新分区相关的操作(包括通过网络传输流数据)
*   流上的数据聚合(该操作将网络传输作为操作的一部分)
*   对流中的字段进行分组
*   合并和加入

## 本地分区操纵操作

顾名思义，这些操作在每个节点上的批处理上是本地操作的，不涉及网络流量。以下功能属于这一类别。

### 功能

*   该操作取单个输入值，输出零个或多个元组
*   这些函数操作的输出被附加到原始元组的末尾，并被发送到流中
*   在函数不发出输出元组的情况下，框架也会过滤输入元组，而在其他情况下，输入元组对于每个输出元组都是重复的

让我们用一个例子来说明这是如何工作的:

```scala
public class MyLocalFunction extends BaseFunction {
  public void execute(TridentTuple myTuple, TridentCollector  myCollector) {
      for(int i=0; i < myTuple.getInteger(0); i++) {
          myCollector.emit(new Values(i));
      }
  }
}
```

现在是的下一个假设，变量中名为`myTridentStream`的输入流具有以下字段`["a", "b", "c" ]`，流上的元组描述如下:

```scala
[10, 2, 30]
[40, 1, 60]
[30, 0, 80]
```

现在，让我们执行前面代码中创建的示例函数，如下面的代码片段所示:

```scala
mystream.each(new Fields("b"), new MyLocalFunction(), new  Fields("d")))
```

这里期望的输出是根据它应该返回的函数`["a", "b", "c", "d"]`，所以对于流中前面的元组，我将得到以下输出:

```scala
//for input tuple [10, 2, 30] loop in the function executes twice  //value of b=2
[10, 2, 30, 0]
[10, 2, 30, 1]
//for input tuple [4, 1, 6] loop in the function executes once  value //of b =1
[4, 1, 6, 0]
//for input tuple [3, 0, 8]
//no output because the value of field b is zero and the for loop  //would exit in first iteration itself value of b=0
```

### 过滤器

滤镜没有用词不当；它们的执行就像它们的名字所暗示的一样:它们帮助我们决定我们是否必须保留一个元组——它们做的正是过滤器所做的，也就是根据给定的标准移除不需要的东西。

让我们看一下下面的代码片段，看看过滤器函数的工作原理:

```scala
public class MyLocalFilterFunction extends BaseFunction {
    public boolean isKeep(TridentTuple tuple) {
      return tuple.getInteger(0) == 1 && tuple.getInteger(1) == 2;
    }
}
```

让我们看看输入流上的样本元组，字段为`[ "a" , "b" , "c"]`:

```scala
[1,2,3]
[2,1,1]
[2,3,4]
```

我们执行或调用函数如下:

```scala
mystream.each(new Fields("b", "a"), new MyLocalFilterFunction())
```

输出如下:

```scala
//for tuple 1 [1,2,3]
// no output because valueof("field b") ==1 && valueof("field a")  ==2 //is not satisfied 
//for tuple 1 [2,1,1]
// no output because valueof("field b") ==1 && valueof("field a")  ==2 [2,1,1]
//for tuple 1 [2,3,4]
// no output because valueof("field b") ==1 && valueof("field a")  ==2 //is not satisfied
```

### 分区聚合

一组元组上的每个分区上的`partitionAggregate`函数作为批聚集在一起。这种功能之间存在行为差异；与我们到目前为止执行的局部函数相比，这个函数为输入元组上的流发出一个输出元组。

以下是可用于在此框架上执行的各种聚合的其他函数。

#### 总和

下面是如何调用求和聚合函数:

```scala
mystream.partitionAggregate(new Fields("b"), new Sum(), new Fields("sum"))
```

假设输入流有`["a", "b"]`字段，以下是元组:

```scala
Partition 0:
["a", 1]
["b", 2]
Partition 1:
["a", 3]
["c", 8]
Partition 2:
["e", 1]
["d", 9]
["d", 10]
```

输出如下:

```scala
Partition 0:
[3]
Partition 1:
[11]
Partition 2:
[20]
```

#### 组合聚集器

三叉戟 API 提供的这个接口的实现返回一个单一的元组，单个字段作为输出；在内部，它对每个输入元组执行一个 init 函数，然后组合值，直到只剩下一个值，作为输出返回。如果组合函数遇到没有任何值的分区，就会发出“0”。

以下是接口定义及其合同:

```scala
public interface CombinerAggregator<T> extends Serializable {
    T init(TridentTuple tuple);
    T combine(T val1, T val2);
    T zero();
}
```

以下是计数功能的实现:

```scala
public class myCount implements CombinerAggregator<Long> {
    public Long init(TridentTuple mytuple) {
        return 1L;
    }
public Long combine(Long val1, Long val2) {
        return val1 + val2;
    }

    public Long zero() {
        return 0L;
    }
}
```

这些`CombinerAggregators`函数相对于`partitionAggregate`函数的最大优势在于，在通过网络传输结果之前，通过执行部分聚合，这是一种更高效、更优化的方法。

#### 减振器

顾名思义，函数产生一个`init`值，然后迭代输入流中的每个元组以产生一个由单个字段和单个元组组成的输出。

以下是`ReducerAggregate`界面的界面契约:

```scala
public interface ReducerAggregator<T> extends Serializable {
    T init();
    T reduce(T curr, TridentTuple tuple);
}
```

下面是计数功能接口的实现:

```scala
public class myReducerCount implements ReducerAggregator<Long> {
    public Long init() {
        return 0L;
    }

    public Long reduce(Long curr, TridentTuple tuple) {
        return curr + 1;
    }
}
```

#### 聚合器

一个`Aggregator`函数是最常用和最通用的聚合函数。它有能力发出一个或多个元组，每个元组可以有任意数量的字段。它们具有以下接口签名:

```scala
public interface Aggregator<T> extends Operation {
    T init(Object batchId, TridentCollector collector);
    void aggregate(T state, TridentTuple tuple, TridentCollector  collector);
    void complete(T state, TridentCollector collector);
}
```

执行模式如下:

*   `init`方法是每批加工的前身。它在每批加工之前被调用。完成后，它返回一个保存批处理状态表示的对象，并将其传递给后续的聚合和完成方法。
*   与`init`方法不同，`aggregate`方法对批处理分区中的每个元组调用一次。该方法可以存储状态，并可以根据功能需求发出结果。
*   完整的方法就像一个后处理器；它在最后执行，此时批处理分区已经被聚合完全处理。

以下是计数作为聚合函数的实现:

```scala
public class CountAggregate extends BaseAggregator<CountState> {
    static class CountState {
        long count = 0;
    }
    public CountState init(Object batchId, TridentCollector  collector) {
        return new CountState();
    }
    public void aggregate(CountState state, TridentTuple tuple,  TridentCollector collector) {
        state.count+=1;
    }
    public void complete(CountState state, TridentCollector  collector) {
        collector.emit(new Values(state.count));
    }
}
```

我们多次遇到需要多个聚合器同时执行的实现。在这种情况下，链接的概念就派上了用场。由于三叉戟应用编程接口中的这一功能，我们可以构建一个聚合器的执行链，在成批的传入流元组上执行。以下是这类链条的一个例子:

```scala
myInputstream.chainedAgg()
        .partitionAggregate(new Count(), new Fields("count"))
        .partitionAggregate(new Fields("b"), new Sum(), new  Fields("sum"))
        .chainEnd()
```

这个链的执行将在每个分区上运行指定的`sum`和`count`聚合器函数。输出将是一个单一的元组，两个字段保存`sum`和`count`的值。

## 与流重新分区相关的操作

正如名称所暗示的，这些流重新分区操作与跨任务改变元组分区的函数的执行相关。这些操作涉及网络流量，结果会重新分配流，并可能导致整体分区策略发生变化，从而影响多个分区。

以下是三叉戟应用编程接口提供的重新分区功能:

*   `Shuffle`:这个执行一种重新平衡的功能，它使用随机循环算法在分区之间均匀地重新分配元组。
*   `Broadcast`:这就做到了顾名思义；它向每个目标分区广播和传输每个元组。
*   `partitionBy`:这个函数对一组指定的字段进行散列和 mod，这样相同的字段总是被移动到相同的分区。作为一个类比，我们可以假设这个的功能类似于我们最初在 Storm 分组中学到的字段分组。
*   `global`:这个和 Storm 中的流的全局分组是一样的，在这种情况下，所有的批次都选择相同的分区。
*   `batchGlobal`:一个批次中的所有元组都被发送到同一个分区(所以它们有点粘在一起)，但是不同的批次可以被传递到不同的分区。

## 流上的数据聚合

Storm 的三叉戟框架提供了两种执行聚合的操作:

*   `aggregate`:我们在前面的章节中已经介绍过了，它在独立的分区中工作，不涉及网络流量
*   `persistentAggregate`:这将跨分区执行聚合，但不同的是将结果存储在一个状态源中

## 在溪流中的田野上分组

分组操作的工作原理类似于按关系模型中的操作分组，唯一的区别是 Storm 框架中的操作在来自输入源的元组流上执行。

让我们借助下图更深入地了解这一点:

![Grouping over a field in a stream](img/00073.jpeg)

Storm 三叉戟中的这些操作运行在几个不同分区的元组流上。

## 合并并加入

合并和连接应用编程接口提供了将各种流合并和连接在一起的接口。这种是可能使用的各种的方式提供如下:

*   `Merge`:顾名思义，`merge`将两个或多个流合并在一起，并将合并后的流作为第一个流的输出字段发出:

    ```scala
    myTridentTopology.merge(stream1,stream2,stream3);

    ```

*   `Join`:这个操作和传统的 SQL `join`函数一样工作，不同的是它适用于小批量，而不是从喷口出来的整个无限流

例如，考虑一个连接函数，其中流 1 有诸如`["key", "val1", "val2"]`的字段，流 2 有`["x", "val1"]`，从这些函数中我们执行以下代码:

```scala
myTridentTopology.join(stream1, new Fields("key"), stream2, new  Fields("x"), new Fields("key", "a", "b", "c"));
```

因此，流 1 和流 2 将使用`key`和`x`连接，其中`key`将连接流 1 的字段，`x`将连接流 2 的字段。

从连接发出的输出元组将具有以下内容:

*   所有连接字段的列表；在我们的例子中，它将是来自流 1 的`key`和来自流 2 的`x`。
*   来自参与连接操作的所有流的不是连接字段的所有字段的列表，其顺序与它们被传递到`join`操作的顺序相同。在我们的例子中，分别是来自流 1 的`val1`和`val2`的`a`和`b`，以及来自流 2 的`val1`的`c`(注意，如果流中存在任何歧义，该步骤也消除了字段名的歧义，在我们的例子中`val1`字段在两个流之间是歧义的)。

当像连接这样的操作发生在从不同喷口馈送到拓扑中的流上时，该框架确保喷口相对于批发射是同步的，使得每个连接计算可以包括来自每个喷口的批的元组。

# 示例和插图

三叉戟的另一个现成且流行的实现是到达拓扑，这是一种纯 DRPC 拓扑，可以按需找到网址。在深入研究之前，让我们先了解一些行话。

Reach 基本上是暴露给一个网址的推特用户总数。

到达计算是一个多步骤过程，可以通过以下示例实现:

*   获取所有曾在推特上发布过网址的用户
*   获取这些用户的跟随者树
*   组装之前获取的巨大从动件组
*   数一数

好吧，看看之前包含的骨架算法，你会发现它超出了单台机器的能力，我们需要一个分布式计算引擎来实现它。它是 Storm 三叉戟框架的理想候选，因为您有能力在集群的每一步执行高度并行的计算。

*   我们的三叉戟 reach 拓扑将从两个大型数据库中吸取数据
*   银行是发件人银行的网址，所有的网址都会和发推的用户的名字一起存储
*   银行 B 为用户跟随者银行；这个数据库将有一个用户跟踪所有推特用户的映射

拓扑定义如下:

```scala
TridentState urlToTweeterState =  topology.newStaticState(getUrlToTweetersState());
TridentState tweetersToFollowerState =  topology.newStaticState(getTweeterToFollowersState());

topology.newDRPCStream("reach")
       .stateQuery(urlToTweeterState, new Fields("args"), new  MapGet(), new Fields("tweeters"))
       .each(new Fields("tweeters"), new ExpandList(), new  Fields("tweeter"))
       .shuffle()
       .stateQuery(tweetersToFollowerState, new Fields("tweeter"),  new MapGet(), new Fields("followers"))
       .parallelismHint(200)
       .each(new Fields("followers"), new ExpandList(), new  Fields("follower"))
       .groupBy(new Fields("follower"))
       .aggregate(new One(), new Fields("one"))
       .parallelismHint(20)
       .aggregate(new Count(), new Fields("reach"));
```

在前面的拓扑中，我们执行了以下步骤:

1.  为两个数据库创建一个`TridentState`对象(指向发起银行 A 的 URL 和跟随银行 B 的用户)。
2.  `newStaticState`方法用于数据库状态对象的实例化；我们有能力在前面创建的源状态上运行 DRPC 查询。
3.  在执行中，当要计算某个 URL 的到达范围时，我们使用数据库 A 的三叉戟状态执行查询，以获取曾经使用该 URL 发推的所有用户的列表。
4.  `ExpandList`函数为查询中的网址的每个推文创建并发出一个元组。
5.  接下来，我们获取之前获取的每个高音扬声器的跟随器。这一步需要最高程度的并行性，因此我们在这里使用无序分组，以便在螺栓的所有实例之间均匀分布负载。在我们的 reach 拓扑中，这是最密集的计算步骤。
6.  一旦我们有了网址高音扬声器的追随者列表，我们就执行一个模拟操作来过滤唯一的追随者。
7.  我们通过将他们组合在一起，然后使用`one`聚合器来获得独特的追随者。后者只需为每个组发出`1`，在下一步中，所有这些都被计算在一起，以达到目标。
8.  然后我们计算追随者(唯一的)，从而到达网址的范围。

# 测验时间

问题 1 .陈述以下陈述是真是假:

1.  DRPC 是一个无状态的 Storm 处理机制。
2.  如果一个元组在三叉戟拓扑中执行失败，整个批处理将被重放。
3.  Trident 允许用户在流数据上实现窗口功能。
4.  聚合器比分区聚合器更有效。

问题 2 .填空:

1.  _____ 是 RPC 的分布式版本。
2.  _____ 是 Storm 上的基本微批处理框架。
3.  ___________ 函数用于根据特定标准或条件从流批次中移除元组。

问题 3 .创建一个三叉戟拓扑来查找在最近 5 分钟内拥有最多推文的推文者。

# 总结

在这一章中，我们已经介绍了关于 Storm 及其高级概念的几乎所有内容，并为您提供了使用三叉戟和 DRPC 拓扑的机会。您了解了三叉戟及其需求和应用、DRPC 拓扑以及三叉戟应用编程接口中可用的各种功能。

在下一章中，我们将探索与 Storm 密切相关的其他技术组件，这些组件对于使用 Storm 构建端到端解决方案是必要的。我们将结合 Storm 讨论分布式缓存区和带有 memcache 的**复杂事件处理** ( **CEP** )以及斯珀。